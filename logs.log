2025-11-20 13:19:20,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-20 13:19:20,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-20 13:19:20,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-20 13:19:20,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-20 13:19:21,146:INFO:PyCaret ClassificationExperiment
2025-11-20 13:19:21,146:INFO:Logging name: clf-default-name
2025-11-20 13:19:21,146:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-20 13:19:21,146:INFO:version 3.3.2
2025-11-20 13:19:21,147:INFO:Initializing setup()
2025-11-20 13:19:21,147:INFO:self.USI: 741d
2025-11-20 13:19:21,147:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-20 13:19:21,147:INFO:Checking environment
2025-11-20 13:19:21,147:INFO:python_version: 3.11.9
2025-11-20 13:19:21,147:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-20 13:19:21,147:INFO:machine: AMD64
2025-11-20 13:19:21,147:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-20 13:19:21,147:INFO:Memory: svmem(total=16440479744, available=3981348864, percent=75.8, used=12459130880, free=3981348864)
2025-11-20 13:19:21,147:INFO:Physical Core: 8
2025-11-20 13:19:21,147:INFO:Logical Core: 16
2025-11-20 13:19:21,147:INFO:Checking libraries
2025-11-20 13:19:21,147:INFO:System:
2025-11-20 13:19:21,147:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-20 13:19:21,147:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-20 13:19:21,148:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-20 13:19:21,148:INFO:PyCaret required dependencies:
2025-11-20 13:19:21,243:INFO:                 pip: 24.0
2025-11-20 13:19:21,244:INFO:          setuptools: 65.5.0
2025-11-20 13:19:21,244:INFO:             pycaret: 3.3.2
2025-11-20 13:19:21,244:INFO:             IPython: 9.0.2
2025-11-20 13:19:21,244:INFO:          ipywidgets: 8.1.7
2025-11-20 13:19:21,244:INFO:                tqdm: 4.67.1
2025-11-20 13:19:21,244:INFO:               numpy: 1.26.4
2025-11-20 13:19:21,244:INFO:              pandas: 2.1.4
2025-11-20 13:19:21,244:INFO:              jinja2: 3.1.6
2025-11-20 13:19:21,244:INFO:               scipy: 1.11.4
2025-11-20 13:19:21,244:INFO:              joblib: 1.3.2
2025-11-20 13:19:21,244:INFO:             sklearn: 1.4.2
2025-11-20 13:19:21,244:INFO:                pyod: 2.0.5
2025-11-20 13:19:21,244:INFO:            imblearn: 0.14.0
2025-11-20 13:19:21,244:INFO:   category_encoders: 2.7.0
2025-11-20 13:19:21,245:INFO:            lightgbm: 4.6.0
2025-11-20 13:19:21,245:INFO:               numba: 0.61.2
2025-11-20 13:19:21,245:INFO:            requests: 2.32.5
2025-11-20 13:19:21,245:INFO:          matplotlib: 3.7.5
2025-11-20 13:19:21,245:INFO:          scikitplot: 0.3.7
2025-11-20 13:19:21,245:INFO:         yellowbrick: 1.5
2025-11-20 13:19:21,245:INFO:              plotly: 6.3.0
2025-11-20 13:19:21,245:INFO:    plotly-resampler: Not installed
2025-11-20 13:19:21,245:INFO:             kaleido: 1.1.0
2025-11-20 13:19:21,245:INFO:           schemdraw: 0.15
2025-11-20 13:19:21,245:INFO:         statsmodels: 0.14.5
2025-11-20 13:19:21,245:INFO:              sktime: 0.26.0
2025-11-20 13:19:21,245:INFO:               tbats: 1.1.3
2025-11-20 13:19:21,245:INFO:            pmdarima: 2.0.4
2025-11-20 13:19:21,245:INFO:              psutil: 7.0.0
2025-11-20 13:19:21,245:INFO:          markupsafe: 3.0.2
2025-11-20 13:19:21,245:INFO:             pickle5: Not installed
2025-11-20 13:19:21,245:INFO:         cloudpickle: 3.1.1
2025-11-20 13:19:21,245:INFO:         deprecation: 2.1.0
2025-11-20 13:19:21,245:INFO:              xxhash: 3.5.0
2025-11-20 13:19:21,246:INFO:           wurlitzer: Not installed
2025-11-20 13:19:21,246:INFO:PyCaret optional dependencies:
2025-11-20 13:19:21,314:INFO:                shap: 0.48.0
2025-11-20 13:19:21,314:INFO:           interpret: Not installed
2025-11-20 13:19:21,314:INFO:                umap: 0.5.7
2025-11-20 13:19:21,314:INFO:     ydata_profiling: Not installed
2025-11-20 13:19:21,315:INFO:  explainerdashboard: Not installed
2025-11-20 13:19:21,315:INFO:             autoviz: Not installed
2025-11-20 13:19:21,315:INFO:           fairlearn: Not installed
2025-11-20 13:19:21,315:INFO:          deepchecks: Not installed
2025-11-20 13:19:21,315:INFO:             xgboost: 3.0.5
2025-11-20 13:19:21,315:INFO:            catboost: Not installed
2025-11-20 13:19:21,315:INFO:              kmodes: Not installed
2025-11-20 13:19:21,315:INFO:             mlxtend: Not installed
2025-11-20 13:19:21,315:INFO:       statsforecast: Not installed
2025-11-20 13:19:21,315:INFO:        tune_sklearn: Not installed
2025-11-20 13:19:21,315:INFO:                 ray: Not installed
2025-11-20 13:19:21,315:INFO:            hyperopt: Not installed
2025-11-20 13:19:21,315:INFO:              optuna: 4.5.0
2025-11-20 13:19:21,315:INFO:               skopt: Not installed
2025-11-20 13:19:21,315:INFO:              mlflow: Not installed
2025-11-20 13:19:21,315:INFO:              gradio: Not installed
2025-11-20 13:19:21,315:INFO:             fastapi: Not installed
2025-11-20 13:19:21,315:INFO:             uvicorn: Not installed
2025-11-20 13:19:21,315:INFO:              m2cgen: Not installed
2025-11-20 13:19:21,315:INFO:           evidently: Not installed
2025-11-20 13:19:21,315:INFO:               fugue: Not installed
2025-11-20 13:19:21,315:INFO:           streamlit: Not installed
2025-11-20 13:19:21,315:INFO:             prophet: Not installed
2025-11-20 13:19:21,315:INFO:None
2025-11-20 13:19:21,315:INFO:Set up data.
2025-11-20 13:19:21,327:INFO:Set up folding strategy.
2025-11-20 13:19:21,327:INFO:Set up train/test split.
2025-11-20 13:19:21,340:INFO:Set up index.
2025-11-20 13:19:21,341:INFO:Assigning column types.
2025-11-20 13:19:21,349:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-20 13:19:21,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,425:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,473:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,582:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,586:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-20 13:19:21,636:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,667:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:19:21,751:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,754:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-20 13:19:21,838:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,931:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:21,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:21,954:INFO:Preparing preprocessing pipeline...
2025-11-20 13:19:21,955:INFO:Set up date feature engineering.
2025-11-20 13:19:21,955:INFO:Set up simple imputation.
2025-11-20 13:19:22,010:INFO:Finished creating preprocessing pipeline.
2025-11-20 13:19:22,032:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-20 13:19:22,033:INFO:Creating final display dataframe.
2025-11-20 13:19:22,184:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 20)
5   Transformed train set shape           (5961, 20)
6    Transformed test set shape           (2555, 20)
7               Ignore features                    1
8              Numeric features                   16
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 741d
2025-11-20 13:19:22,281:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:22,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:22,366:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:19:22,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:19:22,371:INFO:setup() successfully completed in 1.24s...............
2025-11-20 13:19:22,371:INFO:Initializing compare_models()
2025-11-20 13:19:22,371:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-20 13:19:22,371:INFO:Checking exceptions
2025-11-20 13:19:22,379:INFO:Preparing display monitor
2025-11-20 13:19:22,414:INFO:Initializing Logistic Regression
2025-11-20 13:19:22,414:INFO:Total runtime is 0.0 minutes
2025-11-20 13:19:22,419:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:22,420:INFO:Initializing create_model()
2025-11-20 13:19:22,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:22,420:INFO:Checking exceptions
2025-11-20 13:19:22,420:INFO:Importing libraries
2025-11-20 13:19:22,420:INFO:Copying training dataset
2025-11-20 13:19:22,431:INFO:Defining folds
2025-11-20 13:19:22,431:INFO:Declaring metric variables
2025-11-20 13:19:22,438:INFO:Importing untrained model
2025-11-20 13:19:22,443:INFO:Logistic Regression Imported successfully
2025-11-20 13:19:22,451:INFO:Starting cross validation
2025-11-20 13:19:22,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:29,432:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,484:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,495:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,564:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,598:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,610:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,760:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,775:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,789:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,815:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:19:29,864:INFO:Calculating mean and std
2025-11-20 13:19:29,866:INFO:Creating metrics dataframe
2025-11-20 13:19:29,869:INFO:Uploading results into container
2025-11-20 13:19:29,870:INFO:Uploading model into container now
2025-11-20 13:19:29,871:INFO:_master_model_container: 1
2025-11-20 13:19:29,871:INFO:_display_container: 2
2025-11-20 13:19:29,872:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 13:19:29,872:INFO:create_model() successfully completed......................................
2025-11-20 13:19:30,016:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:30,016:INFO:Creating metrics dataframe
2025-11-20 13:19:30,023:INFO:Initializing K Neighbors Classifier
2025-11-20 13:19:30,023:INFO:Total runtime is 0.12681700388590494 minutes
2025-11-20 13:19:30,027:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:30,027:INFO:Initializing create_model()
2025-11-20 13:19:30,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:30,028:INFO:Checking exceptions
2025-11-20 13:19:30,028:INFO:Importing libraries
2025-11-20 13:19:30,028:INFO:Copying training dataset
2025-11-20 13:19:30,041:INFO:Defining folds
2025-11-20 13:19:30,041:INFO:Declaring metric variables
2025-11-20 13:19:30,045:INFO:Importing untrained model
2025-11-20 13:19:30,049:INFO:K Neighbors Classifier Imported successfully
2025-11-20 13:19:30,057:INFO:Starting cross validation
2025-11-20 13:19:30,058:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:34,581:INFO:Calculating mean and std
2025-11-20 13:19:34,583:INFO:Creating metrics dataframe
2025-11-20 13:19:34,587:INFO:Uploading results into container
2025-11-20 13:19:34,587:INFO:Uploading model into container now
2025-11-20 13:19:34,588:INFO:_master_model_container: 2
2025-11-20 13:19:34,588:INFO:_display_container: 2
2025-11-20 13:19:34,589:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-20 13:19:34,589:INFO:create_model() successfully completed......................................
2025-11-20 13:19:34,708:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:34,708:INFO:Creating metrics dataframe
2025-11-20 13:19:34,715:INFO:Initializing Naive Bayes
2025-11-20 13:19:34,715:INFO:Total runtime is 0.20501485268274944 minutes
2025-11-20 13:19:34,719:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:34,719:INFO:Initializing create_model()
2025-11-20 13:19:34,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:34,719:INFO:Checking exceptions
2025-11-20 13:19:34,719:INFO:Importing libraries
2025-11-20 13:19:34,719:INFO:Copying training dataset
2025-11-20 13:19:34,731:INFO:Defining folds
2025-11-20 13:19:34,731:INFO:Declaring metric variables
2025-11-20 13:19:34,736:INFO:Importing untrained model
2025-11-20 13:19:34,740:INFO:Naive Bayes Imported successfully
2025-11-20 13:19:34,747:INFO:Starting cross validation
2025-11-20 13:19:34,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:34,876:INFO:Calculating mean and std
2025-11-20 13:19:34,877:INFO:Creating metrics dataframe
2025-11-20 13:19:34,880:INFO:Uploading results into container
2025-11-20 13:19:34,881:INFO:Uploading model into container now
2025-11-20 13:19:34,882:INFO:_master_model_container: 3
2025-11-20 13:19:34,882:INFO:_display_container: 2
2025-11-20 13:19:34,882:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-20 13:19:34,882:INFO:create_model() successfully completed......................................
2025-11-20 13:19:34,995:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:34,995:INFO:Creating metrics dataframe
2025-11-20 13:19:35,004:INFO:Initializing Decision Tree Classifier
2025-11-20 13:19:35,004:INFO:Total runtime is 0.20982593695322674 minutes
2025-11-20 13:19:35,007:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:35,008:INFO:Initializing create_model()
2025-11-20 13:19:35,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:35,008:INFO:Checking exceptions
2025-11-20 13:19:35,008:INFO:Importing libraries
2025-11-20 13:19:35,008:INFO:Copying training dataset
2025-11-20 13:19:35,017:INFO:Defining folds
2025-11-20 13:19:35,018:INFO:Declaring metric variables
2025-11-20 13:19:35,022:INFO:Importing untrained model
2025-11-20 13:19:35,025:INFO:Decision Tree Classifier Imported successfully
2025-11-20 13:19:35,033:INFO:Starting cross validation
2025-11-20 13:19:35,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:35,164:INFO:Calculating mean and std
2025-11-20 13:19:35,166:INFO:Creating metrics dataframe
2025-11-20 13:19:35,168:INFO:Uploading results into container
2025-11-20 13:19:35,168:INFO:Uploading model into container now
2025-11-20 13:19:35,169:INFO:_master_model_container: 4
2025-11-20 13:19:35,169:INFO:_display_container: 2
2025-11-20 13:19:35,170:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-20 13:19:35,170:INFO:create_model() successfully completed......................................
2025-11-20 13:19:35,281:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:35,281:INFO:Creating metrics dataframe
2025-11-20 13:19:35,289:INFO:Initializing SVM - Linear Kernel
2025-11-20 13:19:35,289:INFO:Total runtime is 0.2145764430363973 minutes
2025-11-20 13:19:35,293:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:35,293:INFO:Initializing create_model()
2025-11-20 13:19:35,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:35,294:INFO:Checking exceptions
2025-11-20 13:19:35,294:INFO:Importing libraries
2025-11-20 13:19:35,294:INFO:Copying training dataset
2025-11-20 13:19:35,303:INFO:Defining folds
2025-11-20 13:19:35,303:INFO:Declaring metric variables
2025-11-20 13:19:35,307:INFO:Importing untrained model
2025-11-20 13:19:35,311:INFO:SVM - Linear Kernel Imported successfully
2025-11-20 13:19:35,319:INFO:Starting cross validation
2025-11-20 13:19:35,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:35,470:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-20 13:19:35,475:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-20 13:19:35,512:INFO:Calculating mean and std
2025-11-20 13:19:35,514:INFO:Creating metrics dataframe
2025-11-20 13:19:35,516:INFO:Uploading results into container
2025-11-20 13:19:35,516:INFO:Uploading model into container now
2025-11-20 13:19:35,517:INFO:_master_model_container: 5
2025-11-20 13:19:35,517:INFO:_display_container: 2
2025-11-20 13:19:35,518:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-20 13:19:35,518:INFO:create_model() successfully completed......................................
2025-11-20 13:19:35,632:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:35,633:INFO:Creating metrics dataframe
2025-11-20 13:19:35,643:INFO:Initializing Ridge Classifier
2025-11-20 13:19:35,643:INFO:Total runtime is 0.2204843004544576 minutes
2025-11-20 13:19:35,647:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:35,647:INFO:Initializing create_model()
2025-11-20 13:19:35,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:35,648:INFO:Checking exceptions
2025-11-20 13:19:35,648:INFO:Importing libraries
2025-11-20 13:19:35,648:INFO:Copying training dataset
2025-11-20 13:19:35,659:INFO:Defining folds
2025-11-20 13:19:35,659:INFO:Declaring metric variables
2025-11-20 13:19:35,664:INFO:Importing untrained model
2025-11-20 13:19:35,669:INFO:Ridge Classifier Imported successfully
2025-11-20 13:19:35,680:INFO:Starting cross validation
2025-11-20 13:19:35,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:35,795:INFO:Calculating mean and std
2025-11-20 13:19:35,797:INFO:Creating metrics dataframe
2025-11-20 13:19:35,799:INFO:Uploading results into container
2025-11-20 13:19:35,800:INFO:Uploading model into container now
2025-11-20 13:19:35,800:INFO:_master_model_container: 6
2025-11-20 13:19:35,800:INFO:_display_container: 2
2025-11-20 13:19:35,801:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-20 13:19:35,801:INFO:create_model() successfully completed......................................
2025-11-20 13:19:35,914:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:35,914:INFO:Creating metrics dataframe
2025-11-20 13:19:35,922:INFO:Initializing Random Forest Classifier
2025-11-20 13:19:35,923:INFO:Total runtime is 0.22514089345932006 minutes
2025-11-20 13:19:35,926:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:35,926:INFO:Initializing create_model()
2025-11-20 13:19:35,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:35,927:INFO:Checking exceptions
2025-11-20 13:19:35,927:INFO:Importing libraries
2025-11-20 13:19:35,927:INFO:Copying training dataset
2025-11-20 13:19:35,938:INFO:Defining folds
2025-11-20 13:19:35,950:INFO:Declaring metric variables
2025-11-20 13:19:35,954:INFO:Importing untrained model
2025-11-20 13:19:35,958:INFO:Random Forest Classifier Imported successfully
2025-11-20 13:19:35,965:INFO:Starting cross validation
2025-11-20 13:19:35,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:36,842:INFO:Calculating mean and std
2025-11-20 13:19:36,844:INFO:Creating metrics dataframe
2025-11-20 13:19:36,846:INFO:Uploading results into container
2025-11-20 13:19:36,847:INFO:Uploading model into container now
2025-11-20 13:19:36,847:INFO:_master_model_container: 7
2025-11-20 13:19:36,848:INFO:_display_container: 2
2025-11-20 13:19:36,848:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 13:19:36,848:INFO:create_model() successfully completed......................................
2025-11-20 13:19:36,958:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:36,959:INFO:Creating metrics dataframe
2025-11-20 13:19:36,967:INFO:Initializing Quadratic Discriminant Analysis
2025-11-20 13:19:36,967:INFO:Total runtime is 0.2425487438837687 minutes
2025-11-20 13:19:36,971:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:36,971:INFO:Initializing create_model()
2025-11-20 13:19:36,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:36,972:INFO:Checking exceptions
2025-11-20 13:19:36,972:INFO:Importing libraries
2025-11-20 13:19:36,972:INFO:Copying training dataset
2025-11-20 13:19:36,982:INFO:Defining folds
2025-11-20 13:19:36,982:INFO:Declaring metric variables
2025-11-20 13:19:36,986:INFO:Importing untrained model
2025-11-20 13:19:36,991:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-20 13:19:37,001:INFO:Starting cross validation
2025-11-20 13:19:37,002:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,070:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:19:37,122:INFO:Calculating mean and std
2025-11-20 13:19:37,124:INFO:Creating metrics dataframe
2025-11-20 13:19:37,126:INFO:Uploading results into container
2025-11-20 13:19:37,126:INFO:Uploading model into container now
2025-11-20 13:19:37,127:INFO:_master_model_container: 8
2025-11-20 13:19:37,127:INFO:_display_container: 2
2025-11-20 13:19:37,128:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-20 13:19:37,128:INFO:create_model() successfully completed......................................
2025-11-20 13:19:37,242:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:37,242:INFO:Creating metrics dataframe
2025-11-20 13:19:37,250:INFO:Initializing Ada Boost Classifier
2025-11-20 13:19:37,250:INFO:Total runtime is 0.2472623268763224 minutes
2025-11-20 13:19:37,254:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:37,255:INFO:Initializing create_model()
2025-11-20 13:19:37,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:37,255:INFO:Checking exceptions
2025-11-20 13:19:37,255:INFO:Importing libraries
2025-11-20 13:19:37,256:INFO:Copying training dataset
2025-11-20 13:19:37,266:INFO:Defining folds
2025-11-20 13:19:37,266:INFO:Declaring metric variables
2025-11-20 13:19:37,270:INFO:Importing untrained model
2025-11-20 13:19:37,274:INFO:Ada Boost Classifier Imported successfully
2025-11-20 13:19:37,281:INFO:Starting cross validation
2025-11-20 13:19:37,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:37,327:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,331:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,331:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,334:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,336:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,336:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,337:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,337:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,345:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,346:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:19:37,773:INFO:Calculating mean and std
2025-11-20 13:19:37,774:INFO:Creating metrics dataframe
2025-11-20 13:19:37,776:INFO:Uploading results into container
2025-11-20 13:19:37,777:INFO:Uploading model into container now
2025-11-20 13:19:37,777:INFO:_master_model_container: 9
2025-11-20 13:19:37,778:INFO:_display_container: 2
2025-11-20 13:19:37,778:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-20 13:19:37,778:INFO:create_model() successfully completed......................................
2025-11-20 13:19:37,889:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:37,890:INFO:Creating metrics dataframe
2025-11-20 13:19:37,899:INFO:Initializing Gradient Boosting Classifier
2025-11-20 13:19:37,899:INFO:Total runtime is 0.2580830732981364 minutes
2025-11-20 13:19:37,903:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:37,904:INFO:Initializing create_model()
2025-11-20 13:19:37,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:37,904:INFO:Checking exceptions
2025-11-20 13:19:37,904:INFO:Importing libraries
2025-11-20 13:19:37,904:INFO:Copying training dataset
2025-11-20 13:19:37,917:INFO:Defining folds
2025-11-20 13:19:37,918:INFO:Declaring metric variables
2025-11-20 13:19:37,923:INFO:Importing untrained model
2025-11-20 13:19:37,928:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:19:37,939:INFO:Starting cross validation
2025-11-20 13:19:37,940:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:39,165:INFO:Calculating mean and std
2025-11-20 13:19:39,166:INFO:Creating metrics dataframe
2025-11-20 13:19:39,168:INFO:Uploading results into container
2025-11-20 13:19:39,169:INFO:Uploading model into container now
2025-11-20 13:19:39,170:INFO:_master_model_container: 10
2025-11-20 13:19:39,170:INFO:_display_container: 2
2025-11-20 13:19:39,171:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:19:39,171:INFO:create_model() successfully completed......................................
2025-11-20 13:19:39,284:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:39,284:INFO:Creating metrics dataframe
2025-11-20 13:19:39,293:INFO:Initializing Linear Discriminant Analysis
2025-11-20 13:19:39,293:INFO:Total runtime is 0.28130741119384767 minutes
2025-11-20 13:19:39,297:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:39,298:INFO:Initializing create_model()
2025-11-20 13:19:39,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:39,298:INFO:Checking exceptions
2025-11-20 13:19:39,298:INFO:Importing libraries
2025-11-20 13:19:39,298:INFO:Copying training dataset
2025-11-20 13:19:39,308:INFO:Defining folds
2025-11-20 13:19:39,308:INFO:Declaring metric variables
2025-11-20 13:19:39,313:INFO:Importing untrained model
2025-11-20 13:19:39,316:INFO:Linear Discriminant Analysis Imported successfully
2025-11-20 13:19:39,324:INFO:Starting cross validation
2025-11-20 13:19:39,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:39,431:INFO:Calculating mean and std
2025-11-20 13:19:39,432:INFO:Creating metrics dataframe
2025-11-20 13:19:39,434:INFO:Uploading results into container
2025-11-20 13:19:39,434:INFO:Uploading model into container now
2025-11-20 13:19:39,435:INFO:_master_model_container: 11
2025-11-20 13:19:39,435:INFO:_display_container: 2
2025-11-20 13:19:39,436:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-20 13:19:39,436:INFO:create_model() successfully completed......................................
2025-11-20 13:19:39,547:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:39,548:INFO:Creating metrics dataframe
2025-11-20 13:19:39,557:INFO:Initializing Extra Trees Classifier
2025-11-20 13:19:39,557:INFO:Total runtime is 0.2857136408487956 minutes
2025-11-20 13:19:39,561:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:39,562:INFO:Initializing create_model()
2025-11-20 13:19:39,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:39,562:INFO:Checking exceptions
2025-11-20 13:19:39,562:INFO:Importing libraries
2025-11-20 13:19:39,562:INFO:Copying training dataset
2025-11-20 13:19:39,571:INFO:Defining folds
2025-11-20 13:19:39,572:INFO:Declaring metric variables
2025-11-20 13:19:39,576:INFO:Importing untrained model
2025-11-20 13:19:39,580:INFO:Extra Trees Classifier Imported successfully
2025-11-20 13:19:39,586:INFO:Starting cross validation
2025-11-20 13:19:39,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:40,336:INFO:Calculating mean and std
2025-11-20 13:19:40,338:INFO:Creating metrics dataframe
2025-11-20 13:19:40,340:INFO:Uploading results into container
2025-11-20 13:19:40,340:INFO:Uploading model into container now
2025-11-20 13:19:40,341:INFO:_master_model_container: 12
2025-11-20 13:19:40,341:INFO:_display_container: 2
2025-11-20 13:19:40,342:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-20 13:19:40,342:INFO:create_model() successfully completed......................................
2025-11-20 13:19:40,456:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:40,456:INFO:Creating metrics dataframe
2025-11-20 13:19:40,466:INFO:Initializing Extreme Gradient Boosting
2025-11-20 13:19:40,466:INFO:Total runtime is 0.3008613506952922 minutes
2025-11-20 13:19:40,469:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:40,469:INFO:Initializing create_model()
2025-11-20 13:19:40,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:40,469:INFO:Checking exceptions
2025-11-20 13:19:40,471:INFO:Importing libraries
2025-11-20 13:19:40,471:INFO:Copying training dataset
2025-11-20 13:19:40,481:INFO:Defining folds
2025-11-20 13:19:40,481:INFO:Declaring metric variables
2025-11-20 13:19:40,486:INFO:Importing untrained model
2025-11-20 13:19:40,490:INFO:Extreme Gradient Boosting Imported successfully
2025-11-20 13:19:40,497:INFO:Starting cross validation
2025-11-20 13:19:40,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:41,610:INFO:Calculating mean and std
2025-11-20 13:19:41,612:INFO:Creating metrics dataframe
2025-11-20 13:19:41,613:INFO:Uploading results into container
2025-11-20 13:19:41,613:INFO:Uploading model into container now
2025-11-20 13:19:41,613:INFO:_master_model_container: 13
2025-11-20 13:19:41,615:INFO:_display_container: 2
2025-11-20 13:19:41,615:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-20 13:19:41,615:INFO:create_model() successfully completed......................................
2025-11-20 13:19:41,737:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:41,737:INFO:Creating metrics dataframe
2025-11-20 13:19:41,748:INFO:Initializing Light Gradient Boosting Machine
2025-11-20 13:19:41,748:INFO:Total runtime is 0.3222287098566691 minutes
2025-11-20 13:19:41,752:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:41,752:INFO:Initializing create_model()
2025-11-20 13:19:41,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:41,753:INFO:Checking exceptions
2025-11-20 13:19:41,753:INFO:Importing libraries
2025-11-20 13:19:41,753:INFO:Copying training dataset
2025-11-20 13:19:41,763:INFO:Defining folds
2025-11-20 13:19:41,763:INFO:Declaring metric variables
2025-11-20 13:19:41,766:INFO:Importing untrained model
2025-11-20 13:19:41,772:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-20 13:19:41,778:INFO:Starting cross validation
2025-11-20 13:19:41,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:44,379:INFO:Calculating mean and std
2025-11-20 13:19:44,382:INFO:Creating metrics dataframe
2025-11-20 13:19:44,385:INFO:Uploading results into container
2025-11-20 13:19:44,386:INFO:Uploading model into container now
2025-11-20 13:19:44,387:INFO:_master_model_container: 14
2025-11-20 13:19:44,387:INFO:_display_container: 2
2025-11-20 13:19:44,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-20 13:19:44,390:INFO:create_model() successfully completed......................................
2025-11-20 13:19:44,525:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:44,525:INFO:Creating metrics dataframe
2025-11-20 13:19:44,536:INFO:Initializing Dummy Classifier
2025-11-20 13:19:44,536:INFO:Total runtime is 0.36870455741882324 minutes
2025-11-20 13:19:44,539:INFO:SubProcess create_model() called ==================================
2025-11-20 13:19:44,539:INFO:Initializing create_model()
2025-11-20 13:19:44,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0351E850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:44,540:INFO:Checking exceptions
2025-11-20 13:19:44,540:INFO:Importing libraries
2025-11-20 13:19:44,540:INFO:Copying training dataset
2025-11-20 13:19:44,551:INFO:Defining folds
2025-11-20 13:19:44,551:INFO:Declaring metric variables
2025-11-20 13:19:44,555:INFO:Importing untrained model
2025-11-20 13:19:44,559:INFO:Dummy Classifier Imported successfully
2025-11-20 13:19:44,567:INFO:Starting cross validation
2025-11-20 13:19:44,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:44,673:INFO:Calculating mean and std
2025-11-20 13:19:44,675:INFO:Creating metrics dataframe
2025-11-20 13:19:44,677:INFO:Uploading results into container
2025-11-20 13:19:44,677:INFO:Uploading model into container now
2025-11-20 13:19:44,678:INFO:_master_model_container: 15
2025-11-20 13:19:44,678:INFO:_display_container: 2
2025-11-20 13:19:44,678:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-20 13:19:44,678:INFO:create_model() successfully completed......................................
2025-11-20 13:19:44,799:INFO:SubProcess create_model() end ==================================
2025-11-20 13:19:44,799:INFO:Creating metrics dataframe
2025-11-20 13:19:44,831:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-20 13:19:44,840:INFO:Initializing create_model()
2025-11-20 13:19:44,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:44,841:INFO:Checking exceptions
2025-11-20 13:19:44,842:INFO:Importing libraries
2025-11-20 13:19:44,842:INFO:Copying training dataset
2025-11-20 13:19:44,851:INFO:Defining folds
2025-11-20 13:19:44,851:INFO:Declaring metric variables
2025-11-20 13:19:44,852:INFO:Importing untrained model
2025-11-20 13:19:44,852:INFO:Declaring custom model
2025-11-20 13:19:44,853:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:19:44,854:INFO:Cross validation set to False
2025-11-20 13:19:44,854:INFO:Fitting Model
2025-11-20 13:19:45,993:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:19:45,994:INFO:create_model() successfully completed......................................
2025-11-20 13:19:46,258:INFO:_master_model_container: 15
2025-11-20 13:19:46,258:INFO:_display_container: 2
2025-11-20 13:19:46,258:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:19:46,259:INFO:compare_models() successfully completed......................................
2025-11-20 13:19:46,327:INFO:Initializing create_model()
2025-11-20 13:19:46,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:19:46,327:INFO:Checking exceptions
2025-11-20 13:19:46,344:INFO:Importing libraries
2025-11-20 13:19:46,344:INFO:Copying training dataset
2025-11-20 13:19:46,356:INFO:Defining folds
2025-11-20 13:19:46,356:INFO:Declaring metric variables
2025-11-20 13:19:46,359:INFO:Importing untrained model
2025-11-20 13:19:46,363:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:19:46,371:INFO:Starting cross validation
2025-11-20 13:19:46,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:19:47,626:INFO:Calculating mean and std
2025-11-20 13:19:47,627:INFO:Creating metrics dataframe
2025-11-20 13:19:47,633:INFO:Finalizing model
2025-11-20 13:19:48,826:INFO:Uploading results into container
2025-11-20 13:19:48,827:INFO:Uploading model into container now
2025-11-20 13:19:48,839:INFO:_master_model_container: 16
2025-11-20 13:19:48,839:INFO:_display_container: 3
2025-11-20 13:19:48,839:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:19:48,839:INFO:create_model() successfully completed......................................
2025-11-20 13:19:48,962:INFO:Initializing tune_model()
2025-11-20 13:19:48,962:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-20 13:19:48,962:INFO:Checking exceptions
2025-11-20 13:19:48,982:INFO:Copying training dataset
2025-11-20 13:19:48,991:INFO:Checking base model
2025-11-20 13:19:48,991:INFO:Base model : Gradient Boosting Classifier
2025-11-20 13:19:48,997:INFO:Declaring metric variables
2025-11-20 13:19:49,001:INFO:Defining Hyperparameters
2025-11-20 13:19:49,126:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-20 13:19:49,126:INFO:Tuning with n_jobs=-1
2025-11-20 13:19:49,126:INFO:Initializing RandomizedSearchCV
2025-11-20 13:20:12,878:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-20 13:20:12,879:INFO:Hyperparameter search completed
2025-11-20 13:20:12,879:INFO:SubProcess create_model() called ==================================
2025-11-20 13:20:12,880:INFO:Initializing create_model()
2025-11-20 13:20:12,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD55B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-20 13:20:12,880:INFO:Checking exceptions
2025-11-20 13:20:12,881:INFO:Importing libraries
2025-11-20 13:20:12,881:INFO:Copying training dataset
2025-11-20 13:20:12,891:INFO:Defining folds
2025-11-20 13:20:12,892:INFO:Declaring metric variables
2025-11-20 13:20:12,895:INFO:Importing untrained model
2025-11-20 13:20:12,895:INFO:Declaring custom model
2025-11-20 13:20:12,900:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:20:12,907:INFO:Starting cross validation
2025-11-20 13:20:12,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:20:14,019:INFO:Calculating mean and std
2025-11-20 13:20:14,021:INFO:Creating metrics dataframe
2025-11-20 13:20:14,027:INFO:Finalizing model
2025-11-20 13:20:15,055:INFO:Uploading results into container
2025-11-20 13:20:15,056:INFO:Uploading model into container now
2025-11-20 13:20:15,057:INFO:_master_model_container: 17
2025-11-20 13:20:15,057:INFO:_display_container: 4
2025-11-20 13:20:15,058:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:20:15,058:INFO:create_model() successfully completed......................................
2025-11-20 13:20:15,258:INFO:SubProcess create_model() end ==================================
2025-11-20 13:20:15,258:INFO:choose_better activated
2025-11-20 13:20:15,262:INFO:SubProcess create_model() called ==================================
2025-11-20 13:20:15,263:INFO:Initializing create_model()
2025-11-20 13:20:15,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:20:15,263:INFO:Checking exceptions
2025-11-20 13:20:15,264:INFO:Importing libraries
2025-11-20 13:20:15,265:INFO:Copying training dataset
2025-11-20 13:20:15,275:INFO:Defining folds
2025-11-20 13:20:15,275:INFO:Declaring metric variables
2025-11-20 13:20:15,275:INFO:Importing untrained model
2025-11-20 13:20:15,275:INFO:Declaring custom model
2025-11-20 13:20:15,276:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:20:15,276:INFO:Starting cross validation
2025-11-20 13:20:15,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:20:16,546:INFO:Calculating mean and std
2025-11-20 13:20:16,546:INFO:Creating metrics dataframe
2025-11-20 13:20:16,548:INFO:Finalizing model
2025-11-20 13:20:17,700:INFO:Uploading results into container
2025-11-20 13:20:17,701:INFO:Uploading model into container now
2025-11-20 13:20:17,702:INFO:_master_model_container: 18
2025-11-20 13:20:17,702:INFO:_display_container: 5
2025-11-20 13:20:17,702:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:20:17,702:INFO:create_model() successfully completed......................................
2025-11-20 13:20:17,893:INFO:SubProcess create_model() end ==================================
2025-11-20 13:20:17,894:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9418
2025-11-20 13:20:17,895:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.942
2025-11-20 13:20:17,895:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-20 13:20:17,895:INFO:choose_better completed
2025-11-20 13:20:17,908:INFO:_master_model_container: 18
2025-11-20 13:20:17,908:INFO:_display_container: 4
2025-11-20 13:20:17,909:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:20:17,909:INFO:tune_model() successfully completed......................................
2025-11-20 13:20:18,190:INFO:Initializing plot_model()
2025-11-20 13:20:18,190:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 13:20:18,190:INFO:Checking exceptions
2025-11-20 13:20:18,199:INFO:Preloading libraries
2025-11-20 13:20:18,210:INFO:Copying training dataset
2025-11-20 13:20:18,210:INFO:Plot type: confusion_matrix
2025-11-20 13:20:18,371:INFO:Fitting Model
2025-11-20 13:20:18,390:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-20 13:20:18,390:INFO:Scoring test/hold-out set
2025-11-20 13:20:18,553:INFO:Visual Rendered Successfully
2025-11-20 13:20:18,741:INFO:plot_model() successfully completed......................................
2025-11-20 13:32:54,467:INFO:Initializing plot_model()
2025-11-20 13:32:54,467:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDF132D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 13:32:54,468:INFO:Checking exceptions
2025-11-20 13:32:54,477:INFO:Preloading libraries
2025-11-20 13:32:54,485:INFO:Copying training dataset
2025-11-20 13:32:54,485:INFO:Plot type: feature
2025-11-20 13:32:54,486:WARNING:No coef_ found. Trying feature_importances_
2025-11-20 13:32:54,748:INFO:Visual Rendered Successfully
2025-11-20 13:32:54,912:INFO:plot_model() successfully completed......................................
2025-11-20 13:34:34,136:INFO:PyCaret ClassificationExperiment
2025-11-20 13:34:34,137:INFO:Logging name: clf-default-name
2025-11-20 13:34:34,137:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-20 13:34:34,137:INFO:version 3.3.2
2025-11-20 13:34:34,137:INFO:Initializing setup()
2025-11-20 13:34:34,137:INFO:self.USI: 52f1
2025-11-20 13:34:34,137:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-20 13:34:34,137:INFO:Checking environment
2025-11-20 13:34:34,137:INFO:python_version: 3.11.9
2025-11-20 13:34:34,137:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-20 13:34:34,137:INFO:machine: AMD64
2025-11-20 13:34:34,137:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-20 13:34:34,138:INFO:Memory: svmem(total=16440479744, available=4363112448, percent=73.5, used=12077367296, free=4363112448)
2025-11-20 13:34:34,138:INFO:Physical Core: 8
2025-11-20 13:34:34,138:INFO:Logical Core: 16
2025-11-20 13:34:34,138:INFO:Checking libraries
2025-11-20 13:34:34,138:INFO:System:
2025-11-20 13:34:34,138:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-20 13:34:34,138:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-20 13:34:34,138:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-20 13:34:34,138:INFO:PyCaret required dependencies:
2025-11-20 13:34:34,138:INFO:                 pip: 24.0
2025-11-20 13:34:34,138:INFO:          setuptools: 65.5.0
2025-11-20 13:34:34,138:INFO:             pycaret: 3.3.2
2025-11-20 13:34:34,138:INFO:             IPython: 9.0.2
2025-11-20 13:34:34,138:INFO:          ipywidgets: 8.1.7
2025-11-20 13:34:34,138:INFO:                tqdm: 4.67.1
2025-11-20 13:34:34,138:INFO:               numpy: 1.26.4
2025-11-20 13:34:34,138:INFO:              pandas: 2.1.4
2025-11-20 13:34:34,138:INFO:              jinja2: 3.1.6
2025-11-20 13:34:34,138:INFO:               scipy: 1.11.4
2025-11-20 13:34:34,138:INFO:              joblib: 1.3.2
2025-11-20 13:34:34,138:INFO:             sklearn: 1.4.2
2025-11-20 13:34:34,138:INFO:                pyod: 2.0.5
2025-11-20 13:34:34,138:INFO:            imblearn: 0.14.0
2025-11-20 13:34:34,139:INFO:   category_encoders: 2.7.0
2025-11-20 13:34:34,139:INFO:            lightgbm: 4.6.0
2025-11-20 13:34:34,139:INFO:               numba: 0.61.2
2025-11-20 13:34:34,139:INFO:            requests: 2.32.5
2025-11-20 13:34:34,139:INFO:          matplotlib: 3.7.5
2025-11-20 13:34:34,139:INFO:          scikitplot: 0.3.7
2025-11-20 13:34:34,139:INFO:         yellowbrick: 1.5
2025-11-20 13:34:34,139:INFO:              plotly: 6.3.0
2025-11-20 13:34:34,139:INFO:    plotly-resampler: Not installed
2025-11-20 13:34:34,139:INFO:             kaleido: 1.1.0
2025-11-20 13:34:34,139:INFO:           schemdraw: 0.15
2025-11-20 13:34:34,139:INFO:         statsmodels: 0.14.5
2025-11-20 13:34:34,139:INFO:              sktime: 0.26.0
2025-11-20 13:34:34,139:INFO:               tbats: 1.1.3
2025-11-20 13:34:34,139:INFO:            pmdarima: 2.0.4
2025-11-20 13:34:34,139:INFO:              psutil: 7.0.0
2025-11-20 13:34:34,139:INFO:          markupsafe: 3.0.2
2025-11-20 13:34:34,139:INFO:             pickle5: Not installed
2025-11-20 13:34:34,139:INFO:         cloudpickle: 3.1.1
2025-11-20 13:34:34,139:INFO:         deprecation: 2.1.0
2025-11-20 13:34:34,139:INFO:              xxhash: 3.5.0
2025-11-20 13:34:34,139:INFO:           wurlitzer: Not installed
2025-11-20 13:34:34,139:INFO:PyCaret optional dependencies:
2025-11-20 13:34:34,139:INFO:                shap: 0.48.0
2025-11-20 13:34:34,140:INFO:           interpret: Not installed
2025-11-20 13:34:34,140:INFO:                umap: 0.5.7
2025-11-20 13:34:34,140:INFO:     ydata_profiling: Not installed
2025-11-20 13:34:34,140:INFO:  explainerdashboard: Not installed
2025-11-20 13:34:34,140:INFO:             autoviz: Not installed
2025-11-20 13:34:34,140:INFO:           fairlearn: Not installed
2025-11-20 13:34:34,140:INFO:          deepchecks: Not installed
2025-11-20 13:34:34,140:INFO:             xgboost: 3.0.5
2025-11-20 13:34:34,140:INFO:            catboost: Not installed
2025-11-20 13:34:34,140:INFO:              kmodes: Not installed
2025-11-20 13:34:34,140:INFO:             mlxtend: Not installed
2025-11-20 13:34:34,140:INFO:       statsforecast: Not installed
2025-11-20 13:34:34,140:INFO:        tune_sklearn: Not installed
2025-11-20 13:34:34,140:INFO:                 ray: Not installed
2025-11-20 13:34:34,140:INFO:            hyperopt: Not installed
2025-11-20 13:34:34,140:INFO:              optuna: 4.5.0
2025-11-20 13:34:34,140:INFO:               skopt: Not installed
2025-11-20 13:34:34,140:INFO:              mlflow: Not installed
2025-11-20 13:34:34,140:INFO:              gradio: Not installed
2025-11-20 13:34:34,140:INFO:             fastapi: Not installed
2025-11-20 13:34:34,140:INFO:             uvicorn: Not installed
2025-11-20 13:34:34,140:INFO:              m2cgen: Not installed
2025-11-20 13:34:34,140:INFO:           evidently: Not installed
2025-11-20 13:34:34,140:INFO:               fugue: Not installed
2025-11-20 13:34:34,140:INFO:           streamlit: Not installed
2025-11-20 13:34:34,140:INFO:             prophet: Not installed
2025-11-20 13:34:34,140:INFO:None
2025-11-20 13:34:34,141:INFO:Set up data.
2025-11-20 13:34:34,152:INFO:Set up folding strategy.
2025-11-20 13:34:34,152:INFO:Set up train/test split.
2025-11-20 13:34:34,164:INFO:Set up index.
2025-11-20 13:34:34,164:INFO:Assigning column types.
2025-11-20 13:34:34,172:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-20 13:34:34,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,252:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,346:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,351:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-20 13:34:34,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,445:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-20 13:34:34,568:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,571:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-20 13:34:34,654:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,737:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:34,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:34,742:INFO:Preparing preprocessing pipeline...
2025-11-20 13:34:34,744:INFO:Set up date feature engineering.
2025-11-20 13:34:34,744:INFO:Set up simple imputation.
2025-11-20 13:34:34,809:INFO:Finished creating preprocessing pipeline.
2025-11-20 13:34:34,813:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-20 13:34:34,814:INFO:Creating final display dataframe.
2025-11-20 13:34:34,983:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 19)
5   Transformed train set shape           (5961, 19)
6    Transformed test set shape           (2555, 19)
7               Ignore features                    2
8              Numeric features                   15
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 52f1
2025-11-20 13:34:35,080:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:35,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:35,170:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-20 13:34:35,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-20 13:34:35,175:INFO:setup() successfully completed in 1.06s...............
2025-11-20 13:34:35,185:INFO:Initializing compare_models()
2025-11-20 13:34:35,185:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-20 13:34:35,185:INFO:Checking exceptions
2025-11-20 13:34:35,192:INFO:Preparing display monitor
2025-11-20 13:34:35,217:INFO:Initializing Logistic Regression
2025-11-20 13:34:35,218:INFO:Total runtime is 1.6697247823079427e-05 minutes
2025-11-20 13:34:35,223:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:35,224:INFO:Initializing create_model()
2025-11-20 13:34:35,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:35,224:INFO:Checking exceptions
2025-11-20 13:34:35,224:INFO:Importing libraries
2025-11-20 13:34:35,224:INFO:Copying training dataset
2025-11-20 13:34:35,239:INFO:Defining folds
2025-11-20 13:34:35,239:INFO:Declaring metric variables
2025-11-20 13:34:35,244:INFO:Importing untrained model
2025-11-20 13:34:35,249:INFO:Logistic Regression Imported successfully
2025-11-20 13:34:35,260:INFO:Starting cross validation
2025-11-20 13:34:35,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:44,445:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,455:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,455:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,469:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,476:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,478:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,478:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,488:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,494:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,497:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 13:34:44,546:INFO:Calculating mean and std
2025-11-20 13:34:44,548:INFO:Creating metrics dataframe
2025-11-20 13:34:44,552:INFO:Uploading results into container
2025-11-20 13:34:44,553:INFO:Uploading model into container now
2025-11-20 13:34:44,554:INFO:_master_model_container: 1
2025-11-20 13:34:44,554:INFO:_display_container: 2
2025-11-20 13:34:44,555:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 13:34:44,555:INFO:create_model() successfully completed......................................
2025-11-20 13:34:44,687:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:44,688:INFO:Creating metrics dataframe
2025-11-20 13:34:44,696:INFO:Initializing K Neighbors Classifier
2025-11-20 13:34:44,696:INFO:Total runtime is 0.1579925537109375 minutes
2025-11-20 13:34:44,700:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:44,700:INFO:Initializing create_model()
2025-11-20 13:34:44,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:44,700:INFO:Checking exceptions
2025-11-20 13:34:44,701:INFO:Importing libraries
2025-11-20 13:34:44,701:INFO:Copying training dataset
2025-11-20 13:34:44,711:INFO:Defining folds
2025-11-20 13:34:44,711:INFO:Declaring metric variables
2025-11-20 13:34:44,717:INFO:Importing untrained model
2025-11-20 13:34:44,721:INFO:K Neighbors Classifier Imported successfully
2025-11-20 13:34:44,731:INFO:Starting cross validation
2025-11-20 13:34:44,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:49,064:INFO:Calculating mean and std
2025-11-20 13:34:49,066:INFO:Creating metrics dataframe
2025-11-20 13:34:49,069:INFO:Uploading results into container
2025-11-20 13:34:49,070:INFO:Uploading model into container now
2025-11-20 13:34:49,071:INFO:_master_model_container: 2
2025-11-20 13:34:49,071:INFO:_display_container: 2
2025-11-20 13:34:49,072:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-20 13:34:49,073:INFO:create_model() successfully completed......................................
2025-11-20 13:34:49,196:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:49,196:INFO:Creating metrics dataframe
2025-11-20 13:34:49,203:INFO:Initializing Naive Bayes
2025-11-20 13:34:49,203:INFO:Total runtime is 0.23311244249343874 minutes
2025-11-20 13:34:49,206:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:49,207:INFO:Initializing create_model()
2025-11-20 13:34:49,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:49,207:INFO:Checking exceptions
2025-11-20 13:34:49,207:INFO:Importing libraries
2025-11-20 13:34:49,207:INFO:Copying training dataset
2025-11-20 13:34:49,217:INFO:Defining folds
2025-11-20 13:34:49,217:INFO:Declaring metric variables
2025-11-20 13:34:49,222:INFO:Importing untrained model
2025-11-20 13:34:49,227:INFO:Naive Bayes Imported successfully
2025-11-20 13:34:49,234:INFO:Starting cross validation
2025-11-20 13:34:49,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:49,344:INFO:Calculating mean and std
2025-11-20 13:34:49,346:INFO:Creating metrics dataframe
2025-11-20 13:34:49,348:INFO:Uploading results into container
2025-11-20 13:34:49,349:INFO:Uploading model into container now
2025-11-20 13:34:49,349:INFO:_master_model_container: 3
2025-11-20 13:34:49,350:INFO:_display_container: 2
2025-11-20 13:34:49,350:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-20 13:34:49,350:INFO:create_model() successfully completed......................................
2025-11-20 13:34:49,459:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:49,473:INFO:Creating metrics dataframe
2025-11-20 13:34:49,481:INFO:Initializing Decision Tree Classifier
2025-11-20 13:34:49,481:INFO:Total runtime is 0.2377334793408712 minutes
2025-11-20 13:34:49,484:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:49,485:INFO:Initializing create_model()
2025-11-20 13:34:49,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:49,485:INFO:Checking exceptions
2025-11-20 13:34:49,485:INFO:Importing libraries
2025-11-20 13:34:49,485:INFO:Copying training dataset
2025-11-20 13:34:49,496:INFO:Defining folds
2025-11-20 13:34:49,497:INFO:Declaring metric variables
2025-11-20 13:34:49,501:INFO:Importing untrained model
2025-11-20 13:34:49,505:INFO:Decision Tree Classifier Imported successfully
2025-11-20 13:34:49,512:INFO:Starting cross validation
2025-11-20 13:34:49,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:49,659:INFO:Calculating mean and std
2025-11-20 13:34:49,661:INFO:Creating metrics dataframe
2025-11-20 13:34:49,663:INFO:Uploading results into container
2025-11-20 13:34:49,664:INFO:Uploading model into container now
2025-11-20 13:34:49,664:INFO:_master_model_container: 4
2025-11-20 13:34:49,664:INFO:_display_container: 2
2025-11-20 13:34:49,665:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-20 13:34:49,665:INFO:create_model() successfully completed......................................
2025-11-20 13:34:49,777:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:49,777:INFO:Creating metrics dataframe
2025-11-20 13:34:49,784:INFO:Initializing SVM - Linear Kernel
2025-11-20 13:34:49,785:INFO:Total runtime is 0.2428009072939555 minutes
2025-11-20 13:34:49,789:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:49,789:INFO:Initializing create_model()
2025-11-20 13:34:49,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:49,790:INFO:Checking exceptions
2025-11-20 13:34:49,790:INFO:Importing libraries
2025-11-20 13:34:49,790:INFO:Copying training dataset
2025-11-20 13:34:49,800:INFO:Defining folds
2025-11-20 13:34:49,800:INFO:Declaring metric variables
2025-11-20 13:34:49,804:INFO:Importing untrained model
2025-11-20 13:34:49,808:INFO:SVM - Linear Kernel Imported successfully
2025-11-20 13:34:49,815:INFO:Starting cross validation
2025-11-20 13:34:49,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:49,995:INFO:Calculating mean and std
2025-11-20 13:34:49,997:INFO:Creating metrics dataframe
2025-11-20 13:34:49,998:INFO:Uploading results into container
2025-11-20 13:34:49,999:INFO:Uploading model into container now
2025-11-20 13:34:50,000:INFO:_master_model_container: 5
2025-11-20 13:34:50,000:INFO:_display_container: 2
2025-11-20 13:34:50,001:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-20 13:34:50,001:INFO:create_model() successfully completed......................................
2025-11-20 13:34:50,115:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:50,115:INFO:Creating metrics dataframe
2025-11-20 13:34:50,123:INFO:Initializing Ridge Classifier
2025-11-20 13:34:50,123:INFO:Total runtime is 0.24843788941701256 minutes
2025-11-20 13:34:50,127:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:50,128:INFO:Initializing create_model()
2025-11-20 13:34:50,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:50,128:INFO:Checking exceptions
2025-11-20 13:34:50,128:INFO:Importing libraries
2025-11-20 13:34:50,128:INFO:Copying training dataset
2025-11-20 13:34:50,139:INFO:Defining folds
2025-11-20 13:34:50,139:INFO:Declaring metric variables
2025-11-20 13:34:50,142:INFO:Importing untrained model
2025-11-20 13:34:50,147:INFO:Ridge Classifier Imported successfully
2025-11-20 13:34:50,154:INFO:Starting cross validation
2025-11-20 13:34:50,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:50,262:INFO:Calculating mean and std
2025-11-20 13:34:50,264:INFO:Creating metrics dataframe
2025-11-20 13:34:50,266:INFO:Uploading results into container
2025-11-20 13:34:50,267:INFO:Uploading model into container now
2025-11-20 13:34:50,267:INFO:_master_model_container: 6
2025-11-20 13:34:50,268:INFO:_display_container: 2
2025-11-20 13:34:50,268:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-20 13:34:50,268:INFO:create_model() successfully completed......................................
2025-11-20 13:34:50,379:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:50,379:INFO:Creating metrics dataframe
2025-11-20 13:34:50,387:INFO:Initializing Random Forest Classifier
2025-11-20 13:34:50,388:INFO:Total runtime is 0.252860156695048 minutes
2025-11-20 13:34:50,391:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:50,392:INFO:Initializing create_model()
2025-11-20 13:34:50,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:50,392:INFO:Checking exceptions
2025-11-20 13:34:50,392:INFO:Importing libraries
2025-11-20 13:34:50,392:INFO:Copying training dataset
2025-11-20 13:34:50,402:INFO:Defining folds
2025-11-20 13:34:50,402:INFO:Declaring metric variables
2025-11-20 13:34:50,406:INFO:Importing untrained model
2025-11-20 13:34:50,410:INFO:Random Forest Classifier Imported successfully
2025-11-20 13:34:50,417:INFO:Starting cross validation
2025-11-20 13:34:50,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:51,423:INFO:Calculating mean and std
2025-11-20 13:34:51,424:INFO:Creating metrics dataframe
2025-11-20 13:34:51,427:INFO:Uploading results into container
2025-11-20 13:34:51,428:INFO:Uploading model into container now
2025-11-20 13:34:51,428:INFO:_master_model_container: 7
2025-11-20 13:34:51,428:INFO:_display_container: 2
2025-11-20 13:34:51,430:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 13:34:51,430:INFO:create_model() successfully completed......................................
2025-11-20 13:34:51,553:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:51,553:INFO:Creating metrics dataframe
2025-11-20 13:34:51,563:INFO:Initializing Quadratic Discriminant Analysis
2025-11-20 13:34:51,563:INFO:Total runtime is 0.2724417726198832 minutes
2025-11-20 13:34:51,566:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:51,567:INFO:Initializing create_model()
2025-11-20 13:34:51,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:51,567:INFO:Checking exceptions
2025-11-20 13:34:51,567:INFO:Importing libraries
2025-11-20 13:34:51,568:INFO:Copying training dataset
2025-11-20 13:34:51,579:INFO:Defining folds
2025-11-20 13:34:51,579:INFO:Declaring metric variables
2025-11-20 13:34:51,583:INFO:Importing untrained model
2025-11-20 13:34:51,587:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-20 13:34:51,594:INFO:Starting cross validation
2025-11-20 13:34:51,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:51,651:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,651:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,653:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,654:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,657:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,658:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,661:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,663:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-20 13:34:51,701:INFO:Calculating mean and std
2025-11-20 13:34:51,704:INFO:Creating metrics dataframe
2025-11-20 13:34:51,706:INFO:Uploading results into container
2025-11-20 13:34:51,707:INFO:Uploading model into container now
2025-11-20 13:34:51,707:INFO:_master_model_container: 8
2025-11-20 13:34:51,707:INFO:_display_container: 2
2025-11-20 13:34:51,708:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-20 13:34:51,708:INFO:create_model() successfully completed......................................
2025-11-20 13:34:51,820:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:51,820:INFO:Creating metrics dataframe
2025-11-20 13:34:51,829:INFO:Initializing Ada Boost Classifier
2025-11-20 13:34:51,830:INFO:Total runtime is 0.27686477502187096 minutes
2025-11-20 13:34:51,833:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:51,833:INFO:Initializing create_model()
2025-11-20 13:34:51,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:51,834:INFO:Checking exceptions
2025-11-20 13:34:51,834:INFO:Importing libraries
2025-11-20 13:34:51,834:INFO:Copying training dataset
2025-11-20 13:34:51,845:INFO:Defining folds
2025-11-20 13:34:51,845:INFO:Declaring metric variables
2025-11-20 13:34:51,849:INFO:Importing untrained model
2025-11-20 13:34:51,855:INFO:Ada Boost Classifier Imported successfully
2025-11-20 13:34:51,862:INFO:Starting cross validation
2025-11-20 13:34:51,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,926:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:51,929:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-20 13:34:52,366:INFO:Calculating mean and std
2025-11-20 13:34:52,368:INFO:Creating metrics dataframe
2025-11-20 13:34:52,371:INFO:Uploading results into container
2025-11-20 13:34:52,371:INFO:Uploading model into container now
2025-11-20 13:34:52,372:INFO:_master_model_container: 9
2025-11-20 13:34:52,372:INFO:_display_container: 2
2025-11-20 13:34:52,373:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-20 13:34:52,373:INFO:create_model() successfully completed......................................
2025-11-20 13:34:52,486:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:52,486:INFO:Creating metrics dataframe
2025-11-20 13:34:52,496:INFO:Initializing Gradient Boosting Classifier
2025-11-20 13:34:52,496:INFO:Total runtime is 0.2879803737004598 minutes
2025-11-20 13:34:52,500:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:52,500:INFO:Initializing create_model()
2025-11-20 13:34:52,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:52,501:INFO:Checking exceptions
2025-11-20 13:34:52,501:INFO:Importing libraries
2025-11-20 13:34:52,501:INFO:Copying training dataset
2025-11-20 13:34:52,513:INFO:Defining folds
2025-11-20 13:34:52,513:INFO:Declaring metric variables
2025-11-20 13:34:52,519:INFO:Importing untrained model
2025-11-20 13:34:52,524:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:34:52,534:INFO:Starting cross validation
2025-11-20 13:34:52,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:53,757:INFO:Calculating mean and std
2025-11-20 13:34:53,759:INFO:Creating metrics dataframe
2025-11-20 13:34:53,761:INFO:Uploading results into container
2025-11-20 13:34:53,762:INFO:Uploading model into container now
2025-11-20 13:34:53,762:INFO:_master_model_container: 10
2025-11-20 13:34:53,762:INFO:_display_container: 2
2025-11-20 13:34:53,763:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:34:53,763:INFO:create_model() successfully completed......................................
2025-11-20 13:34:53,879:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:53,880:INFO:Creating metrics dataframe
2025-11-20 13:34:53,890:INFO:Initializing Linear Discriminant Analysis
2025-11-20 13:34:53,891:INFO:Total runtime is 0.3112379829088847 minutes
2025-11-20 13:34:53,894:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:53,895:INFO:Initializing create_model()
2025-11-20 13:34:53,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:53,895:INFO:Checking exceptions
2025-11-20 13:34:53,895:INFO:Importing libraries
2025-11-20 13:34:53,895:INFO:Copying training dataset
2025-11-20 13:34:53,906:INFO:Defining folds
2025-11-20 13:34:53,906:INFO:Declaring metric variables
2025-11-20 13:34:53,910:INFO:Importing untrained model
2025-11-20 13:34:53,915:INFO:Linear Discriminant Analysis Imported successfully
2025-11-20 13:34:53,922:INFO:Starting cross validation
2025-11-20 13:34:53,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:54,032:INFO:Calculating mean and std
2025-11-20 13:34:54,033:INFO:Creating metrics dataframe
2025-11-20 13:34:54,034:INFO:Uploading results into container
2025-11-20 13:34:54,035:INFO:Uploading model into container now
2025-11-20 13:34:54,035:INFO:_master_model_container: 11
2025-11-20 13:34:54,036:INFO:_display_container: 2
2025-11-20 13:34:54,036:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-20 13:34:54,036:INFO:create_model() successfully completed......................................
2025-11-20 13:34:54,148:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:54,149:INFO:Creating metrics dataframe
2025-11-20 13:34:54,157:INFO:Initializing Extra Trees Classifier
2025-11-20 13:34:54,158:INFO:Total runtime is 0.31569549242655437 minutes
2025-11-20 13:34:54,163:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:54,163:INFO:Initializing create_model()
2025-11-20 13:34:54,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:54,163:INFO:Checking exceptions
2025-11-20 13:34:54,163:INFO:Importing libraries
2025-11-20 13:34:54,163:INFO:Copying training dataset
2025-11-20 13:34:54,175:INFO:Defining folds
2025-11-20 13:34:54,175:INFO:Declaring metric variables
2025-11-20 13:34:54,179:INFO:Importing untrained model
2025-11-20 13:34:54,183:INFO:Extra Trees Classifier Imported successfully
2025-11-20 13:34:54,190:INFO:Starting cross validation
2025-11-20 13:34:54,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:55,039:INFO:Calculating mean and std
2025-11-20 13:34:55,041:INFO:Creating metrics dataframe
2025-11-20 13:34:55,043:INFO:Uploading results into container
2025-11-20 13:34:55,043:INFO:Uploading model into container now
2025-11-20 13:34:55,044:INFO:_master_model_container: 12
2025-11-20 13:34:55,044:INFO:_display_container: 2
2025-11-20 13:34:55,044:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-20 13:34:55,044:INFO:create_model() successfully completed......................................
2025-11-20 13:34:55,158:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:55,158:INFO:Creating metrics dataframe
2025-11-20 13:34:55,169:INFO:Initializing Extreme Gradient Boosting
2025-11-20 13:34:55,169:INFO:Total runtime is 0.3325446089108785 minutes
2025-11-20 13:34:55,173:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:55,174:INFO:Initializing create_model()
2025-11-20 13:34:55,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:55,174:INFO:Checking exceptions
2025-11-20 13:34:55,174:INFO:Importing libraries
2025-11-20 13:34:55,174:INFO:Copying training dataset
2025-11-20 13:34:55,184:INFO:Defining folds
2025-11-20 13:34:55,185:INFO:Declaring metric variables
2025-11-20 13:34:55,189:INFO:Importing untrained model
2025-11-20 13:34:55,193:INFO:Extreme Gradient Boosting Imported successfully
2025-11-20 13:34:55,200:INFO:Starting cross validation
2025-11-20 13:34:55,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:56,420:INFO:Calculating mean and std
2025-11-20 13:34:56,422:INFO:Creating metrics dataframe
2025-11-20 13:34:56,424:INFO:Uploading results into container
2025-11-20 13:34:56,425:INFO:Uploading model into container now
2025-11-20 13:34:56,425:INFO:_master_model_container: 13
2025-11-20 13:34:56,425:INFO:_display_container: 2
2025-11-20 13:34:56,426:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-20 13:34:56,426:INFO:create_model() successfully completed......................................
2025-11-20 13:34:56,544:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:56,544:INFO:Creating metrics dataframe
2025-11-20 13:34:56,555:INFO:Initializing Light Gradient Boosting Machine
2025-11-20 13:34:56,556:INFO:Total runtime is 0.35564754406611127 minutes
2025-11-20 13:34:56,560:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:56,560:INFO:Initializing create_model()
2025-11-20 13:34:56,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:56,560:INFO:Checking exceptions
2025-11-20 13:34:56,560:INFO:Importing libraries
2025-11-20 13:34:56,560:INFO:Copying training dataset
2025-11-20 13:34:56,572:INFO:Defining folds
2025-11-20 13:34:56,572:INFO:Declaring metric variables
2025-11-20 13:34:56,576:INFO:Importing untrained model
2025-11-20 13:34:56,580:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-20 13:34:56,588:INFO:Starting cross validation
2025-11-20 13:34:56,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:59,166:INFO:Calculating mean and std
2025-11-20 13:34:59,169:INFO:Creating metrics dataframe
2025-11-20 13:34:59,173:INFO:Uploading results into container
2025-11-20 13:34:59,174:INFO:Uploading model into container now
2025-11-20 13:34:59,175:INFO:_master_model_container: 14
2025-11-20 13:34:59,175:INFO:_display_container: 2
2025-11-20 13:34:59,177:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-20 13:34:59,177:INFO:create_model() successfully completed......................................
2025-11-20 13:34:59,344:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:59,344:INFO:Creating metrics dataframe
2025-11-20 13:34:59,355:INFO:Initializing Dummy Classifier
2025-11-20 13:34:59,355:INFO:Total runtime is 0.4023113131523133 minutes
2025-11-20 13:34:59,360:INFO:SubProcess create_model() called ==================================
2025-11-20 13:34:59,360:INFO:Initializing create_model()
2025-11-20 13:34:59,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDD30310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:59,360:INFO:Checking exceptions
2025-11-20 13:34:59,360:INFO:Importing libraries
2025-11-20 13:34:59,361:INFO:Copying training dataset
2025-11-20 13:34:59,372:INFO:Defining folds
2025-11-20 13:34:59,372:INFO:Declaring metric variables
2025-11-20 13:34:59,377:INFO:Importing untrained model
2025-11-20 13:34:59,380:INFO:Dummy Classifier Imported successfully
2025-11-20 13:34:59,389:INFO:Starting cross validation
2025-11-20 13:34:59,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:34:59,485:INFO:Calculating mean and std
2025-11-20 13:34:59,487:INFO:Creating metrics dataframe
2025-11-20 13:34:59,489:INFO:Uploading results into container
2025-11-20 13:34:59,490:INFO:Uploading model into container now
2025-11-20 13:34:59,490:INFO:_master_model_container: 15
2025-11-20 13:34:59,490:INFO:_display_container: 2
2025-11-20 13:34:59,490:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-20 13:34:59,491:INFO:create_model() successfully completed......................................
2025-11-20 13:34:59,606:INFO:SubProcess create_model() end ==================================
2025-11-20 13:34:59,606:INFO:Creating metrics dataframe
2025-11-20 13:34:59,617:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-20 13:34:59,626:INFO:Initializing create_model()
2025-11-20 13:34:59,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:34:59,627:INFO:Checking exceptions
2025-11-20 13:34:59,628:INFO:Importing libraries
2025-11-20 13:34:59,629:INFO:Copying training dataset
2025-11-20 13:34:59,638:INFO:Defining folds
2025-11-20 13:34:59,638:INFO:Declaring metric variables
2025-11-20 13:34:59,638:INFO:Importing untrained model
2025-11-20 13:34:59,638:INFO:Declaring custom model
2025-11-20 13:34:59,639:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:34:59,639:INFO:Cross validation set to False
2025-11-20 13:34:59,639:INFO:Fitting Model
2025-11-20 13:35:00,825:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:00,825:INFO:create_model() successfully completed......................................
2025-11-20 13:35:01,115:INFO:_master_model_container: 15
2025-11-20 13:35:01,116:INFO:_display_container: 2
2025-11-20 13:35:01,116:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:01,116:INFO:compare_models() successfully completed......................................
2025-11-20 13:35:25,494:INFO:Initializing create_model()
2025-11-20 13:35:25,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:35:25,495:INFO:Checking exceptions
2025-11-20 13:35:25,520:INFO:Importing libraries
2025-11-20 13:35:25,520:INFO:Copying training dataset
2025-11-20 13:35:25,540:INFO:Defining folds
2025-11-20 13:35:25,540:INFO:Declaring metric variables
2025-11-20 13:35:25,547:INFO:Importing untrained model
2025-11-20 13:35:25,553:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:35:25,563:INFO:Starting cross validation
2025-11-20 13:35:25,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:35:26,994:INFO:Calculating mean and std
2025-11-20 13:35:26,996:INFO:Creating metrics dataframe
2025-11-20 13:35:27,004:INFO:Finalizing model
2025-11-20 13:35:28,148:INFO:Uploading results into container
2025-11-20 13:35:28,149:INFO:Uploading model into container now
2025-11-20 13:35:28,162:INFO:_master_model_container: 16
2025-11-20 13:35:28,162:INFO:_display_container: 3
2025-11-20 13:35:28,162:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:28,162:INFO:create_model() successfully completed......................................
2025-11-20 13:35:28,290:INFO:Initializing tune_model()
2025-11-20 13:35:28,290:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-20 13:35:28,290:INFO:Checking exceptions
2025-11-20 13:35:28,308:INFO:Copying training dataset
2025-11-20 13:35:28,314:INFO:Checking base model
2025-11-20 13:35:28,314:INFO:Base model : Gradient Boosting Classifier
2025-11-20 13:35:28,319:INFO:Declaring metric variables
2025-11-20 13:35:28,323:INFO:Defining Hyperparameters
2025-11-20 13:35:28,442:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-20 13:35:28,442:INFO:Tuning with n_jobs=-1
2025-11-20 13:35:28,442:INFO:Initializing RandomizedSearchCV
2025-11-20 13:35:53,097:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-20 13:35:53,099:INFO:Hyperparameter search completed
2025-11-20 13:35:53,099:INFO:SubProcess create_model() called ==================================
2025-11-20 13:35:53,100:INFO:Initializing create_model()
2025-11-20 13:35:53,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE030087D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-20 13:35:53,100:INFO:Checking exceptions
2025-11-20 13:35:53,101:INFO:Importing libraries
2025-11-20 13:35:53,101:INFO:Copying training dataset
2025-11-20 13:35:53,111:INFO:Defining folds
2025-11-20 13:35:53,111:INFO:Declaring metric variables
2025-11-20 13:35:53,115:INFO:Importing untrained model
2025-11-20 13:35:53,115:INFO:Declaring custom model
2025-11-20 13:35:53,120:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:35:53,127:INFO:Starting cross validation
2025-11-20 13:35:53,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:35:54,244:INFO:Calculating mean and std
2025-11-20 13:35:54,245:INFO:Creating metrics dataframe
2025-11-20 13:35:54,251:INFO:Finalizing model
2025-11-20 13:35:55,305:INFO:Uploading results into container
2025-11-20 13:35:55,306:INFO:Uploading model into container now
2025-11-20 13:35:55,307:INFO:_master_model_container: 17
2025-11-20 13:35:55,307:INFO:_display_container: 4
2025-11-20 13:35:55,308:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:55,308:INFO:create_model() successfully completed......................................
2025-11-20 13:35:55,444:INFO:SubProcess create_model() end ==================================
2025-11-20 13:35:55,444:INFO:choose_better activated
2025-11-20 13:35:55,448:INFO:SubProcess create_model() called ==================================
2025-11-20 13:35:55,448:INFO:Initializing create_model()
2025-11-20 13:35:55,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 13:35:55,449:INFO:Checking exceptions
2025-11-20 13:35:55,450:INFO:Importing libraries
2025-11-20 13:35:55,450:INFO:Copying training dataset
2025-11-20 13:35:55,459:INFO:Defining folds
2025-11-20 13:35:55,459:INFO:Declaring metric variables
2025-11-20 13:35:55,459:INFO:Importing untrained model
2025-11-20 13:35:55,459:INFO:Declaring custom model
2025-11-20 13:35:55,460:INFO:Gradient Boosting Classifier Imported successfully
2025-11-20 13:35:55,460:INFO:Starting cross validation
2025-11-20 13:35:55,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 13:35:56,724:INFO:Calculating mean and std
2025-11-20 13:35:56,724:INFO:Creating metrics dataframe
2025-11-20 13:35:56,726:INFO:Finalizing model
2025-11-20 13:35:57,906:INFO:Uploading results into container
2025-11-20 13:35:57,907:INFO:Uploading model into container now
2025-11-20 13:35:57,908:INFO:_master_model_container: 18
2025-11-20 13:35:57,908:INFO:_display_container: 5
2025-11-20 13:35:57,909:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:57,909:INFO:create_model() successfully completed......................................
2025-11-20 13:35:58,028:INFO:SubProcess create_model() end ==================================
2025-11-20 13:35:58,029:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.839
2025-11-20 13:35:58,029:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8394
2025-11-20 13:35:58,030:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-20 13:35:58,030:INFO:choose_better completed
2025-11-20 13:35:58,042:INFO:_master_model_container: 18
2025-11-20 13:35:58,042:INFO:_display_container: 4
2025-11-20 13:35:58,043:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-20 13:35:58,043:INFO:tune_model() successfully completed......................................
2025-11-20 13:36:09,596:INFO:Initializing plot_model()
2025-11-20 13:36:09,596:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 13:36:09,596:INFO:Checking exceptions
2025-11-20 13:36:09,607:INFO:Preloading libraries
2025-11-20 13:36:09,621:INFO:Copying training dataset
2025-11-20 13:36:09,621:INFO:Plot type: confusion_matrix
2025-11-20 13:36:09,802:INFO:Fitting Model
2025-11-20 13:36:09,803:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-20 13:36:09,803:INFO:Scoring test/hold-out set
2025-11-20 13:36:09,957:INFO:Visual Rendered Successfully
2025-11-20 13:36:10,175:INFO:plot_model() successfully completed......................................
2025-11-20 13:36:16,096:INFO:Initializing plot_model()
2025-11-20 13:36:16,096:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 13:36:16,096:INFO:Checking exceptions
2025-11-20 13:36:16,107:INFO:Preloading libraries
2025-11-20 13:36:16,118:INFO:Copying training dataset
2025-11-20 13:36:16,118:INFO:Plot type: feature
2025-11-20 13:36:16,119:WARNING:No coef_ found. Trying feature_importances_
2025-11-20 13:36:16,396:INFO:Visual Rendered Successfully
2025-11-20 13:36:16,598:INFO:plot_model() successfully completed......................................
2025-11-20 13:37:41,199:INFO:Initializing interpret_model()
2025-11-20 13:37:41,199:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-11-20 13:37:41,199:INFO:Checking exceptions
2025-11-20 13:37:41,199:INFO:Soft dependency imported: shap: 0.48.0
2025-11-20 13:40:24,229:INFO:Initializing interpret_model()
2025-11-20 13:40:24,229:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-11-20 13:40:24,229:INFO:Checking exceptions
2025-11-20 13:40:24,229:INFO:Soft dependency imported: shap: 0.48.0
2025-11-20 15:16:20,208:INFO:Initializing create_model()
2025-11-20 15:16:20,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 15:16:20,209:INFO:Checking exceptions
2025-11-20 15:16:20,228:INFO:Importing libraries
2025-11-20 15:16:20,229:INFO:Copying training dataset
2025-11-20 15:16:20,244:INFO:Defining folds
2025-11-20 15:16:20,245:INFO:Declaring metric variables
2025-11-20 15:16:20,250:INFO:Importing untrained model
2025-11-20 15:16:20,256:INFO:Logistic Regression Imported successfully
2025-11-20 15:16:20,267:INFO:Starting cross validation
2025-11-20 15:16:20,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:16:27,158:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,167:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,167:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,176:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,182:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,183:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,184:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,190:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,191:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,227:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:27,286:INFO:Calculating mean and std
2025-11-20 15:16:27,288:INFO:Creating metrics dataframe
2025-11-20 15:16:27,297:INFO:Finalizing model
2025-11-20 15:16:28,209:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:28,214:INFO:Uploading results into container
2025-11-20 15:16:28,215:INFO:Uploading model into container now
2025-11-20 15:16:28,226:INFO:_master_model_container: 19
2025-11-20 15:16:28,227:INFO:_display_container: 5
2025-11-20 15:16:28,227:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 15:16:28,227:INFO:create_model() successfully completed......................................
2025-11-20 15:16:28,394:INFO:Initializing tune_model()
2025-11-20 15:16:28,395:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'class_weight': ['balanced', None], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-20 15:16:28,395:INFO:Checking exceptions
2025-11-20 15:16:28,417:INFO:Copying training dataset
2025-11-20 15:16:28,425:INFO:Checking base model
2025-11-20 15:16:28,425:INFO:Base model : Logistic Regression
2025-11-20 15:16:28,430:INFO:Declaring metric variables
2025-11-20 15:16:28,434:INFO:Defining Hyperparameters
2025-11-20 15:16:28,585:INFO:custom_grid: {'actual_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100], 'actual_estimator__class_weight': ['balanced', None], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-11-20 15:16:28,585:INFO:Tuning with n_jobs=-1
2025-11-20 15:16:28,585:INFO:Initializing RandomizedSearchCV
2025-11-20 15:16:29,368:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,391:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,412:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,427:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,440:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,516:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,529:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,560:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:29,581:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,553:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,569:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,570:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,589:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,621:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,637:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,652:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:30,666:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,095:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,176:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,197:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,220:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,221:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,242:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,257:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,263:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,274:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,303:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,858:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,930:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,935:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,943:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,946:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,975:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,983:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,987:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:31,990:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,034:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,543:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,596:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,636:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,639:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,660:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,663:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,674:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,682:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,705:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:32,723:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:34,866:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1}
2025-11-20 15:16:34,868:INFO:Hyperparameter search completed
2025-11-20 15:16:34,868:INFO:SubProcess create_model() called ==================================
2025-11-20 15:16:34,870:INFO:Initializing create_model()
2025-11-20 15:16:34,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0727D390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 1})
2025-11-20 15:16:34,870:INFO:Checking exceptions
2025-11-20 15:16:34,870:INFO:Importing libraries
2025-11-20 15:16:34,870:INFO:Copying training dataset
2025-11-20 15:16:34,885:INFO:Defining folds
2025-11-20 15:16:34,885:INFO:Declaring metric variables
2025-11-20 15:16:34,889:INFO:Importing untrained model
2025-11-20 15:16:34,890:INFO:Declaring custom model
2025-11-20 15:16:34,895:INFO:Logistic Regression Imported successfully
2025-11-20 15:16:34,902:INFO:Starting cross validation
2025-11-20 15:16:34,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:16:35,414:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,434:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,441:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,445:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,451:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,461:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,463:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,475:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,479:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,484:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:35,515:INFO:Calculating mean and std
2025-11-20 15:16:35,517:INFO:Creating metrics dataframe
2025-11-20 15:16:35,523:INFO:Finalizing model
2025-11-20 15:16:36,406:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:36,412:INFO:Uploading results into container
2025-11-20 15:16:36,413:INFO:Uploading model into container now
2025-11-20 15:16:36,414:INFO:_master_model_container: 20
2025-11-20 15:16:36,414:INFO:_display_container: 6
2025-11-20 15:16:36,415:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 15:16:36,415:INFO:create_model() successfully completed......................................
2025-11-20 15:16:36,564:INFO:SubProcess create_model() end ==================================
2025-11-20 15:16:36,564:INFO:choose_better activated
2025-11-20 15:16:36,568:INFO:SubProcess create_model() called ==================================
2025-11-20 15:16:36,568:INFO:Initializing create_model()
2025-11-20 15:16:36,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 15:16:36,569:INFO:Checking exceptions
2025-11-20 15:16:36,571:INFO:Importing libraries
2025-11-20 15:16:36,571:INFO:Copying training dataset
2025-11-20 15:16:36,580:INFO:Defining folds
2025-11-20 15:16:36,580:INFO:Declaring metric variables
2025-11-20 15:16:36,580:INFO:Importing untrained model
2025-11-20 15:16:36,580:INFO:Declaring custom model
2025-11-20 15:16:36,581:INFO:Logistic Regression Imported successfully
2025-11-20 15:16:36,581:INFO:Starting cross validation
2025-11-20 15:16:36,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:16:37,065:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,084:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,093:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,093:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,099:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,100:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,106:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,117:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,133:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,134:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:37,169:INFO:Calculating mean and std
2025-11-20 15:16:37,170:INFO:Creating metrics dataframe
2025-11-20 15:16:37,172:INFO:Finalizing model
2025-11-20 15:16:38,101:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-20 15:16:38,102:INFO:Uploading results into container
2025-11-20 15:16:38,102:INFO:Uploading model into container now
2025-11-20 15:16:38,103:INFO:_master_model_container: 21
2025-11-20 15:16:38,103:INFO:_display_container: 7
2025-11-20 15:16:38,103:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 15:16:38,104:INFO:create_model() successfully completed......................................
2025-11-20 15:16:38,256:INFO:SubProcess create_model() end ==================================
2025-11-20 15:16:38,257:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8128
2025-11-20 15:16:38,257:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8134
2025-11-20 15:16:38,258:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-11-20 15:16:38,258:INFO:choose_better completed
2025-11-20 15:16:38,269:INFO:_master_model_container: 21
2025-11-20 15:16:38,270:INFO:_display_container: 6
2025-11-20 15:16:38,270:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-20 15:16:38,270:INFO:tune_model() successfully completed......................................
2025-11-20 15:17:33,639:INFO:Initializing plot_model()
2025-11-20 15:17:33,639:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 15:17:33,639:INFO:Checking exceptions
2025-11-20 15:17:33,648:INFO:Preloading libraries
2025-11-20 15:17:33,649:INFO:Copying training dataset
2025-11-20 15:17:33,649:INFO:Plot type: confusion_matrix
2025-11-20 15:17:33,818:INFO:Fitting Model
2025-11-20 15:17:33,818:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-11-20 15:17:33,819:INFO:Scoring test/hold-out set
2025-11-20 15:17:33,997:INFO:Visual Rendered Successfully
2025-11-20 15:17:34,164:INFO:plot_model() successfully completed......................................
2025-11-20 15:18:07,596:INFO:Initializing plot_model()
2025-11-20 15:18:07,596:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 15:18:07,596:INFO:Checking exceptions
2025-11-20 15:18:07,606:INFO:Preloading libraries
2025-11-20 15:18:07,607:INFO:Copying training dataset
2025-11-20 15:18:07,607:INFO:Plot type: feature
2025-11-20 15:18:07,892:INFO:Visual Rendered Successfully
2025-11-20 15:18:08,043:INFO:plot_model() successfully completed......................................
2025-11-20 15:19:32,904:INFO:Initializing create_model()
2025-11-20 15:19:32,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 15:19:32,904:INFO:Checking exceptions
2025-11-20 15:19:32,924:INFO:Importing libraries
2025-11-20 15:19:32,924:INFO:Copying training dataset
2025-11-20 15:19:32,937:INFO:Defining folds
2025-11-20 15:19:32,937:INFO:Declaring metric variables
2025-11-20 15:19:32,944:INFO:Importing untrained model
2025-11-20 15:19:32,948:INFO:Random Forest Classifier Imported successfully
2025-11-20 15:19:32,957:INFO:Starting cross validation
2025-11-20 15:19:32,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:19:34,038:INFO:Calculating mean and std
2025-11-20 15:19:34,040:INFO:Creating metrics dataframe
2025-11-20 15:19:34,046:INFO:Finalizing model
2025-11-20 15:19:34,343:INFO:Uploading results into container
2025-11-20 15:19:34,343:INFO:Uploading model into container now
2025-11-20 15:19:34,355:INFO:_master_model_container: 22
2025-11-20 15:19:34,355:INFO:_display_container: 7
2025-11-20 15:19:34,355:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 15:19:34,355:INFO:create_model() successfully completed......................................
2025-11-20 15:19:34,511:INFO:Initializing tune_model()
2025-11-20 15:19:34,511:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', 'balanced_subsample', None]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-20 15:19:34,511:INFO:Checking exceptions
2025-11-20 15:19:34,530:INFO:Copying training dataset
2025-11-20 15:19:34,538:INFO:Checking base model
2025-11-20 15:19:34,539:INFO:Base model : Random Forest Classifier
2025-11-20 15:19:34,542:INFO:Declaring metric variables
2025-11-20 15:19:34,546:INFO:Defining Hyperparameters
2025-11-20 15:19:34,699:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [10, 20, None], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__criterion': ['gini', 'entropy'], 'actual_estimator__class_weight': ['balanced', 'balanced_subsample', None]}
2025-11-20 15:19:34,699:INFO:Tuning with n_jobs=-1
2025-11-20 15:19:34,699:INFO:Initializing RandomizedSearchCV
2025-11-20 15:19:56,914:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2025-11-20 15:19:56,915:INFO:Hyperparameter search completed
2025-11-20 15:19:56,916:INFO:SubProcess create_model() called ==================================
2025-11-20 15:19:56,917:INFO:Initializing create_model()
2025-11-20 15:19:56,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0D15D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced'})
2025-11-20 15:19:56,917:INFO:Checking exceptions
2025-11-20 15:19:56,917:INFO:Importing libraries
2025-11-20 15:19:56,917:INFO:Copying training dataset
2025-11-20 15:19:56,928:INFO:Defining folds
2025-11-20 15:19:56,929:INFO:Declaring metric variables
2025-11-20 15:19:56,932:INFO:Importing untrained model
2025-11-20 15:19:56,932:INFO:Declaring custom model
2025-11-20 15:19:56,937:INFO:Random Forest Classifier Imported successfully
2025-11-20 15:19:56,944:INFO:Starting cross validation
2025-11-20 15:19:56,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:19:59,296:INFO:Calculating mean and std
2025-11-20 15:19:59,297:INFO:Creating metrics dataframe
2025-11-20 15:19:59,303:INFO:Finalizing model
2025-11-20 15:19:59,922:INFO:Uploading results into container
2025-11-20 15:19:59,924:INFO:Uploading model into container now
2025-11-20 15:19:59,924:INFO:_master_model_container: 23
2025-11-20 15:19:59,924:INFO:_display_container: 8
2025-11-20 15:19:59,926:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 15:19:59,926:INFO:create_model() successfully completed......................................
2025-11-20 15:20:00,088:INFO:SubProcess create_model() end ==================================
2025-11-20 15:20:00,088:INFO:choose_better activated
2025-11-20 15:20:00,092:INFO:SubProcess create_model() called ==================================
2025-11-20 15:20:00,093:INFO:Initializing create_model()
2025-11-20 15:20:00,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-20 15:20:00,093:INFO:Checking exceptions
2025-11-20 15:20:00,095:INFO:Importing libraries
2025-11-20 15:20:00,095:INFO:Copying training dataset
2025-11-20 15:20:00,105:INFO:Defining folds
2025-11-20 15:20:00,105:INFO:Declaring metric variables
2025-11-20 15:20:00,105:INFO:Importing untrained model
2025-11-20 15:20:00,105:INFO:Declaring custom model
2025-11-20 15:20:00,106:INFO:Random Forest Classifier Imported successfully
2025-11-20 15:20:00,106:INFO:Starting cross validation
2025-11-20 15:20:00,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-20 15:20:01,061:INFO:Calculating mean and std
2025-11-20 15:20:01,062:INFO:Creating metrics dataframe
2025-11-20 15:20:01,063:INFO:Finalizing model
2025-11-20 15:20:01,321:INFO:Uploading results into container
2025-11-20 15:20:01,322:INFO:Uploading model into container now
2025-11-20 15:20:01,323:INFO:_master_model_container: 24
2025-11-20 15:20:01,323:INFO:_display_container: 9
2025-11-20 15:20:01,324:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 15:20:01,324:INFO:create_model() successfully completed......................................
2025-11-20 15:20:01,475:INFO:SubProcess create_model() end ==================================
2025-11-20 15:20:01,476:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8219
2025-11-20 15:20:01,477:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8365
2025-11-20 15:20:01,477:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-11-20 15:20:01,477:INFO:choose_better completed
2025-11-20 15:20:01,488:INFO:_master_model_container: 24
2025-11-20 15:20:01,488:INFO:_display_container: 8
2025-11-20 15:20:01,489:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-20 15:20:01,489:INFO:tune_model() successfully completed......................................
2025-11-20 15:20:22,062:INFO:Initializing plot_model()
2025-11-20 15:20:22,062:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 15:20:22,062:INFO:Checking exceptions
2025-11-20 15:20:22,135:INFO:Preloading libraries
2025-11-20 15:20:22,191:INFO:Copying training dataset
2025-11-20 15:20:22,191:INFO:Plot type: confusion_matrix
2025-11-20 15:20:22,358:INFO:Fitting Model
2025-11-20 15:20:22,358:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-11-20 15:20:22,359:INFO:Scoring test/hold-out set
2025-11-20 15:20:22,661:INFO:Visual Rendered Successfully
2025-11-20 15:20:22,816:INFO:plot_model() successfully completed......................................
2025-11-20 15:21:19,152:INFO:Initializing plot_model()
2025-11-20 15:21:19,152:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 15:21:19,152:INFO:Checking exceptions
2025-11-20 15:21:19,162:INFO:Preloading libraries
2025-11-20 15:21:19,162:INFO:Copying training dataset
2025-11-20 15:21:19,162:INFO:Plot type: feature
2025-11-20 15:21:19,465:INFO:Visual Rendered Successfully
2025-11-20 15:21:19,615:INFO:plot_model() successfully completed......................................
2025-11-20 15:21:24,207:INFO:Initializing plot_model()
2025-11-20 15:21:24,207:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FDFDEB1D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-20 15:21:24,207:INFO:Checking exceptions
2025-11-20 15:21:24,276:INFO:Preloading libraries
2025-11-20 15:21:24,318:INFO:Copying training dataset
2025-11-20 15:21:24,318:INFO:Plot type: feature
2025-11-20 15:21:24,319:WARNING:No coef_ found. Trying feature_importances_
2025-11-20 15:21:24,596:INFO:Visual Rendered Successfully
2025-11-20 15:21:24,768:INFO:plot_model() successfully completed......................................
2025-11-21 16:58:01,035:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 16:58:01,304:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 16:58:01,517:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 16:58:01,734:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 16:58:01,987:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 16:58:02,159:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 16:58:02,334:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 16:58:02,522:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 16:58:02,777:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 16:58:03,102:INFO:PyCaret ClassificationExperiment
2025-11-21 16:58:03,103:INFO:Logging name: clf-default-name
2025-11-21 16:58:03,103:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-21 16:58:03,103:INFO:version 3.3.2
2025-11-21 16:58:03,103:INFO:Initializing setup()
2025-11-21 16:58:03,103:INFO:self.USI: 6ed9
2025-11-21 16:58:03,103:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-21 16:58:03,103:INFO:Checking environment
2025-11-21 16:58:03,103:INFO:python_version: 3.11.9
2025-11-21 16:58:03,103:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-21 16:58:03,103:INFO:machine: AMD64
2025-11-21 16:58:03,103:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-21 16:58:03,103:INFO:Memory: svmem(total=16440479744, available=3412426752, percent=79.2, used=13028052992, free=3412426752)
2025-11-21 16:58:03,103:INFO:Physical Core: 8
2025-11-21 16:58:03,103:INFO:Logical Core: 16
2025-11-21 16:58:03,103:INFO:Checking libraries
2025-11-21 16:58:03,103:INFO:System:
2025-11-21 16:58:03,103:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-21 16:58:03,103:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-21 16:58:03,103:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-21 16:58:03,103:INFO:PyCaret required dependencies:
2025-11-21 16:58:03,103:INFO:                 pip: 24.0
2025-11-21 16:58:03,103:INFO:          setuptools: 65.5.0
2025-11-21 16:58:03,103:INFO:             pycaret: 3.3.2
2025-11-21 16:58:03,103:INFO:             IPython: 9.0.2
2025-11-21 16:58:03,103:INFO:          ipywidgets: 8.1.7
2025-11-21 16:58:03,103:INFO:                tqdm: 4.67.1
2025-11-21 16:58:03,103:INFO:               numpy: 1.26.4
2025-11-21 16:58:03,114:INFO:              pandas: 2.1.4
2025-11-21 16:58:03,114:INFO:              jinja2: 3.1.6
2025-11-21 16:58:03,114:INFO:               scipy: 1.11.4
2025-11-21 16:58:03,114:INFO:              joblib: 1.3.2
2025-11-21 16:58:03,114:INFO:             sklearn: 1.4.2
2025-11-21 16:58:03,114:INFO:                pyod: 2.0.5
2025-11-21 16:58:03,114:INFO:            imblearn: 0.14.0
2025-11-21 16:58:03,114:INFO:   category_encoders: 2.7.0
2025-11-21 16:58:03,114:INFO:            lightgbm: 4.6.0
2025-11-21 16:58:03,114:INFO:               numba: 0.61.2
2025-11-21 16:58:03,114:INFO:            requests: 2.32.5
2025-11-21 16:58:03,114:INFO:          matplotlib: 3.7.5
2025-11-21 16:58:03,114:INFO:          scikitplot: 0.3.7
2025-11-21 16:58:03,114:INFO:         yellowbrick: 1.5
2025-11-21 16:58:03,114:INFO:              plotly: 6.3.0
2025-11-21 16:58:03,114:INFO:    plotly-resampler: Not installed
2025-11-21 16:58:03,114:INFO:             kaleido: 1.1.0
2025-11-21 16:58:03,114:INFO:           schemdraw: 0.15
2025-11-21 16:58:03,114:INFO:         statsmodels: 0.14.5
2025-11-21 16:58:03,114:INFO:              sktime: 0.26.0
2025-11-21 16:58:03,114:INFO:               tbats: 1.1.3
2025-11-21 16:58:03,114:INFO:            pmdarima: 2.0.4
2025-11-21 16:58:03,114:INFO:              psutil: 7.0.0
2025-11-21 16:58:03,114:INFO:          markupsafe: 3.0.2
2025-11-21 16:58:03,114:INFO:             pickle5: Not installed
2025-11-21 16:58:03,114:INFO:         cloudpickle: 3.1.1
2025-11-21 16:58:03,114:INFO:         deprecation: 2.1.0
2025-11-21 16:58:03,114:INFO:              xxhash: 3.5.0
2025-11-21 16:58:03,114:INFO:           wurlitzer: Not installed
2025-11-21 16:58:03,114:INFO:PyCaret optional dependencies:
2025-11-21 16:58:03,114:INFO:                shap: 0.48.0
2025-11-21 16:58:03,114:INFO:           interpret: Not installed
2025-11-21 16:58:03,114:INFO:                umap: 0.5.7
2025-11-21 16:58:03,114:INFO:     ydata_profiling: Not installed
2025-11-21 16:58:03,114:INFO:  explainerdashboard: Not installed
2025-11-21 16:58:03,114:INFO:             autoviz: Not installed
2025-11-21 16:58:03,114:INFO:           fairlearn: Not installed
2025-11-21 16:58:03,114:INFO:          deepchecks: Not installed
2025-11-21 16:58:03,114:INFO:             xgboost: 3.0.5
2025-11-21 16:58:03,114:INFO:            catboost: Not installed
2025-11-21 16:58:03,114:INFO:              kmodes: Not installed
2025-11-21 16:58:03,114:INFO:             mlxtend: Not installed
2025-11-21 16:58:03,114:INFO:       statsforecast: Not installed
2025-11-21 16:58:03,114:INFO:        tune_sklearn: Not installed
2025-11-21 16:58:03,114:INFO:                 ray: Not installed
2025-11-21 16:58:03,114:INFO:            hyperopt: Not installed
2025-11-21 16:58:03,114:INFO:              optuna: 4.5.0
2025-11-21 16:58:03,114:INFO:               skopt: Not installed
2025-11-21 16:58:03,114:INFO:              mlflow: Not installed
2025-11-21 16:58:03,114:INFO:              gradio: Not installed
2025-11-21 16:58:03,114:INFO:             fastapi: Not installed
2025-11-21 16:58:03,114:INFO:             uvicorn: Not installed
2025-11-21 16:58:03,114:INFO:              m2cgen: Not installed
2025-11-21 16:58:03,114:INFO:           evidently: Not installed
2025-11-21 16:58:03,114:INFO:               fugue: Not installed
2025-11-21 16:58:03,114:INFO:           streamlit: Not installed
2025-11-21 16:58:03,114:INFO:             prophet: Not installed
2025-11-21 16:58:03,114:INFO:None
2025-11-21 16:58:03,114:INFO:Set up data.
2025-11-21 16:58:03,137:INFO:Set up folding strategy.
2025-11-21 16:58:03,137:INFO:Set up train/test split.
2025-11-21 16:58:03,189:INFO:Set up index.
2025-11-21 16:58:03,189:INFO:Assigning column types.
2025-11-21 16:58:03,199:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-21 16:58:03,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,346:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,477:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,482:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-21 16:58:03,539:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,577:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,648:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:58:03,687:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,692:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-21 16:58:03,784:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,879:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:03,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:03,894:INFO:Preparing preprocessing pipeline...
2025-11-21 16:58:03,894:INFO:Set up date feature engineering.
2025-11-21 16:58:03,902:INFO:Set up simple imputation.
2025-11-21 16:58:04,051:INFO:Finished creating preprocessing pipeline.
2025-11-21 16:58:04,060:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-21 16:58:04,061:INFO:Creating final display dataframe.
2025-11-21 16:58:04,283:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 20)
5   Transformed train set shape           (5961, 20)
6    Transformed test set shape           (2555, 20)
7               Ignore features                    1
8              Numeric features                   16
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 6ed9
2025-11-21 16:58:04,432:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:04,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:04,536:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:58:04,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:58:04,555:INFO:setup() successfully completed in 1.55s...............
2025-11-21 16:58:04,561:INFO:Initializing compare_models()
2025-11-21 16:58:04,561:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-21 16:58:04,561:INFO:Checking exceptions
2025-11-21 16:58:04,572:INFO:Preparing display monitor
2025-11-21 16:58:04,618:INFO:Initializing Logistic Regression
2025-11-21 16:58:04,618:INFO:Total runtime is 0.0 minutes
2025-11-21 16:58:04,622:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:04,625:INFO:Initializing create_model()
2025-11-21 16:58:04,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:04,625:INFO:Checking exceptions
2025-11-21 16:58:04,625:INFO:Importing libraries
2025-11-21 16:58:04,625:INFO:Copying training dataset
2025-11-21 16:58:04,640:INFO:Defining folds
2025-11-21 16:58:04,640:INFO:Declaring metric variables
2025-11-21 16:58:04,645:INFO:Importing untrained model
2025-11-21 16:58:04,648:INFO:Logistic Regression Imported successfully
2025-11-21 16:58:04,659:INFO:Starting cross validation
2025-11-21 16:58:04,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:45,683:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:58:45,742:INFO:Calculating mean and std
2025-11-21 16:58:45,748:INFO:Creating metrics dataframe
2025-11-21 16:58:45,756:INFO:Uploading results into container
2025-11-21 16:58:45,757:INFO:Uploading model into container now
2025-11-21 16:58:45,763:INFO:_master_model_container: 1
2025-11-21 16:58:45,765:INFO:_display_container: 2
2025-11-21 16:58:45,767:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 16:58:45,769:INFO:create_model() successfully completed......................................
2025-11-21 16:58:46,942:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:46,942:INFO:Creating metrics dataframe
2025-11-21 16:58:46,949:INFO:Initializing K Neighbors Classifier
2025-11-21 16:58:46,949:INFO:Total runtime is 0.7055170615514119 minutes
2025-11-21 16:58:46,955:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:46,957:INFO:Initializing create_model()
2025-11-21 16:58:46,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:46,957:INFO:Checking exceptions
2025-11-21 16:58:46,957:INFO:Importing libraries
2025-11-21 16:58:46,957:INFO:Copying training dataset
2025-11-21 16:58:46,965:INFO:Defining folds
2025-11-21 16:58:46,969:INFO:Declaring metric variables
2025-11-21 16:58:46,973:INFO:Importing untrained model
2025-11-21 16:58:46,973:INFO:K Neighbors Classifier Imported successfully
2025-11-21 16:58:46,990:INFO:Starting cross validation
2025-11-21 16:58:46,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:52,413:INFO:Calculating mean and std
2025-11-21 16:58:52,415:INFO:Creating metrics dataframe
2025-11-21 16:58:52,418:INFO:Uploading results into container
2025-11-21 16:58:52,418:INFO:Uploading model into container now
2025-11-21 16:58:52,418:INFO:_master_model_container: 2
2025-11-21 16:58:52,420:INFO:_display_container: 2
2025-11-21 16:58:52,420:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-21 16:58:52,420:INFO:create_model() successfully completed......................................
2025-11-21 16:58:52,622:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:52,622:INFO:Creating metrics dataframe
2025-11-21 16:58:52,632:INFO:Initializing Naive Bayes
2025-11-21 16:58:52,632:INFO:Total runtime is 0.8002267281214396 minutes
2025-11-21 16:58:52,632:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:52,632:INFO:Initializing create_model()
2025-11-21 16:58:52,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:52,632:INFO:Checking exceptions
2025-11-21 16:58:52,632:INFO:Importing libraries
2025-11-21 16:58:52,632:INFO:Copying training dataset
2025-11-21 16:58:52,649:INFO:Defining folds
2025-11-21 16:58:52,649:INFO:Declaring metric variables
2025-11-21 16:58:52,653:INFO:Importing untrained model
2025-11-21 16:58:52,658:INFO:Naive Bayes Imported successfully
2025-11-21 16:58:52,663:INFO:Starting cross validation
2025-11-21 16:58:52,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:52,793:INFO:Calculating mean and std
2025-11-21 16:58:52,793:INFO:Creating metrics dataframe
2025-11-21 16:58:52,795:INFO:Uploading results into container
2025-11-21 16:58:52,795:INFO:Uploading model into container now
2025-11-21 16:58:52,795:INFO:_master_model_container: 3
2025-11-21 16:58:52,795:INFO:_display_container: 2
2025-11-21 16:58:52,799:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-21 16:58:52,799:INFO:create_model() successfully completed......................................
2025-11-21 16:58:52,956:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:52,956:INFO:Creating metrics dataframe
2025-11-21 16:58:52,956:INFO:Initializing Decision Tree Classifier
2025-11-21 16:58:52,956:INFO:Total runtime is 0.8056275010108948 minutes
2025-11-21 16:58:52,966:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:52,966:INFO:Initializing create_model()
2025-11-21 16:58:52,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:52,966:INFO:Checking exceptions
2025-11-21 16:58:52,966:INFO:Importing libraries
2025-11-21 16:58:52,966:INFO:Copying training dataset
2025-11-21 16:58:52,966:INFO:Defining folds
2025-11-21 16:58:52,966:INFO:Declaring metric variables
2025-11-21 16:58:52,986:INFO:Importing untrained model
2025-11-21 16:58:52,990:INFO:Decision Tree Classifier Imported successfully
2025-11-21 16:58:52,999:INFO:Starting cross validation
2025-11-21 16:58:52,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:53,147:INFO:Calculating mean and std
2025-11-21 16:58:53,147:INFO:Creating metrics dataframe
2025-11-21 16:58:53,149:INFO:Uploading results into container
2025-11-21 16:58:53,151:INFO:Uploading model into container now
2025-11-21 16:58:53,151:INFO:_master_model_container: 4
2025-11-21 16:58:53,151:INFO:_display_container: 2
2025-11-21 16:58:53,151:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-21 16:58:53,151:INFO:create_model() successfully completed......................................
2025-11-21 16:58:53,309:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:53,309:INFO:Creating metrics dataframe
2025-11-21 16:58:53,317:INFO:Initializing SVM - Linear Kernel
2025-11-21 16:58:53,317:INFO:Total runtime is 0.8116485436757406 minutes
2025-11-21 16:58:53,321:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:53,321:INFO:Initializing create_model()
2025-11-21 16:58:53,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:53,321:INFO:Checking exceptions
2025-11-21 16:58:53,321:INFO:Importing libraries
2025-11-21 16:58:53,323:INFO:Copying training dataset
2025-11-21 16:58:53,335:INFO:Defining folds
2025-11-21 16:58:53,335:INFO:Declaring metric variables
2025-11-21 16:58:53,337:INFO:Importing untrained model
2025-11-21 16:58:53,344:INFO:SVM - Linear Kernel Imported successfully
2025-11-21 16:58:53,351:INFO:Starting cross validation
2025-11-21 16:58:53,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:53,530:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 16:58:53,530:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 16:58:53,570:INFO:Calculating mean and std
2025-11-21 16:58:53,570:INFO:Creating metrics dataframe
2025-11-21 16:58:53,573:INFO:Uploading results into container
2025-11-21 16:58:53,573:INFO:Uploading model into container now
2025-11-21 16:58:53,574:INFO:_master_model_container: 5
2025-11-21 16:58:53,574:INFO:_display_container: 2
2025-11-21 16:58:53,574:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-21 16:58:53,574:INFO:create_model() successfully completed......................................
2025-11-21 16:58:53,734:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:53,734:INFO:Creating metrics dataframe
2025-11-21 16:58:53,747:INFO:Initializing Ridge Classifier
2025-11-21 16:58:53,747:INFO:Total runtime is 0.8188062429428101 minutes
2025-11-21 16:58:53,761:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:53,761:INFO:Initializing create_model()
2025-11-21 16:58:53,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:53,761:INFO:Checking exceptions
2025-11-21 16:58:53,761:INFO:Importing libraries
2025-11-21 16:58:53,761:INFO:Copying training dataset
2025-11-21 16:58:53,766:INFO:Defining folds
2025-11-21 16:58:53,766:INFO:Declaring metric variables
2025-11-21 16:58:53,779:INFO:Importing untrained model
2025-11-21 16:58:53,785:INFO:Ridge Classifier Imported successfully
2025-11-21 16:58:53,795:INFO:Starting cross validation
2025-11-21 16:58:53,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:53,943:INFO:Calculating mean and std
2025-11-21 16:58:53,943:INFO:Creating metrics dataframe
2025-11-21 16:58:53,945:INFO:Uploading results into container
2025-11-21 16:58:53,947:INFO:Uploading model into container now
2025-11-21 16:58:53,947:INFO:_master_model_container: 6
2025-11-21 16:58:53,947:INFO:_display_container: 2
2025-11-21 16:58:53,947:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-21 16:58:53,947:INFO:create_model() successfully completed......................................
2025-11-21 16:58:54,105:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:54,105:INFO:Creating metrics dataframe
2025-11-21 16:58:54,111:INFO:Initializing Random Forest Classifier
2025-11-21 16:58:54,115:INFO:Total runtime is 0.8249502261479696 minutes
2025-11-21 16:58:54,122:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:54,122:INFO:Initializing create_model()
2025-11-21 16:58:54,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:54,122:INFO:Checking exceptions
2025-11-21 16:58:54,122:INFO:Importing libraries
2025-11-21 16:58:54,122:INFO:Copying training dataset
2025-11-21 16:58:54,129:INFO:Defining folds
2025-11-21 16:58:54,129:INFO:Declaring metric variables
2025-11-21 16:58:54,139:INFO:Importing untrained model
2025-11-21 16:58:54,142:INFO:Random Forest Classifier Imported successfully
2025-11-21 16:58:54,153:INFO:Starting cross validation
2025-11-21 16:58:54,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:55,092:INFO:Calculating mean and std
2025-11-21 16:58:55,092:INFO:Creating metrics dataframe
2025-11-21 16:58:55,092:INFO:Uploading results into container
2025-11-21 16:58:55,092:INFO:Uploading model into container now
2025-11-21 16:58:55,092:INFO:_master_model_container: 7
2025-11-21 16:58:55,092:INFO:_display_container: 2
2025-11-21 16:58:55,092:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 16:58:55,092:INFO:create_model() successfully completed......................................
2025-11-21 16:58:55,253:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:55,253:INFO:Creating metrics dataframe
2025-11-21 16:58:55,269:INFO:Initializing Quadratic Discriminant Analysis
2025-11-21 16:58:55,269:INFO:Total runtime is 0.8441809296607972 minutes
2025-11-21 16:58:55,273:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:55,273:INFO:Initializing create_model()
2025-11-21 16:58:55,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:55,275:INFO:Checking exceptions
2025-11-21 16:58:55,275:INFO:Importing libraries
2025-11-21 16:58:55,275:INFO:Copying training dataset
2025-11-21 16:58:55,285:INFO:Defining folds
2025-11-21 16:58:55,285:INFO:Declaring metric variables
2025-11-21 16:58:55,293:INFO:Importing untrained model
2025-11-21 16:58:55,297:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-21 16:58:55,311:INFO:Starting cross validation
2025-11-21 16:58:55,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,425:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,429:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:58:55,482:INFO:Calculating mean and std
2025-11-21 16:58:55,483:INFO:Creating metrics dataframe
2025-11-21 16:58:55,483:INFO:Uploading results into container
2025-11-21 16:58:55,483:INFO:Uploading model into container now
2025-11-21 16:58:55,483:INFO:_master_model_container: 8
2025-11-21 16:58:55,483:INFO:_display_container: 2
2025-11-21 16:58:55,483:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-21 16:58:55,483:INFO:create_model() successfully completed......................................
2025-11-21 16:58:55,643:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:55,643:INFO:Creating metrics dataframe
2025-11-21 16:58:55,656:INFO:Initializing Ada Boost Classifier
2025-11-21 16:58:55,656:INFO:Total runtime is 0.8506321628888448 minutes
2025-11-21 16:58:55,656:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:55,656:INFO:Initializing create_model()
2025-11-21 16:58:55,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:55,656:INFO:Checking exceptions
2025-11-21 16:58:55,656:INFO:Importing libraries
2025-11-21 16:58:55,656:INFO:Copying training dataset
2025-11-21 16:58:55,667:INFO:Defining folds
2025-11-21 16:58:55,667:INFO:Declaring metric variables
2025-11-21 16:58:55,680:INFO:Importing untrained model
2025-11-21 16:58:55,686:INFO:Ada Boost Classifier Imported successfully
2025-11-21 16:58:55,694:INFO:Starting cross validation
2025-11-21 16:58:55,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:55,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:58:56,236:INFO:Calculating mean and std
2025-11-21 16:58:56,236:INFO:Creating metrics dataframe
2025-11-21 16:58:56,236:INFO:Uploading results into container
2025-11-21 16:58:56,236:INFO:Uploading model into container now
2025-11-21 16:58:56,236:INFO:_master_model_container: 9
2025-11-21 16:58:56,236:INFO:_display_container: 2
2025-11-21 16:58:56,236:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-21 16:58:56,236:INFO:create_model() successfully completed......................................
2025-11-21 16:58:56,395:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:56,395:INFO:Creating metrics dataframe
2025-11-21 16:58:56,408:INFO:Initializing Gradient Boosting Classifier
2025-11-21 16:58:56,408:INFO:Total runtime is 0.8631634950637818 minutes
2025-11-21 16:58:56,408:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:56,408:INFO:Initializing create_model()
2025-11-21 16:58:56,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:56,408:INFO:Checking exceptions
2025-11-21 16:58:56,408:INFO:Importing libraries
2025-11-21 16:58:56,408:INFO:Copying training dataset
2025-11-21 16:58:56,421:INFO:Defining folds
2025-11-21 16:58:56,421:INFO:Declaring metric variables
2025-11-21 16:58:56,430:INFO:Importing untrained model
2025-11-21 16:58:56,434:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:58:56,442:INFO:Starting cross validation
2025-11-21 16:58:56,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:57,839:INFO:Calculating mean and std
2025-11-21 16:58:57,839:INFO:Creating metrics dataframe
2025-11-21 16:58:57,839:INFO:Uploading results into container
2025-11-21 16:58:57,839:INFO:Uploading model into container now
2025-11-21 16:58:57,839:INFO:_master_model_container: 10
2025-11-21 16:58:57,839:INFO:_display_container: 2
2025-11-21 16:58:57,839:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:58:57,839:INFO:create_model() successfully completed......................................
2025-11-21 16:58:57,994:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:57,994:INFO:Creating metrics dataframe
2025-11-21 16:58:58,026:INFO:Initializing Linear Discriminant Analysis
2025-11-21 16:58:58,026:INFO:Total runtime is 0.8901306867599488 minutes
2025-11-21 16:58:58,030:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:58,030:INFO:Initializing create_model()
2025-11-21 16:58:58,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:58,030:INFO:Checking exceptions
2025-11-21 16:58:58,030:INFO:Importing libraries
2025-11-21 16:58:58,030:INFO:Copying training dataset
2025-11-21 16:58:58,045:INFO:Defining folds
2025-11-21 16:58:58,045:INFO:Declaring metric variables
2025-11-21 16:58:58,045:INFO:Importing untrained model
2025-11-21 16:58:58,054:INFO:Linear Discriminant Analysis Imported successfully
2025-11-21 16:58:58,063:INFO:Starting cross validation
2025-11-21 16:58:58,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:58,192:INFO:Calculating mean and std
2025-11-21 16:58:58,192:INFO:Creating metrics dataframe
2025-11-21 16:58:58,192:INFO:Uploading results into container
2025-11-21 16:58:58,192:INFO:Uploading model into container now
2025-11-21 16:58:58,192:INFO:_master_model_container: 11
2025-11-21 16:58:58,192:INFO:_display_container: 2
2025-11-21 16:58:58,192:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-21 16:58:58,192:INFO:create_model() successfully completed......................................
2025-11-21 16:58:58,359:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:58,359:INFO:Creating metrics dataframe
2025-11-21 16:58:58,368:INFO:Initializing Extra Trees Classifier
2025-11-21 16:58:58,368:INFO:Total runtime is 0.8958188931147258 minutes
2025-11-21 16:58:58,368:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:58,368:INFO:Initializing create_model()
2025-11-21 16:58:58,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:58,368:INFO:Checking exceptions
2025-11-21 16:58:58,368:INFO:Importing libraries
2025-11-21 16:58:58,368:INFO:Copying training dataset
2025-11-21 16:58:58,385:INFO:Defining folds
2025-11-21 16:58:58,385:INFO:Declaring metric variables
2025-11-21 16:58:58,390:INFO:Importing untrained model
2025-11-21 16:58:58,393:INFO:Extra Trees Classifier Imported successfully
2025-11-21 16:58:58,401:INFO:Starting cross validation
2025-11-21 16:58:58,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:58:59,230:INFO:Calculating mean and std
2025-11-21 16:58:59,230:INFO:Creating metrics dataframe
2025-11-21 16:58:59,233:INFO:Uploading results into container
2025-11-21 16:58:59,233:INFO:Uploading model into container now
2025-11-21 16:58:59,236:INFO:_master_model_container: 12
2025-11-21 16:58:59,236:INFO:_display_container: 2
2025-11-21 16:58:59,236:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-21 16:58:59,236:INFO:create_model() successfully completed......................................
2025-11-21 16:58:59,410:INFO:SubProcess create_model() end ==================================
2025-11-21 16:58:59,410:INFO:Creating metrics dataframe
2025-11-21 16:58:59,440:INFO:Initializing Extreme Gradient Boosting
2025-11-21 16:58:59,440:INFO:Total runtime is 0.9136900345484417 minutes
2025-11-21 16:58:59,440:INFO:SubProcess create_model() called ==================================
2025-11-21 16:58:59,440:INFO:Initializing create_model()
2025-11-21 16:58:59,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:58:59,440:INFO:Checking exceptions
2025-11-21 16:58:59,440:INFO:Importing libraries
2025-11-21 16:58:59,440:INFO:Copying training dataset
2025-11-21 16:58:59,458:INFO:Defining folds
2025-11-21 16:58:59,458:INFO:Declaring metric variables
2025-11-21 16:58:59,458:INFO:Importing untrained model
2025-11-21 16:58:59,471:INFO:Extreme Gradient Boosting Imported successfully
2025-11-21 16:58:59,483:INFO:Starting cross validation
2025-11-21 16:58:59,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:01,094:INFO:Calculating mean and std
2025-11-21 16:59:01,094:INFO:Creating metrics dataframe
2025-11-21 16:59:01,094:INFO:Uploading results into container
2025-11-21 16:59:01,094:INFO:Uploading model into container now
2025-11-21 16:59:01,094:INFO:_master_model_container: 13
2025-11-21 16:59:01,094:INFO:_display_container: 2
2025-11-21 16:59:01,094:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-21 16:59:01,094:INFO:create_model() successfully completed......................................
2025-11-21 16:59:01,256:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:01,256:INFO:Creating metrics dataframe
2025-11-21 16:59:01,267:INFO:Initializing Light Gradient Boosting Machine
2025-11-21 16:59:01,267:INFO:Total runtime is 0.9441424409548442 minutes
2025-11-21 16:59:01,271:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:01,271:INFO:Initializing create_model()
2025-11-21 16:59:01,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:01,271:INFO:Checking exceptions
2025-11-21 16:59:01,271:INFO:Importing libraries
2025-11-21 16:59:01,271:INFO:Copying training dataset
2025-11-21 16:59:01,277:INFO:Defining folds
2025-11-21 16:59:01,277:INFO:Declaring metric variables
2025-11-21 16:59:01,288:INFO:Importing untrained model
2025-11-21 16:59:01,294:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-21 16:59:01,302:INFO:Starting cross validation
2025-11-21 16:59:01,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:03,081:INFO:Calculating mean and std
2025-11-21 16:59:03,083:INFO:Creating metrics dataframe
2025-11-21 16:59:03,087:INFO:Uploading results into container
2025-11-21 16:59:03,087:INFO:Uploading model into container now
2025-11-21 16:59:03,089:INFO:_master_model_container: 14
2025-11-21 16:59:03,090:INFO:_display_container: 2
2025-11-21 16:59:03,090:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-21 16:59:03,090:INFO:create_model() successfully completed......................................
2025-11-21 16:59:03,259:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:03,259:INFO:Creating metrics dataframe
2025-11-21 16:59:03,269:INFO:Initializing Dummy Classifier
2025-11-21 16:59:03,269:INFO:Total runtime is 0.977504849433899 minutes
2025-11-21 16:59:03,273:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:03,275:INFO:Initializing create_model()
2025-11-21 16:59:03,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07DC8B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:03,275:INFO:Checking exceptions
2025-11-21 16:59:03,275:INFO:Importing libraries
2025-11-21 16:59:03,275:INFO:Copying training dataset
2025-11-21 16:59:03,289:INFO:Defining folds
2025-11-21 16:59:03,289:INFO:Declaring metric variables
2025-11-21 16:59:03,293:INFO:Importing untrained model
2025-11-21 16:59:03,297:INFO:Dummy Classifier Imported successfully
2025-11-21 16:59:03,305:INFO:Starting cross validation
2025-11-21 16:59:03,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:03,437:INFO:Calculating mean and std
2025-11-21 16:59:03,437:INFO:Creating metrics dataframe
2025-11-21 16:59:03,442:INFO:Uploading results into container
2025-11-21 16:59:03,442:INFO:Uploading model into container now
2025-11-21 16:59:03,442:INFO:_master_model_container: 15
2025-11-21 16:59:03,442:INFO:_display_container: 2
2025-11-21 16:59:03,442:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-21 16:59:03,442:INFO:create_model() successfully completed......................................
2025-11-21 16:59:03,610:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:03,610:INFO:Creating metrics dataframe
2025-11-21 16:59:03,625:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-21 16:59:03,637:INFO:Initializing create_model()
2025-11-21 16:59:03,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:03,637:INFO:Checking exceptions
2025-11-21 16:59:03,637:INFO:Importing libraries
2025-11-21 16:59:03,637:INFO:Copying training dataset
2025-11-21 16:59:03,651:INFO:Defining folds
2025-11-21 16:59:03,651:INFO:Declaring metric variables
2025-11-21 16:59:03,651:INFO:Importing untrained model
2025-11-21 16:59:03,651:INFO:Declaring custom model
2025-11-21 16:59:03,653:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:03,653:INFO:Cross validation set to False
2025-11-21 16:59:03,653:INFO:Fitting Model
2025-11-21 16:59:04,975:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:04,975:INFO:create_model() successfully completed......................................
2025-11-21 16:59:05,176:INFO:_master_model_container: 15
2025-11-21 16:59:05,177:INFO:_display_container: 2
2025-11-21 16:59:05,177:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:05,177:INFO:compare_models() successfully completed......................................
2025-11-21 16:59:05,213:INFO:Initializing create_model()
2025-11-21 16:59:05,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:05,213:INFO:Checking exceptions
2025-11-21 16:59:05,232:INFO:Importing libraries
2025-11-21 16:59:05,232:INFO:Copying training dataset
2025-11-21 16:59:05,245:INFO:Defining folds
2025-11-21 16:59:05,245:INFO:Declaring metric variables
2025-11-21 16:59:05,247:INFO:Importing untrained model
2025-11-21 16:59:05,253:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:05,261:INFO:Starting cross validation
2025-11-21 16:59:05,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:06,601:INFO:Calculating mean and std
2025-11-21 16:59:06,603:INFO:Creating metrics dataframe
2025-11-21 16:59:06,608:INFO:Finalizing model
2025-11-21 16:59:07,788:INFO:Uploading results into container
2025-11-21 16:59:07,788:INFO:Uploading model into container now
2025-11-21 16:59:07,796:INFO:_master_model_container: 16
2025-11-21 16:59:07,796:INFO:_display_container: 3
2025-11-21 16:59:07,796:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:07,796:INFO:create_model() successfully completed......................................
2025-11-21 16:59:07,975:INFO:Initializing tune_model()
2025-11-21 16:59:07,975:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 16:59:07,975:INFO:Checking exceptions
2025-11-21 16:59:07,994:INFO:Copying training dataset
2025-11-21 16:59:08,001:INFO:Checking base model
2025-11-21 16:59:08,001:INFO:Base model : Gradient Boosting Classifier
2025-11-21 16:59:08,006:INFO:Declaring metric variables
2025-11-21 16:59:08,007:INFO:Defining Hyperparameters
2025-11-21 16:59:08,167:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-21 16:59:08,167:INFO:Tuning with n_jobs=-1
2025-11-21 16:59:08,167:INFO:Initializing RandomizedSearchCV
2025-11-21 16:59:34,393:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-21 16:59:34,393:INFO:Hyperparameter search completed
2025-11-21 16:59:34,393:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:34,393:INFO:Initializing create_model()
2025-11-21 16:59:34,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDA9D290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-21 16:59:34,393:INFO:Checking exceptions
2025-11-21 16:59:34,393:INFO:Importing libraries
2025-11-21 16:59:34,393:INFO:Copying training dataset
2025-11-21 16:59:34,411:INFO:Defining folds
2025-11-21 16:59:34,411:INFO:Declaring metric variables
2025-11-21 16:59:34,414:INFO:Importing untrained model
2025-11-21 16:59:34,414:INFO:Declaring custom model
2025-11-21 16:59:34,414:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:34,422:INFO:Starting cross validation
2025-11-21 16:59:34,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:35,657:INFO:Calculating mean and std
2025-11-21 16:59:35,657:INFO:Creating metrics dataframe
2025-11-21 16:59:35,662:INFO:Finalizing model
2025-11-21 16:59:36,798:INFO:Uploading results into container
2025-11-21 16:59:36,799:INFO:Uploading model into container now
2025-11-21 16:59:36,799:INFO:_master_model_container: 17
2025-11-21 16:59:36,799:INFO:_display_container: 4
2025-11-21 16:59:36,799:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:36,799:INFO:create_model() successfully completed......................................
2025-11-21 16:59:36,967:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:36,967:INFO:choose_better activated
2025-11-21 16:59:36,975:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:36,977:INFO:Initializing create_model()
2025-11-21 16:59:36,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:36,977:INFO:Checking exceptions
2025-11-21 16:59:36,979:INFO:Importing libraries
2025-11-21 16:59:36,979:INFO:Copying training dataset
2025-11-21 16:59:36,982:INFO:Defining folds
2025-11-21 16:59:36,982:INFO:Declaring metric variables
2025-11-21 16:59:36,982:INFO:Importing untrained model
2025-11-21 16:59:36,982:INFO:Declaring custom model
2025-11-21 16:59:36,982:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:36,982:INFO:Starting cross validation
2025-11-21 16:59:36,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:38,328:INFO:Calculating mean and std
2025-11-21 16:59:38,328:INFO:Creating metrics dataframe
2025-11-21 16:59:38,328:INFO:Finalizing model
2025-11-21 16:59:39,471:INFO:Uploading results into container
2025-11-21 16:59:39,471:INFO:Uploading model into container now
2025-11-21 16:59:39,471:INFO:_master_model_container: 18
2025-11-21 16:59:39,486:INFO:_display_container: 5
2025-11-21 16:59:39,486:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:39,486:INFO:create_model() successfully completed......................................
2025-11-21 16:59:39,630:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:39,630:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9418
2025-11-21 16:59:39,630:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.942
2025-11-21 16:59:39,630:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-21 16:59:39,630:INFO:choose_better completed
2025-11-21 16:59:39,646:INFO:_master_model_container: 18
2025-11-21 16:59:39,646:INFO:_display_container: 4
2025-11-21 16:59:39,646:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:39,646:INFO:tune_model() successfully completed......................................
2025-11-21 16:59:39,815:INFO:Initializing plot_model()
2025-11-21 16:59:39,815:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 16:59:39,815:INFO:Checking exceptions
2025-11-21 16:59:39,831:INFO:Preloading libraries
2025-11-21 16:59:39,848:INFO:Copying training dataset
2025-11-21 16:59:39,848:INFO:Plot type: confusion_matrix
2025-11-21 16:59:39,989:INFO:Fitting Model
2025-11-21 16:59:39,989:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-21 16:59:39,989:INFO:Scoring test/hold-out set
2025-11-21 16:59:40,149:INFO:Visual Rendered Successfully
2025-11-21 16:59:40,311:INFO:plot_model() successfully completed......................................
2025-11-21 16:59:40,330:INFO:Initializing plot_model()
2025-11-21 16:59:40,330:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE019E7C10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 16:59:40,330:INFO:Checking exceptions
2025-11-21 16:59:40,338:INFO:Preloading libraries
2025-11-21 16:59:40,349:INFO:Copying training dataset
2025-11-21 16:59:40,349:INFO:Plot type: feature
2025-11-21 16:59:40,349:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 16:59:40,632:INFO:Visual Rendered Successfully
2025-11-21 16:59:40,777:INFO:plot_model() successfully completed......................................
2025-11-21 16:59:40,833:INFO:PyCaret ClassificationExperiment
2025-11-21 16:59:40,833:INFO:Logging name: clf-default-name
2025-11-21 16:59:40,833:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-21 16:59:40,833:INFO:version 3.3.2
2025-11-21 16:59:40,833:INFO:Initializing setup()
2025-11-21 16:59:40,833:INFO:self.USI: 8eb1
2025-11-21 16:59:40,833:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-21 16:59:40,833:INFO:Checking environment
2025-11-21 16:59:40,833:INFO:python_version: 3.11.9
2025-11-21 16:59:40,833:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-21 16:59:40,833:INFO:machine: AMD64
2025-11-21 16:59:40,833:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-21 16:59:40,833:INFO:Memory: svmem(total=16440479744, available=870248448, percent=94.7, used=15570231296, free=870248448)
2025-11-21 16:59:40,833:INFO:Physical Core: 8
2025-11-21 16:59:40,833:INFO:Logical Core: 16
2025-11-21 16:59:40,833:INFO:Checking libraries
2025-11-21 16:59:40,833:INFO:System:
2025-11-21 16:59:40,833:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-21 16:59:40,833:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-21 16:59:40,833:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-21 16:59:40,833:INFO:PyCaret required dependencies:
2025-11-21 16:59:40,833:INFO:                 pip: 24.0
2025-11-21 16:59:40,833:INFO:          setuptools: 65.5.0
2025-11-21 16:59:40,833:INFO:             pycaret: 3.3.2
2025-11-21 16:59:40,833:INFO:             IPython: 9.0.2
2025-11-21 16:59:40,833:INFO:          ipywidgets: 8.1.7
2025-11-21 16:59:40,833:INFO:                tqdm: 4.67.1
2025-11-21 16:59:40,833:INFO:               numpy: 1.26.4
2025-11-21 16:59:40,833:INFO:              pandas: 2.1.4
2025-11-21 16:59:40,833:INFO:              jinja2: 3.1.6
2025-11-21 16:59:40,833:INFO:               scipy: 1.11.4
2025-11-21 16:59:40,833:INFO:              joblib: 1.3.2
2025-11-21 16:59:40,833:INFO:             sklearn: 1.4.2
2025-11-21 16:59:40,833:INFO:                pyod: 2.0.5
2025-11-21 16:59:40,833:INFO:            imblearn: 0.14.0
2025-11-21 16:59:40,833:INFO:   category_encoders: 2.7.0
2025-11-21 16:59:40,833:INFO:            lightgbm: 4.6.0
2025-11-21 16:59:40,833:INFO:               numba: 0.61.2
2025-11-21 16:59:40,833:INFO:            requests: 2.32.5
2025-11-21 16:59:40,833:INFO:          matplotlib: 3.7.5
2025-11-21 16:59:40,833:INFO:          scikitplot: 0.3.7
2025-11-21 16:59:40,833:INFO:         yellowbrick: 1.5
2025-11-21 16:59:40,833:INFO:              plotly: 6.3.0
2025-11-21 16:59:40,833:INFO:    plotly-resampler: Not installed
2025-11-21 16:59:40,833:INFO:             kaleido: 1.1.0
2025-11-21 16:59:40,833:INFO:           schemdraw: 0.15
2025-11-21 16:59:40,833:INFO:         statsmodels: 0.14.5
2025-11-21 16:59:40,833:INFO:              sktime: 0.26.0
2025-11-21 16:59:40,833:INFO:               tbats: 1.1.3
2025-11-21 16:59:40,833:INFO:            pmdarima: 2.0.4
2025-11-21 16:59:40,833:INFO:              psutil: 7.0.0
2025-11-21 16:59:40,833:INFO:          markupsafe: 3.0.2
2025-11-21 16:59:40,833:INFO:             pickle5: Not installed
2025-11-21 16:59:40,833:INFO:         cloudpickle: 3.1.1
2025-11-21 16:59:40,833:INFO:         deprecation: 2.1.0
2025-11-21 16:59:40,833:INFO:              xxhash: 3.5.0
2025-11-21 16:59:40,833:INFO:           wurlitzer: Not installed
2025-11-21 16:59:40,833:INFO:PyCaret optional dependencies:
2025-11-21 16:59:40,833:INFO:                shap: 0.48.0
2025-11-21 16:59:40,833:INFO:           interpret: Not installed
2025-11-21 16:59:40,833:INFO:                umap: 0.5.7
2025-11-21 16:59:40,833:INFO:     ydata_profiling: Not installed
2025-11-21 16:59:40,833:INFO:  explainerdashboard: Not installed
2025-11-21 16:59:40,833:INFO:             autoviz: Not installed
2025-11-21 16:59:40,833:INFO:           fairlearn: Not installed
2025-11-21 16:59:40,833:INFO:          deepchecks: Not installed
2025-11-21 16:59:40,833:INFO:             xgboost: 3.0.5
2025-11-21 16:59:40,833:INFO:            catboost: Not installed
2025-11-21 16:59:40,833:INFO:              kmodes: Not installed
2025-11-21 16:59:40,841:INFO:             mlxtend: Not installed
2025-11-21 16:59:40,841:INFO:       statsforecast: Not installed
2025-11-21 16:59:40,841:INFO:        tune_sklearn: Not installed
2025-11-21 16:59:40,841:INFO:                 ray: Not installed
2025-11-21 16:59:40,841:INFO:            hyperopt: Not installed
2025-11-21 16:59:40,841:INFO:              optuna: 4.5.0
2025-11-21 16:59:40,841:INFO:               skopt: Not installed
2025-11-21 16:59:40,841:INFO:              mlflow: Not installed
2025-11-21 16:59:40,841:INFO:              gradio: Not installed
2025-11-21 16:59:40,841:INFO:             fastapi: Not installed
2025-11-21 16:59:40,841:INFO:             uvicorn: Not installed
2025-11-21 16:59:40,841:INFO:              m2cgen: Not installed
2025-11-21 16:59:40,841:INFO:           evidently: Not installed
2025-11-21 16:59:40,841:INFO:               fugue: Not installed
2025-11-21 16:59:40,841:INFO:           streamlit: Not installed
2025-11-21 16:59:40,841:INFO:             prophet: Not installed
2025-11-21 16:59:40,841:INFO:None
2025-11-21 16:59:40,841:INFO:Set up data.
2025-11-21 16:59:40,849:INFO:Set up folding strategy.
2025-11-21 16:59:40,849:INFO:Set up train/test split.
2025-11-21 16:59:40,857:INFO:Set up index.
2025-11-21 16:59:40,857:INFO:Assigning column types.
2025-11-21 16:59:40,864:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-21 16:59:40,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 16:59:40,926:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:59:40,954:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:40,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 16:59:41,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:59:41,051:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,051:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-21 16:59:41,096:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:59:41,141:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 16:59:41,233:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,233:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-21 16:59:41,330:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,421:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,429:INFO:Preparing preprocessing pipeline...
2025-11-21 16:59:41,429:INFO:Set up date feature engineering.
2025-11-21 16:59:41,429:INFO:Set up simple imputation.
2025-11-21 16:59:41,494:INFO:Finished creating preprocessing pipeline.
2025-11-21 16:59:41,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-21 16:59:41,494:INFO:Creating final display dataframe.
2025-11-21 16:59:41,643:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 19)
5   Transformed train set shape           (5961, 19)
6    Transformed test set shape           (2555, 19)
7               Ignore features                    2
8              Numeric features                   15
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 8eb1
2025-11-21 16:59:41,732:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,820:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 16:59:41,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 16:59:41,825:INFO:setup() successfully completed in 1.0s...............
2025-11-21 16:59:41,836:INFO:Initializing compare_models()
2025-11-21 16:59:41,836:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-21 16:59:41,836:INFO:Checking exceptions
2025-11-21 16:59:41,836:INFO:Preparing display monitor
2025-11-21 16:59:41,868:INFO:Initializing Logistic Regression
2025-11-21 16:59:41,868:INFO:Total runtime is 0.0 minutes
2025-11-21 16:59:41,877:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:41,877:INFO:Initializing create_model()
2025-11-21 16:59:41,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:41,877:INFO:Checking exceptions
2025-11-21 16:59:41,877:INFO:Importing libraries
2025-11-21 16:59:41,877:INFO:Copying training dataset
2025-11-21 16:59:41,886:INFO:Defining folds
2025-11-21 16:59:41,886:INFO:Declaring metric variables
2025-11-21 16:59:41,886:INFO:Importing untrained model
2025-11-21 16:59:41,894:INFO:Logistic Regression Imported successfully
2025-11-21 16:59:41,903:INFO:Starting cross validation
2025-11-21 16:59:41,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:42,470:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,474:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,478:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,479:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,490:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,493:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,493:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,493:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,493:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,497:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 16:59:42,534:INFO:Calculating mean and std
2025-11-21 16:59:42,534:INFO:Creating metrics dataframe
2025-11-21 16:59:42,534:INFO:Uploading results into container
2025-11-21 16:59:42,534:INFO:Uploading model into container now
2025-11-21 16:59:42,534:INFO:_master_model_container: 1
2025-11-21 16:59:42,534:INFO:_display_container: 2
2025-11-21 16:59:42,534:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 16:59:42,534:INFO:create_model() successfully completed......................................
2025-11-21 16:59:42,695:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:42,695:INFO:Creating metrics dataframe
2025-11-21 16:59:42,695:INFO:Initializing K Neighbors Classifier
2025-11-21 16:59:42,695:INFO:Total runtime is 0.01377881368001302 minutes
2025-11-21 16:59:42,708:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:42,708:INFO:Initializing create_model()
2025-11-21 16:59:42,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:42,710:INFO:Checking exceptions
2025-11-21 16:59:42,710:INFO:Importing libraries
2025-11-21 16:59:42,710:INFO:Copying training dataset
2025-11-21 16:59:42,719:INFO:Defining folds
2025-11-21 16:59:42,721:INFO:Declaring metric variables
2025-11-21 16:59:42,723:INFO:Importing untrained model
2025-11-21 16:59:42,726:INFO:K Neighbors Classifier Imported successfully
2025-11-21 16:59:42,737:INFO:Starting cross validation
2025-11-21 16:59:42,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:42,926:INFO:Calculating mean and std
2025-11-21 16:59:42,926:INFO:Creating metrics dataframe
2025-11-21 16:59:42,926:INFO:Uploading results into container
2025-11-21 16:59:42,926:INFO:Uploading model into container now
2025-11-21 16:59:42,926:INFO:_master_model_container: 2
2025-11-21 16:59:42,926:INFO:_display_container: 2
2025-11-21 16:59:42,926:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-21 16:59:42,926:INFO:create_model() successfully completed......................................
2025-11-21 16:59:43,085:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:43,085:INFO:Creating metrics dataframe
2025-11-21 16:59:43,085:INFO:Initializing Naive Bayes
2025-11-21 16:59:43,085:INFO:Total runtime is 0.02028135061264038 minutes
2025-11-21 16:59:43,085:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:43,085:INFO:Initializing create_model()
2025-11-21 16:59:43,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:43,085:INFO:Checking exceptions
2025-11-21 16:59:43,085:INFO:Importing libraries
2025-11-21 16:59:43,085:INFO:Copying training dataset
2025-11-21 16:59:43,101:INFO:Defining folds
2025-11-21 16:59:43,101:INFO:Declaring metric variables
2025-11-21 16:59:43,112:INFO:Importing untrained model
2025-11-21 16:59:43,117:INFO:Naive Bayes Imported successfully
2025-11-21 16:59:43,117:INFO:Starting cross validation
2025-11-21 16:59:43,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:43,243:INFO:Calculating mean and std
2025-11-21 16:59:43,243:INFO:Creating metrics dataframe
2025-11-21 16:59:43,243:INFO:Uploading results into container
2025-11-21 16:59:43,243:INFO:Uploading model into container now
2025-11-21 16:59:43,243:INFO:_master_model_container: 3
2025-11-21 16:59:43,243:INFO:_display_container: 2
2025-11-21 16:59:43,243:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-21 16:59:43,243:INFO:create_model() successfully completed......................................
2025-11-21 16:59:43,403:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:43,403:INFO:Creating metrics dataframe
2025-11-21 16:59:43,410:INFO:Initializing Decision Tree Classifier
2025-11-21 16:59:43,410:INFO:Total runtime is 0.025687062740325926 minutes
2025-11-21 16:59:43,415:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:43,417:INFO:Initializing create_model()
2025-11-21 16:59:43,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:43,417:INFO:Checking exceptions
2025-11-21 16:59:43,417:INFO:Importing libraries
2025-11-21 16:59:43,417:INFO:Copying training dataset
2025-11-21 16:59:43,425:INFO:Defining folds
2025-11-21 16:59:43,425:INFO:Declaring metric variables
2025-11-21 16:59:43,425:INFO:Importing untrained model
2025-11-21 16:59:43,425:INFO:Decision Tree Classifier Imported successfully
2025-11-21 16:59:43,439:INFO:Starting cross validation
2025-11-21 16:59:43,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:43,591:INFO:Calculating mean and std
2025-11-21 16:59:43,593:INFO:Creating metrics dataframe
2025-11-21 16:59:43,595:INFO:Uploading results into container
2025-11-21 16:59:43,595:INFO:Uploading model into container now
2025-11-21 16:59:43,597:INFO:_master_model_container: 4
2025-11-21 16:59:43,597:INFO:_display_container: 2
2025-11-21 16:59:43,597:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-21 16:59:43,597:INFO:create_model() successfully completed......................................
2025-11-21 16:59:43,757:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:43,757:INFO:Creating metrics dataframe
2025-11-21 16:59:43,762:INFO:Initializing SVM - Linear Kernel
2025-11-21 16:59:43,762:INFO:Total runtime is 0.031561474005381264 minutes
2025-11-21 16:59:43,762:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:43,762:INFO:Initializing create_model()
2025-11-21 16:59:43,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:43,762:INFO:Checking exceptions
2025-11-21 16:59:43,762:INFO:Importing libraries
2025-11-21 16:59:43,762:INFO:Copying training dataset
2025-11-21 16:59:43,786:INFO:Defining folds
2025-11-21 16:59:43,786:INFO:Declaring metric variables
2025-11-21 16:59:43,792:INFO:Importing untrained model
2025-11-21 16:59:43,797:INFO:SVM - Linear Kernel Imported successfully
2025-11-21 16:59:43,809:INFO:Starting cross validation
2025-11-21 16:59:43,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:44,022:INFO:Calculating mean and std
2025-11-21 16:59:44,022:INFO:Creating metrics dataframe
2025-11-21 16:59:44,022:INFO:Uploading results into container
2025-11-21 16:59:44,022:INFO:Uploading model into container now
2025-11-21 16:59:44,022:INFO:_master_model_container: 5
2025-11-21 16:59:44,022:INFO:_display_container: 2
2025-11-21 16:59:44,022:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-21 16:59:44,022:INFO:create_model() successfully completed......................................
2025-11-21 16:59:44,185:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:44,185:INFO:Creating metrics dataframe
2025-11-21 16:59:44,193:INFO:Initializing Ridge Classifier
2025-11-21 16:59:44,193:INFO:Total runtime is 0.03874415556589762 minutes
2025-11-21 16:59:44,193:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:44,193:INFO:Initializing create_model()
2025-11-21 16:59:44,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:44,193:INFO:Checking exceptions
2025-11-21 16:59:44,193:INFO:Importing libraries
2025-11-21 16:59:44,193:INFO:Copying training dataset
2025-11-21 16:59:44,209:INFO:Defining folds
2025-11-21 16:59:44,209:INFO:Declaring metric variables
2025-11-21 16:59:44,209:INFO:Importing untrained model
2025-11-21 16:59:44,209:INFO:Ridge Classifier Imported successfully
2025-11-21 16:59:44,224:INFO:Starting cross validation
2025-11-21 16:59:44,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:44,343:INFO:Calculating mean and std
2025-11-21 16:59:44,343:INFO:Creating metrics dataframe
2025-11-21 16:59:44,343:INFO:Uploading results into container
2025-11-21 16:59:44,343:INFO:Uploading model into container now
2025-11-21 16:59:44,343:INFO:_master_model_container: 6
2025-11-21 16:59:44,343:INFO:_display_container: 2
2025-11-21 16:59:44,343:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-21 16:59:44,343:INFO:create_model() successfully completed......................................
2025-11-21 16:59:44,511:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:44,511:INFO:Creating metrics dataframe
2025-11-21 16:59:44,519:INFO:Initializing Random Forest Classifier
2025-11-21 16:59:44,519:INFO:Total runtime is 0.04418642123540242 minutes
2025-11-21 16:59:44,523:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:44,523:INFO:Initializing create_model()
2025-11-21 16:59:44,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:44,523:INFO:Checking exceptions
2025-11-21 16:59:44,523:INFO:Importing libraries
2025-11-21 16:59:44,523:INFO:Copying training dataset
2025-11-21 16:59:44,537:INFO:Defining folds
2025-11-21 16:59:44,537:INFO:Declaring metric variables
2025-11-21 16:59:44,541:INFO:Importing untrained model
2025-11-21 16:59:44,545:INFO:Random Forest Classifier Imported successfully
2025-11-21 16:59:44,554:INFO:Starting cross validation
2025-11-21 16:59:44,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:45,572:INFO:Calculating mean and std
2025-11-21 16:59:45,573:INFO:Creating metrics dataframe
2025-11-21 16:59:45,573:INFO:Uploading results into container
2025-11-21 16:59:45,573:INFO:Uploading model into container now
2025-11-21 16:59:45,573:INFO:_master_model_container: 7
2025-11-21 16:59:45,573:INFO:_display_container: 2
2025-11-21 16:59:45,573:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 16:59:45,573:INFO:create_model() successfully completed......................................
2025-11-21 16:59:45,732:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:45,732:INFO:Creating metrics dataframe
2025-11-21 16:59:45,747:INFO:Initializing Quadratic Discriminant Analysis
2025-11-21 16:59:45,747:INFO:Total runtime is 0.06465173562367757 minutes
2025-11-21 16:59:45,747:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:45,747:INFO:Initializing create_model()
2025-11-21 16:59:45,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:45,747:INFO:Checking exceptions
2025-11-21 16:59:45,747:INFO:Importing libraries
2025-11-21 16:59:45,747:INFO:Copying training dataset
2025-11-21 16:59:45,763:INFO:Defining folds
2025-11-21 16:59:45,763:INFO:Declaring metric variables
2025-11-21 16:59:45,767:INFO:Importing untrained model
2025-11-21 16:59:45,767:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-21 16:59:45,781:INFO:Starting cross validation
2025-11-21 16:59:45,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:45,845:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,847:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,852:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,852:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,858:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,858:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,862:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,864:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,867:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 16:59:45,914:INFO:Calculating mean and std
2025-11-21 16:59:45,916:INFO:Creating metrics dataframe
2025-11-21 16:59:45,919:INFO:Uploading results into container
2025-11-21 16:59:45,919:INFO:Uploading model into container now
2025-11-21 16:59:45,920:INFO:_master_model_container: 8
2025-11-21 16:59:45,920:INFO:_display_container: 2
2025-11-21 16:59:45,920:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-21 16:59:45,920:INFO:create_model() successfully completed......................................
2025-11-21 16:59:46,074:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:46,074:INFO:Creating metrics dataframe
2025-11-21 16:59:46,083:INFO:Initializing Ada Boost Classifier
2025-11-21 16:59:46,083:INFO:Total runtime is 0.07024336655934652 minutes
2025-11-21 16:59:46,088:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:46,088:INFO:Initializing create_model()
2025-11-21 16:59:46,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:46,088:INFO:Checking exceptions
2025-11-21 16:59:46,088:INFO:Importing libraries
2025-11-21 16:59:46,090:INFO:Copying training dataset
2025-11-21 16:59:46,100:INFO:Defining folds
2025-11-21 16:59:46,101:INFO:Declaring metric variables
2025-11-21 16:59:46,101:INFO:Importing untrained model
2025-11-21 16:59:46,109:INFO:Ada Boost Classifier Imported successfully
2025-11-21 16:59:46,115:INFO:Starting cross validation
2025-11-21 16:59:46,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:46,167:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,170:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,173:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,176:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,177:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,181:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,184:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,184:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,194:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 16:59:46,668:INFO:Calculating mean and std
2025-11-21 16:59:46,670:INFO:Creating metrics dataframe
2025-11-21 16:59:46,670:INFO:Uploading results into container
2025-11-21 16:59:46,670:INFO:Uploading model into container now
2025-11-21 16:59:46,670:INFO:_master_model_container: 9
2025-11-21 16:59:46,670:INFO:_display_container: 2
2025-11-21 16:59:46,670:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-21 16:59:46,670:INFO:create_model() successfully completed......................................
2025-11-21 16:59:46,831:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:46,843:INFO:Creating metrics dataframe
2025-11-21 16:59:46,853:INFO:Initializing Gradient Boosting Classifier
2025-11-21 16:59:46,853:INFO:Total runtime is 0.08308126926422119 minutes
2025-11-21 16:59:46,857:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:46,857:INFO:Initializing create_model()
2025-11-21 16:59:46,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:46,857:INFO:Checking exceptions
2025-11-21 16:59:46,857:INFO:Importing libraries
2025-11-21 16:59:46,857:INFO:Copying training dataset
2025-11-21 16:59:46,872:INFO:Defining folds
2025-11-21 16:59:46,872:INFO:Declaring metric variables
2025-11-21 16:59:46,877:INFO:Importing untrained model
2025-11-21 16:59:46,878:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:46,885:INFO:Starting cross validation
2025-11-21 16:59:46,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:48,159:INFO:Calculating mean and std
2025-11-21 16:59:48,160:INFO:Creating metrics dataframe
2025-11-21 16:59:48,162:INFO:Uploading results into container
2025-11-21 16:59:48,163:INFO:Uploading model into container now
2025-11-21 16:59:48,164:INFO:_master_model_container: 10
2025-11-21 16:59:48,164:INFO:_display_container: 2
2025-11-21 16:59:48,165:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:48,165:INFO:create_model() successfully completed......................................
2025-11-21 16:59:48,316:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:48,316:INFO:Creating metrics dataframe
2025-11-21 16:59:48,329:INFO:Initializing Linear Discriminant Analysis
2025-11-21 16:59:48,329:INFO:Total runtime is 0.10768519639968871 minutes
2025-11-21 16:59:48,329:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:48,329:INFO:Initializing create_model()
2025-11-21 16:59:48,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:48,329:INFO:Checking exceptions
2025-11-21 16:59:48,329:INFO:Importing libraries
2025-11-21 16:59:48,329:INFO:Copying training dataset
2025-11-21 16:59:48,343:INFO:Defining folds
2025-11-21 16:59:48,343:INFO:Declaring metric variables
2025-11-21 16:59:48,350:INFO:Importing untrained model
2025-11-21 16:59:48,355:INFO:Linear Discriminant Analysis Imported successfully
2025-11-21 16:59:48,364:INFO:Starting cross validation
2025-11-21 16:59:48,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:48,489:INFO:Calculating mean and std
2025-11-21 16:59:48,491:INFO:Creating metrics dataframe
2025-11-21 16:59:48,492:INFO:Uploading results into container
2025-11-21 16:59:48,492:INFO:Uploading model into container now
2025-11-21 16:59:48,492:INFO:_master_model_container: 11
2025-11-21 16:59:48,492:INFO:_display_container: 2
2025-11-21 16:59:48,492:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-21 16:59:48,492:INFO:create_model() successfully completed......................................
2025-11-21 16:59:48,649:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:48,649:INFO:Creating metrics dataframe
2025-11-21 16:59:48,663:INFO:Initializing Extra Trees Classifier
2025-11-21 16:59:48,663:INFO:Total runtime is 0.11324260632197061 minutes
2025-11-21 16:59:48,663:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:48,663:INFO:Initializing create_model()
2025-11-21 16:59:48,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:48,663:INFO:Checking exceptions
2025-11-21 16:59:48,663:INFO:Importing libraries
2025-11-21 16:59:48,663:INFO:Copying training dataset
2025-11-21 16:59:48,677:INFO:Defining folds
2025-11-21 16:59:48,677:INFO:Declaring metric variables
2025-11-21 16:59:48,683:INFO:Importing untrained model
2025-11-21 16:59:48,683:INFO:Extra Trees Classifier Imported successfully
2025-11-21 16:59:48,691:INFO:Starting cross validation
2025-11-21 16:59:48,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:49,559:INFO:Calculating mean and std
2025-11-21 16:59:49,572:INFO:Creating metrics dataframe
2025-11-21 16:59:49,580:INFO:Uploading results into container
2025-11-21 16:59:49,580:INFO:Uploading model into container now
2025-11-21 16:59:49,582:INFO:_master_model_container: 12
2025-11-21 16:59:49,582:INFO:_display_container: 2
2025-11-21 16:59:49,582:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-21 16:59:49,582:INFO:create_model() successfully completed......................................
2025-11-21 16:59:49,746:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:49,746:INFO:Creating metrics dataframe
2025-11-21 16:59:49,753:INFO:Initializing Extreme Gradient Boosting
2025-11-21 16:59:49,753:INFO:Total runtime is 0.13141828775405884 minutes
2025-11-21 16:59:49,760:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:49,760:INFO:Initializing create_model()
2025-11-21 16:59:49,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:49,760:INFO:Checking exceptions
2025-11-21 16:59:49,760:INFO:Importing libraries
2025-11-21 16:59:49,760:INFO:Copying training dataset
2025-11-21 16:59:49,774:INFO:Defining folds
2025-11-21 16:59:49,774:INFO:Declaring metric variables
2025-11-21 16:59:49,774:INFO:Importing untrained model
2025-11-21 16:59:49,781:INFO:Extreme Gradient Boosting Imported successfully
2025-11-21 16:59:49,788:INFO:Starting cross validation
2025-11-21 16:59:49,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:50,656:INFO:Calculating mean and std
2025-11-21 16:59:50,656:INFO:Creating metrics dataframe
2025-11-21 16:59:50,656:INFO:Uploading results into container
2025-11-21 16:59:50,656:INFO:Uploading model into container now
2025-11-21 16:59:50,656:INFO:_master_model_container: 13
2025-11-21 16:59:50,656:INFO:_display_container: 2
2025-11-21 16:59:50,656:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-21 16:59:50,662:INFO:create_model() successfully completed......................................
2025-11-21 16:59:50,843:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:50,843:INFO:Creating metrics dataframe
2025-11-21 16:59:50,854:INFO:Initializing Light Gradient Boosting Machine
2025-11-21 16:59:50,856:INFO:Total runtime is 0.14976260264714558 minutes
2025-11-21 16:59:50,857:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:50,857:INFO:Initializing create_model()
2025-11-21 16:59:50,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:50,857:INFO:Checking exceptions
2025-11-21 16:59:50,857:INFO:Importing libraries
2025-11-21 16:59:50,857:INFO:Copying training dataset
2025-11-21 16:59:50,876:INFO:Defining folds
2025-11-21 16:59:50,876:INFO:Declaring metric variables
2025-11-21 16:59:50,878:INFO:Importing untrained model
2025-11-21 16:59:50,885:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-21 16:59:50,892:INFO:Starting cross validation
2025-11-21 16:59:50,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:52,781:INFO:Calculating mean and std
2025-11-21 16:59:52,783:INFO:Creating metrics dataframe
2025-11-21 16:59:52,787:INFO:Uploading results into container
2025-11-21 16:59:52,787:INFO:Uploading model into container now
2025-11-21 16:59:52,787:INFO:_master_model_container: 14
2025-11-21 16:59:52,787:INFO:_display_container: 2
2025-11-21 16:59:52,789:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-21 16:59:52,789:INFO:create_model() successfully completed......................................
2025-11-21 16:59:52,964:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:52,964:INFO:Creating metrics dataframe
2025-11-21 16:59:52,976:INFO:Initializing Dummy Classifier
2025-11-21 16:59:52,976:INFO:Total runtime is 0.18512952725092569 minutes
2025-11-21 16:59:52,981:INFO:SubProcess create_model() called ==================================
2025-11-21 16:59:52,981:INFO:Initializing create_model()
2025-11-21 16:59:52,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE01AB0F50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:52,981:INFO:Checking exceptions
2025-11-21 16:59:52,981:INFO:Importing libraries
2025-11-21 16:59:52,981:INFO:Copying training dataset
2025-11-21 16:59:52,989:INFO:Defining folds
2025-11-21 16:59:52,989:INFO:Declaring metric variables
2025-11-21 16:59:52,999:INFO:Importing untrained model
2025-11-21 16:59:53,004:INFO:Dummy Classifier Imported successfully
2025-11-21 16:59:53,016:INFO:Starting cross validation
2025-11-21 16:59:53,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:53,133:INFO:Calculating mean and std
2025-11-21 16:59:53,135:INFO:Creating metrics dataframe
2025-11-21 16:59:53,135:INFO:Uploading results into container
2025-11-21 16:59:53,135:INFO:Uploading model into container now
2025-11-21 16:59:53,135:INFO:_master_model_container: 15
2025-11-21 16:59:53,135:INFO:_display_container: 2
2025-11-21 16:59:53,135:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-21 16:59:53,135:INFO:create_model() successfully completed......................................
2025-11-21 16:59:53,302:INFO:SubProcess create_model() end ==================================
2025-11-21 16:59:53,302:INFO:Creating metrics dataframe
2025-11-21 16:59:53,308:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-21 16:59:53,323:INFO:Initializing create_model()
2025-11-21 16:59:53,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:53,323:INFO:Checking exceptions
2025-11-21 16:59:53,329:INFO:Importing libraries
2025-11-21 16:59:53,329:INFO:Copying training dataset
2025-11-21 16:59:53,336:INFO:Defining folds
2025-11-21 16:59:53,336:INFO:Declaring metric variables
2025-11-21 16:59:53,336:INFO:Importing untrained model
2025-11-21 16:59:53,336:INFO:Declaring custom model
2025-11-21 16:59:53,336:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:53,336:INFO:Cross validation set to False
2025-11-21 16:59:53,336:INFO:Fitting Model
2025-11-21 16:59:54,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:54,553:INFO:create_model() successfully completed......................................
2025-11-21 16:59:54,739:INFO:_master_model_container: 15
2025-11-21 16:59:54,739:INFO:_display_container: 2
2025-11-21 16:59:54,739:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:54,739:INFO:compare_models() successfully completed......................................
2025-11-21 16:59:54,780:INFO:Initializing create_model()
2025-11-21 16:59:54,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 16:59:54,781:INFO:Checking exceptions
2025-11-21 16:59:54,798:INFO:Importing libraries
2025-11-21 16:59:54,798:INFO:Copying training dataset
2025-11-21 16:59:54,812:INFO:Defining folds
2025-11-21 16:59:54,812:INFO:Declaring metric variables
2025-11-21 16:59:54,818:INFO:Importing untrained model
2025-11-21 16:59:54,825:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 16:59:54,831:INFO:Starting cross validation
2025-11-21 16:59:54,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 16:59:56,368:INFO:Calculating mean and std
2025-11-21 16:59:56,371:INFO:Creating metrics dataframe
2025-11-21 16:59:56,382:INFO:Finalizing model
2025-11-21 16:59:57,551:INFO:Uploading results into container
2025-11-21 16:59:57,551:INFO:Uploading model into container now
2025-11-21 16:59:57,566:INFO:_master_model_container: 16
2025-11-21 16:59:57,566:INFO:_display_container: 3
2025-11-21 16:59:57,566:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 16:59:57,566:INFO:create_model() successfully completed......................................
2025-11-21 16:59:57,719:INFO:Initializing tune_model()
2025-11-21 16:59:57,724:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 16:59:57,724:INFO:Checking exceptions
2025-11-21 16:59:57,743:INFO:Copying training dataset
2025-11-21 16:59:57,755:INFO:Checking base model
2025-11-21 16:59:57,755:INFO:Base model : Gradient Boosting Classifier
2025-11-21 16:59:57,763:INFO:Declaring metric variables
2025-11-21 16:59:57,768:INFO:Defining Hyperparameters
2025-11-21 16:59:57,927:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-21 16:59:57,927:INFO:Tuning with n_jobs=-1
2025-11-21 16:59:57,927:INFO:Initializing RandomizedSearchCV
2025-11-21 17:00:22,719:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-21 17:00:22,719:INFO:Hyperparameter search completed
2025-11-21 17:00:22,719:INFO:SubProcess create_model() called ==================================
2025-11-21 17:00:22,719:INFO:Initializing create_model()
2025-11-21 17:00:22,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF8F0B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-21 17:00:22,719:INFO:Checking exceptions
2025-11-21 17:00:22,719:INFO:Importing libraries
2025-11-21 17:00:22,724:INFO:Copying training dataset
2025-11-21 17:00:22,731:INFO:Defining folds
2025-11-21 17:00:22,731:INFO:Declaring metric variables
2025-11-21 17:00:22,739:INFO:Importing untrained model
2025-11-21 17:00:22,739:INFO:Declaring custom model
2025-11-21 17:00:22,745:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 17:00:22,752:INFO:Starting cross validation
2025-11-21 17:00:22,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:23,900:INFO:Calculating mean and std
2025-11-21 17:00:23,900:INFO:Creating metrics dataframe
2025-11-21 17:00:23,904:INFO:Finalizing model
2025-11-21 17:00:24,925:INFO:Uploading results into container
2025-11-21 17:00:24,925:INFO:Uploading model into container now
2025-11-21 17:00:24,925:INFO:_master_model_container: 17
2025-11-21 17:00:24,925:INFO:_display_container: 4
2025-11-21 17:00:24,925:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 17:00:24,925:INFO:create_model() successfully completed......................................
2025-11-21 17:00:25,079:INFO:SubProcess create_model() end ==================================
2025-11-21 17:00:25,079:INFO:choose_better activated
2025-11-21 17:00:25,085:INFO:SubProcess create_model() called ==================================
2025-11-21 17:00:25,085:INFO:Initializing create_model()
2025-11-21 17:00:25,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 17:00:25,088:INFO:Checking exceptions
2025-11-21 17:00:25,089:INFO:Importing libraries
2025-11-21 17:00:25,089:INFO:Copying training dataset
2025-11-21 17:00:25,096:INFO:Defining folds
2025-11-21 17:00:25,096:INFO:Declaring metric variables
2025-11-21 17:00:25,096:INFO:Importing untrained model
2025-11-21 17:00:25,096:INFO:Declaring custom model
2025-11-21 17:00:25,099:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 17:00:25,099:INFO:Starting cross validation
2025-11-21 17:00:25,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:26,363:INFO:Calculating mean and std
2025-11-21 17:00:26,363:INFO:Creating metrics dataframe
2025-11-21 17:00:26,363:INFO:Finalizing model
2025-11-21 17:00:27,481:INFO:Uploading results into container
2025-11-21 17:00:27,488:INFO:Uploading model into container now
2025-11-21 17:00:27,488:INFO:_master_model_container: 18
2025-11-21 17:00:27,488:INFO:_display_container: 5
2025-11-21 17:00:27,488:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 17:00:27,488:INFO:create_model() successfully completed......................................
2025-11-21 17:00:27,634:INFO:SubProcess create_model() end ==================================
2025-11-21 17:00:27,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.839
2025-11-21 17:00:27,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8394
2025-11-21 17:00:27,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-21 17:00:27,641:INFO:choose_better completed
2025-11-21 17:00:27,648:INFO:_master_model_container: 18
2025-11-21 17:00:27,648:INFO:_display_container: 4
2025-11-21 17:00:27,648:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 17:00:27,648:INFO:tune_model() successfully completed......................................
2025-11-21 17:00:27,846:INFO:Initializing plot_model()
2025-11-21 17:00:27,846:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:00:27,846:INFO:Checking exceptions
2025-11-21 17:00:27,856:INFO:Preloading libraries
2025-11-21 17:00:27,866:INFO:Copying training dataset
2025-11-21 17:00:27,866:INFO:Plot type: confusion_matrix
2025-11-21 17:00:28,037:INFO:Fitting Model
2025-11-21 17:00:28,037:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-21 17:00:28,037:INFO:Scoring test/hold-out set
2025-11-21 17:00:28,193:INFO:Visual Rendered Successfully
2025-11-21 17:00:28,359:INFO:plot_model() successfully completed......................................
2025-11-21 17:00:28,376:INFO:Initializing plot_model()
2025-11-21 17:00:28,376:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:00:28,376:INFO:Checking exceptions
2025-11-21 17:00:28,382:INFO:Preloading libraries
2025-11-21 17:00:28,396:INFO:Copying training dataset
2025-11-21 17:00:28,396:INFO:Plot type: feature
2025-11-21 17:00:28,397:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 17:00:28,648:INFO:Visual Rendered Successfully
2025-11-21 17:00:28,813:INFO:plot_model() successfully completed......................................
2025-11-21 17:00:28,822:INFO:Initializing create_model()
2025-11-21 17:00:28,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 17:00:28,822:INFO:Checking exceptions
2025-11-21 17:00:28,854:INFO:Importing libraries
2025-11-21 17:00:28,854:INFO:Copying training dataset
2025-11-21 17:00:28,865:INFO:Defining folds
2025-11-21 17:00:28,865:INFO:Declaring metric variables
2025-11-21 17:00:28,869:INFO:Importing untrained model
2025-11-21 17:00:28,872:INFO:Logistic Regression Imported successfully
2025-11-21 17:00:28,880:INFO:Starting cross validation
2025-11-21 17:00:28,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:29,456:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,463:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,467:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,469:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,474:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,474:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,484:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,486:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,499:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,499:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:29,533:INFO:Calculating mean and std
2025-11-21 17:00:29,533:INFO:Creating metrics dataframe
2025-11-21 17:00:29,533:INFO:Finalizing model
2025-11-21 17:00:30,502:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:30,517:INFO:Uploading results into container
2025-11-21 17:00:30,517:INFO:Uploading model into container now
2025-11-21 17:00:30,517:INFO:_master_model_container: 19
2025-11-21 17:00:30,517:INFO:_display_container: 5
2025-11-21 17:00:30,517:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 17:00:30,517:INFO:create_model() successfully completed......................................
2025-11-21 17:00:30,687:INFO:Initializing tune_model()
2025-11-21 17:00:30,687:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'class_weight': ['balanced', None], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 17:00:30,687:INFO:Checking exceptions
2025-11-21 17:00:30,708:INFO:Copying training dataset
2025-11-21 17:00:30,718:INFO:Checking base model
2025-11-21 17:00:30,718:INFO:Base model : Logistic Regression
2025-11-21 17:00:30,718:INFO:Declaring metric variables
2025-11-21 17:00:30,718:INFO:Defining Hyperparameters
2025-11-21 17:00:30,873:INFO:custom_grid: {'actual_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100], 'actual_estimator__class_weight': ['balanced', None], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-11-21 17:00:30,873:INFO:Tuning with n_jobs=-1
2025-11-21 17:00:30,873:INFO:Initializing RandomizedSearchCV
2025-11-21 17:00:31,635:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,644:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,672:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,675:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,719:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,773:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,781:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,847:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:31,857:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,353:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,374:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,408:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,412:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,437:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,449:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,457:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,464:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,474:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,487:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,497:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,558:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,581:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,664:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,684:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,741:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:32,993:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,051:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,088:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,094:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,123:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,159:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,174:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,180:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,212:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,243:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,253:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,312:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,316:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,331:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,453:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,490:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,580:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,611:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,621:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,673:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:33,983:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,034:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,045:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,065:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,086:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1}
2025-11-21 17:00:34,086:INFO:Hyperparameter search completed
2025-11-21 17:00:34,086:INFO:SubProcess create_model() called ==================================
2025-11-21 17:00:34,086:INFO:Initializing create_model()
2025-11-21 17:00:34,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDD95EE010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 1})
2025-11-21 17:00:34,086:INFO:Checking exceptions
2025-11-21 17:00:34,086:INFO:Importing libraries
2025-11-21 17:00:34,086:INFO:Copying training dataset
2025-11-21 17:00:34,099:INFO:Defining folds
2025-11-21 17:00:34,099:INFO:Declaring metric variables
2025-11-21 17:00:34,101:INFO:Importing untrained model
2025-11-21 17:00:34,101:INFO:Declaring custom model
2025-11-21 17:00:34,101:INFO:Logistic Regression Imported successfully
2025-11-21 17:00:34,111:INFO:Starting cross validation
2025-11-21 17:00:34,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:34,695:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,696:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,698:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,706:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,706:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,706:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,708:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,708:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,718:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,733:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:34,763:INFO:Calculating mean and std
2025-11-21 17:00:34,763:INFO:Creating metrics dataframe
2025-11-21 17:00:34,763:INFO:Finalizing model
2025-11-21 17:00:35,723:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:35,723:INFO:Uploading results into container
2025-11-21 17:00:35,731:INFO:Uploading model into container now
2025-11-21 17:00:35,732:INFO:_master_model_container: 20
2025-11-21 17:00:35,732:INFO:_display_container: 6
2025-11-21 17:00:35,732:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 17:00:35,732:INFO:create_model() successfully completed......................................
2025-11-21 17:00:35,888:INFO:SubProcess create_model() end ==================================
2025-11-21 17:00:35,888:INFO:choose_better activated
2025-11-21 17:00:35,888:INFO:SubProcess create_model() called ==================================
2025-11-21 17:00:35,888:INFO:Initializing create_model()
2025-11-21 17:00:35,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 17:00:35,888:INFO:Checking exceptions
2025-11-21 17:00:35,888:INFO:Importing libraries
2025-11-21 17:00:35,888:INFO:Copying training dataset
2025-11-21 17:00:35,904:INFO:Defining folds
2025-11-21 17:00:35,904:INFO:Declaring metric variables
2025-11-21 17:00:35,904:INFO:Importing untrained model
2025-11-21 17:00:35,904:INFO:Declaring custom model
2025-11-21 17:00:35,904:INFO:Logistic Regression Imported successfully
2025-11-21 17:00:35,904:INFO:Starting cross validation
2025-11-21 17:00:35,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:36,550:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,553:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,558:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,567:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,568:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,575:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,583:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,589:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,592:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:36,651:INFO:Calculating mean and std
2025-11-21 17:00:36,652:INFO:Creating metrics dataframe
2025-11-21 17:00:36,652:INFO:Finalizing model
2025-11-21 17:00:37,614:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 17:00:37,614:INFO:Uploading results into container
2025-11-21 17:00:37,614:INFO:Uploading model into container now
2025-11-21 17:00:37,614:INFO:_master_model_container: 21
2025-11-21 17:00:37,616:INFO:_display_container: 7
2025-11-21 17:00:37,616:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 17:00:37,616:INFO:create_model() successfully completed......................................
2025-11-21 17:00:37,766:INFO:SubProcess create_model() end ==================================
2025-11-21 17:00:37,766:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8128
2025-11-21 17:00:37,766:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8134
2025-11-21 17:00:37,766:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-11-21 17:00:37,766:INFO:choose_better completed
2025-11-21 17:00:37,782:INFO:_master_model_container: 21
2025-11-21 17:00:37,782:INFO:_display_container: 6
2025-11-21 17:00:37,782:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 17:00:37,782:INFO:tune_model() successfully completed......................................
2025-11-21 17:00:37,967:INFO:Initializing plot_model()
2025-11-21 17:00:37,967:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:00:37,967:INFO:Checking exceptions
2025-11-21 17:00:37,983:INFO:Preloading libraries
2025-11-21 17:00:37,983:INFO:Copying training dataset
2025-11-21 17:00:37,983:INFO:Plot type: confusion_matrix
2025-11-21 17:00:38,147:INFO:Fitting Model
2025-11-21 17:00:38,147:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-11-21 17:00:38,147:INFO:Scoring test/hold-out set
2025-11-21 17:00:38,285:INFO:Visual Rendered Successfully
2025-11-21 17:00:38,435:INFO:plot_model() successfully completed......................................
2025-11-21 17:00:38,460:INFO:Initializing plot_model()
2025-11-21 17:00:38,460:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:00:38,460:INFO:Checking exceptions
2025-11-21 17:00:38,467:INFO:Preloading libraries
2025-11-21 17:00:38,467:INFO:Copying training dataset
2025-11-21 17:00:38,467:INFO:Plot type: feature
2025-11-21 17:00:38,753:INFO:Visual Rendered Successfully
2025-11-21 17:00:38,910:INFO:plot_model() successfully completed......................................
2025-11-21 17:00:38,954:INFO:Initializing create_model()
2025-11-21 17:00:38,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 17:00:38,954:INFO:Checking exceptions
2025-11-21 17:00:38,973:INFO:Importing libraries
2025-11-21 17:00:38,973:INFO:Copying training dataset
2025-11-21 17:00:38,979:INFO:Defining folds
2025-11-21 17:00:38,979:INFO:Declaring metric variables
2025-11-21 17:00:38,987:INFO:Importing untrained model
2025-11-21 17:00:38,987:INFO:Random Forest Classifier Imported successfully
2025-11-21 17:00:38,996:INFO:Starting cross validation
2025-11-21 17:00:38,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:00:40,004:INFO:Calculating mean and std
2025-11-21 17:00:40,004:INFO:Creating metrics dataframe
2025-11-21 17:00:40,011:INFO:Finalizing model
2025-11-21 17:00:40,289:INFO:Uploading results into container
2025-11-21 17:00:40,289:INFO:Uploading model into container now
2025-11-21 17:00:40,294:INFO:_master_model_container: 22
2025-11-21 17:00:40,294:INFO:_display_container: 7
2025-11-21 17:00:40,294:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 17:00:40,294:INFO:create_model() successfully completed......................................
2025-11-21 17:00:40,454:INFO:Initializing tune_model()
2025-11-21 17:00:40,454:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', 'balanced_subsample', None]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 17:00:40,454:INFO:Checking exceptions
2025-11-21 17:00:40,476:INFO:Copying training dataset
2025-11-21 17:00:40,481:INFO:Checking base model
2025-11-21 17:00:40,481:INFO:Base model : Random Forest Classifier
2025-11-21 17:00:40,484:INFO:Declaring metric variables
2025-11-21 17:00:40,489:INFO:Defining Hyperparameters
2025-11-21 17:00:40,648:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [10, 20, None], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__criterion': ['gini', 'entropy'], 'actual_estimator__class_weight': ['balanced', 'balanced_subsample', None]}
2025-11-21 17:00:40,648:INFO:Tuning with n_jobs=-1
2025-11-21 17:00:40,648:INFO:Initializing RandomizedSearchCV
2025-11-21 17:00:59,570:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2025-11-21 17:00:59,570:INFO:Hyperparameter search completed
2025-11-21 17:00:59,570:INFO:SubProcess create_model() called ==================================
2025-11-21 17:00:59,570:INFO:Initializing create_model()
2025-11-21 17:00:59,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF043AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced'})
2025-11-21 17:00:59,570:INFO:Checking exceptions
2025-11-21 17:00:59,570:INFO:Importing libraries
2025-11-21 17:00:59,570:INFO:Copying training dataset
2025-11-21 17:00:59,584:INFO:Defining folds
2025-11-21 17:00:59,584:INFO:Declaring metric variables
2025-11-21 17:00:59,585:INFO:Importing untrained model
2025-11-21 17:00:59,585:INFO:Declaring custom model
2025-11-21 17:00:59,591:INFO:Random Forest Classifier Imported successfully
2025-11-21 17:00:59,599:INFO:Starting cross validation
2025-11-21 17:00:59,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:01:01,978:INFO:Calculating mean and std
2025-11-21 17:01:01,980:INFO:Creating metrics dataframe
2025-11-21 17:01:01,980:INFO:Finalizing model
2025-11-21 17:01:02,668:INFO:Uploading results into container
2025-11-21 17:01:02,668:INFO:Uploading model into container now
2025-11-21 17:01:02,670:INFO:_master_model_container: 23
2025-11-21 17:01:02,670:INFO:_display_container: 8
2025-11-21 17:01:02,672:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 17:01:02,672:INFO:create_model() successfully completed......................................
2025-11-21 17:01:02,842:INFO:SubProcess create_model() end ==================================
2025-11-21 17:01:02,842:INFO:choose_better activated
2025-11-21 17:01:02,842:INFO:SubProcess create_model() called ==================================
2025-11-21 17:01:02,842:INFO:Initializing create_model()
2025-11-21 17:01:02,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 17:01:02,842:INFO:Checking exceptions
2025-11-21 17:01:02,848:INFO:Importing libraries
2025-11-21 17:01:02,848:INFO:Copying training dataset
2025-11-21 17:01:02,857:INFO:Defining folds
2025-11-21 17:01:02,857:INFO:Declaring metric variables
2025-11-21 17:01:02,857:INFO:Importing untrained model
2025-11-21 17:01:02,857:INFO:Declaring custom model
2025-11-21 17:01:02,857:INFO:Random Forest Classifier Imported successfully
2025-11-21 17:01:02,857:INFO:Starting cross validation
2025-11-21 17:01:02,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 17:01:03,867:INFO:Calculating mean and std
2025-11-21 17:01:03,867:INFO:Creating metrics dataframe
2025-11-21 17:01:03,869:INFO:Finalizing model
2025-11-21 17:01:04,128:INFO:Uploading results into container
2025-11-21 17:01:04,128:INFO:Uploading model into container now
2025-11-21 17:01:04,128:INFO:_master_model_container: 24
2025-11-21 17:01:04,128:INFO:_display_container: 9
2025-11-21 17:01:04,128:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 17:01:04,128:INFO:create_model() successfully completed......................................
2025-11-21 17:01:04,285:INFO:SubProcess create_model() end ==================================
2025-11-21 17:01:04,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8219
2025-11-21 17:01:04,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8365
2025-11-21 17:01:04,285:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-11-21 17:01:04,285:INFO:choose_better completed
2025-11-21 17:01:04,302:INFO:_master_model_container: 24
2025-11-21 17:01:04,302:INFO:_display_container: 8
2025-11-21 17:01:04,302:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 17:01:04,302:INFO:tune_model() successfully completed......................................
2025-11-21 17:01:04,491:INFO:Initializing plot_model()
2025-11-21 17:01:04,491:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:01:04,491:INFO:Checking exceptions
2025-11-21 17:01:04,545:INFO:Preloading libraries
2025-11-21 17:01:04,578:INFO:Copying training dataset
2025-11-21 17:01:04,586:INFO:Plot type: confusion_matrix
2025-11-21 17:01:04,738:INFO:Fitting Model
2025-11-21 17:01:04,738:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-11-21 17:01:04,738:INFO:Scoring test/hold-out set
2025-11-21 17:01:05,039:INFO:Visual Rendered Successfully
2025-11-21 17:01:05,201:INFO:plot_model() successfully completed......................................
2025-11-21 17:01:05,221:INFO:Initializing plot_model()
2025-11-21 17:01:05,237:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0301ECD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 17:01:05,237:INFO:Checking exceptions
2025-11-21 17:01:05,286:INFO:Preloading libraries
2025-11-21 17:01:05,319:INFO:Copying training dataset
2025-11-21 17:01:05,319:INFO:Plot type: feature
2025-11-21 17:01:05,319:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 17:01:05,598:INFO:Visual Rendered Successfully
2025-11-21 17:01:05,764:INFO:plot_model() successfully completed......................................
2025-11-21 18:04:56,936:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 18:04:57,170:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 18:04:57,404:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 18:04:57,628:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:22: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.boxplot(x='EnrolledByAug312022', y=var, data=df, palette='Set2')

2025-11-21 18:04:57,867:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 18:04:58,038:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 18:04:58,228:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 18:04:58,414:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 18:04:58,621:WARNING:C:\Users\sivv1\AppData\Local\Temp\ipykernel_34388\3161557009.py:38: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=var, y='EnrolledByAug312022', data=prop, palette='pastel')

2025-11-21 18:04:58,835:INFO:PyCaret ClassificationExperiment
2025-11-21 18:04:58,835:INFO:Logging name: clf-default-name
2025-11-21 18:04:58,835:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-21 18:04:58,835:INFO:version 3.3.2
2025-11-21 18:04:58,835:INFO:Initializing setup()
2025-11-21 18:04:58,835:INFO:self.USI: 0c00
2025-11-21 18:04:58,835:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-21 18:04:58,835:INFO:Checking environment
2025-11-21 18:04:58,835:INFO:python_version: 3.11.9
2025-11-21 18:04:58,835:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-21 18:04:58,835:INFO:machine: AMD64
2025-11-21 18:04:58,835:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-21 18:04:58,835:INFO:Memory: svmem(total=16440479744, available=2636201984, percent=84.0, used=13804277760, free=2636201984)
2025-11-21 18:04:58,842:INFO:Physical Core: 8
2025-11-21 18:04:58,842:INFO:Logical Core: 16
2025-11-21 18:04:58,842:INFO:Checking libraries
2025-11-21 18:04:58,842:INFO:System:
2025-11-21 18:04:58,842:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-21 18:04:58,842:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-21 18:04:58,842:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-21 18:04:58,842:INFO:PyCaret required dependencies:
2025-11-21 18:04:58,842:INFO:                 pip: 24.0
2025-11-21 18:04:58,842:INFO:          setuptools: 65.5.0
2025-11-21 18:04:58,842:INFO:             pycaret: 3.3.2
2025-11-21 18:04:58,842:INFO:             IPython: 9.0.2
2025-11-21 18:04:58,842:INFO:          ipywidgets: 8.1.7
2025-11-21 18:04:58,842:INFO:                tqdm: 4.67.1
2025-11-21 18:04:58,842:INFO:               numpy: 1.26.4
2025-11-21 18:04:58,842:INFO:              pandas: 2.1.4
2025-11-21 18:04:58,842:INFO:              jinja2: 3.1.6
2025-11-21 18:04:58,842:INFO:               scipy: 1.11.4
2025-11-21 18:04:58,842:INFO:              joblib: 1.3.2
2025-11-21 18:04:58,842:INFO:             sklearn: 1.4.2
2025-11-21 18:04:58,842:INFO:                pyod: 2.0.5
2025-11-21 18:04:58,842:INFO:            imblearn: 0.14.0
2025-11-21 18:04:58,842:INFO:   category_encoders: 2.7.0
2025-11-21 18:04:58,842:INFO:            lightgbm: 4.6.0
2025-11-21 18:04:58,842:INFO:               numba: 0.61.2
2025-11-21 18:04:58,842:INFO:            requests: 2.32.5
2025-11-21 18:04:58,842:INFO:          matplotlib: 3.7.5
2025-11-21 18:04:58,842:INFO:          scikitplot: 0.3.7
2025-11-21 18:04:58,842:INFO:         yellowbrick: 1.5
2025-11-21 18:04:58,842:INFO:              plotly: 6.3.0
2025-11-21 18:04:58,842:INFO:    plotly-resampler: Not installed
2025-11-21 18:04:58,842:INFO:             kaleido: 1.1.0
2025-11-21 18:04:58,842:INFO:           schemdraw: 0.15
2025-11-21 18:04:58,842:INFO:         statsmodels: 0.14.5
2025-11-21 18:04:58,842:INFO:              sktime: 0.26.0
2025-11-21 18:04:58,842:INFO:               tbats: 1.1.3
2025-11-21 18:04:58,842:INFO:            pmdarima: 2.0.4
2025-11-21 18:04:58,842:INFO:              psutil: 7.0.0
2025-11-21 18:04:58,842:INFO:          markupsafe: 3.0.2
2025-11-21 18:04:58,842:INFO:             pickle5: Not installed
2025-11-21 18:04:58,842:INFO:         cloudpickle: 3.1.1
2025-11-21 18:04:58,842:INFO:         deprecation: 2.1.0
2025-11-21 18:04:58,842:INFO:              xxhash: 3.5.0
2025-11-21 18:04:58,842:INFO:           wurlitzer: Not installed
2025-11-21 18:04:58,842:INFO:PyCaret optional dependencies:
2025-11-21 18:04:58,842:INFO:                shap: 0.48.0
2025-11-21 18:04:58,842:INFO:           interpret: Not installed
2025-11-21 18:04:58,842:INFO:                umap: 0.5.7
2025-11-21 18:04:58,842:INFO:     ydata_profiling: Not installed
2025-11-21 18:04:58,842:INFO:  explainerdashboard: Not installed
2025-11-21 18:04:58,842:INFO:             autoviz: Not installed
2025-11-21 18:04:58,842:INFO:           fairlearn: Not installed
2025-11-21 18:04:58,842:INFO:          deepchecks: Not installed
2025-11-21 18:04:58,842:INFO:             xgboost: 3.0.5
2025-11-21 18:04:58,842:INFO:            catboost: Not installed
2025-11-21 18:04:58,842:INFO:              kmodes: Not installed
2025-11-21 18:04:58,842:INFO:             mlxtend: Not installed
2025-11-21 18:04:58,842:INFO:       statsforecast: Not installed
2025-11-21 18:04:58,842:INFO:        tune_sklearn: Not installed
2025-11-21 18:04:58,842:INFO:                 ray: Not installed
2025-11-21 18:04:58,842:INFO:            hyperopt: Not installed
2025-11-21 18:04:58,842:INFO:              optuna: 4.5.0
2025-11-21 18:04:58,842:INFO:               skopt: Not installed
2025-11-21 18:04:58,842:INFO:              mlflow: Not installed
2025-11-21 18:04:58,842:INFO:              gradio: Not installed
2025-11-21 18:04:58,842:INFO:             fastapi: Not installed
2025-11-21 18:04:58,842:INFO:             uvicorn: Not installed
2025-11-21 18:04:58,842:INFO:              m2cgen: Not installed
2025-11-21 18:04:58,842:INFO:           evidently: Not installed
2025-11-21 18:04:58,842:INFO:               fugue: Not installed
2025-11-21 18:04:58,842:INFO:           streamlit: Not installed
2025-11-21 18:04:58,842:INFO:             prophet: Not installed
2025-11-21 18:04:58,842:INFO:None
2025-11-21 18:04:58,842:INFO:Set up data.
2025-11-21 18:04:58,855:INFO:Set up folding strategy.
2025-11-21 18:04:58,857:INFO:Set up train/test split.
2025-11-21 18:04:58,876:INFO:Set up index.
2025-11-21 18:04:58,878:INFO:Assigning column types.
2025-11-21 18:04:58,880:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-21 18:04:58,936:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 18:04:58,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:04:58,975:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:58,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 18:04:59,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:04:59,092:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-21 18:04:59,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:04:59,196:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:04:59,317:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,317:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-21 18:04:59,413:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,503:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:04:59,533:INFO:Preparing preprocessing pipeline...
2025-11-21 18:04:59,533:INFO:Set up date feature engineering.
2025-11-21 18:04:59,533:INFO:Set up simple imputation.
2025-11-21 18:04:59,600:INFO:Finished creating preprocessing pipeline.
2025-11-21 18:04:59,600:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-21 18:04:59,600:INFO:Creating final display dataframe.
2025-11-21 18:04:59,775:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 20)
5   Transformed train set shape           (5961, 20)
6    Transformed test set shape           (2555, 20)
7               Ignore features                    1
8              Numeric features                   16
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 0c00
2025-11-21 18:04:59,919:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:04:59,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:05:00,003:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:05:00,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:05:00,005:INFO:setup() successfully completed in 1.21s...............
2025-11-21 18:05:00,017:INFO:Initializing compare_models()
2025-11-21 18:05:00,017:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-21 18:05:00,017:INFO:Checking exceptions
2025-11-21 18:05:00,033:INFO:Preparing display monitor
2025-11-21 18:05:00,065:INFO:Initializing Logistic Regression
2025-11-21 18:05:00,065:INFO:Total runtime is 0.0 minutes
2025-11-21 18:05:00,065:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:00,065:INFO:Initializing create_model()
2025-11-21 18:05:00,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:00,071:INFO:Checking exceptions
2025-11-21 18:05:00,071:INFO:Importing libraries
2025-11-21 18:05:00,071:INFO:Copying training dataset
2025-11-21 18:05:00,081:INFO:Defining folds
2025-11-21 18:05:00,081:INFO:Declaring metric variables
2025-11-21 18:05:00,081:INFO:Importing untrained model
2025-11-21 18:05:00,088:INFO:Logistic Regression Imported successfully
2025-11-21 18:05:00,098:INFO:Starting cross validation
2025-11-21 18:05:00,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,245:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:05:13,287:INFO:Calculating mean and std
2025-11-21 18:05:13,289:INFO:Creating metrics dataframe
2025-11-21 18:05:13,296:INFO:Uploading results into container
2025-11-21 18:05:13,296:INFO:Uploading model into container now
2025-11-21 18:05:13,298:INFO:_master_model_container: 1
2025-11-21 18:05:13,298:INFO:_display_container: 2
2025-11-21 18:05:13,300:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:05:13,300:INFO:create_model() successfully completed......................................
2025-11-21 18:05:13,950:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:13,950:INFO:Creating metrics dataframe
2025-11-21 18:05:13,956:INFO:Initializing K Neighbors Classifier
2025-11-21 18:05:13,956:INFO:Total runtime is 0.23151082992553712 minutes
2025-11-21 18:05:13,962:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:13,962:INFO:Initializing create_model()
2025-11-21 18:05:13,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:13,962:INFO:Checking exceptions
2025-11-21 18:05:13,962:INFO:Importing libraries
2025-11-21 18:05:13,962:INFO:Copying training dataset
2025-11-21 18:05:13,974:INFO:Defining folds
2025-11-21 18:05:13,974:INFO:Declaring metric variables
2025-11-21 18:05:13,976:INFO:Importing untrained model
2025-11-21 18:05:13,976:INFO:K Neighbors Classifier Imported successfully
2025-11-21 18:05:13,976:INFO:Starting cross validation
2025-11-21 18:05:13,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:18,737:INFO:Calculating mean and std
2025-11-21 18:05:18,739:INFO:Creating metrics dataframe
2025-11-21 18:05:18,741:INFO:Uploading results into container
2025-11-21 18:05:18,743:INFO:Uploading model into container now
2025-11-21 18:05:18,744:INFO:_master_model_container: 2
2025-11-21 18:05:18,744:INFO:_display_container: 2
2025-11-21 18:05:18,745:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-21 18:05:18,745:INFO:create_model() successfully completed......................................
2025-11-21 18:05:18,943:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:18,943:INFO:Creating metrics dataframe
2025-11-21 18:05:18,952:INFO:Initializing Naive Bayes
2025-11-21 18:05:18,954:INFO:Total runtime is 0.3148061672846476 minutes
2025-11-21 18:05:18,954:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:18,959:INFO:Initializing create_model()
2025-11-21 18:05:18,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:18,959:INFO:Checking exceptions
2025-11-21 18:05:18,959:INFO:Importing libraries
2025-11-21 18:05:18,959:INFO:Copying training dataset
2025-11-21 18:05:18,968:INFO:Defining folds
2025-11-21 18:05:18,972:INFO:Declaring metric variables
2025-11-21 18:05:18,974:INFO:Importing untrained model
2025-11-21 18:05:18,981:INFO:Naive Bayes Imported successfully
2025-11-21 18:05:18,988:INFO:Starting cross validation
2025-11-21 18:05:18,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:19,120:INFO:Calculating mean and std
2025-11-21 18:05:19,120:INFO:Creating metrics dataframe
2025-11-21 18:05:19,120:INFO:Uploading results into container
2025-11-21 18:05:19,124:INFO:Uploading model into container now
2025-11-21 18:05:19,124:INFO:_master_model_container: 3
2025-11-21 18:05:19,124:INFO:_display_container: 2
2025-11-21 18:05:19,124:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-21 18:05:19,124:INFO:create_model() successfully completed......................................
2025-11-21 18:05:19,301:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:19,301:INFO:Creating metrics dataframe
2025-11-21 18:05:19,308:INFO:Initializing Decision Tree Classifier
2025-11-21 18:05:19,308:INFO:Total runtime is 0.3207183917363485 minutes
2025-11-21 18:05:19,315:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:19,315:INFO:Initializing create_model()
2025-11-21 18:05:19,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:19,315:INFO:Checking exceptions
2025-11-21 18:05:19,315:INFO:Importing libraries
2025-11-21 18:05:19,315:INFO:Copying training dataset
2025-11-21 18:05:19,327:INFO:Defining folds
2025-11-21 18:05:19,327:INFO:Declaring metric variables
2025-11-21 18:05:19,332:INFO:Importing untrained model
2025-11-21 18:05:19,332:INFO:Decision Tree Classifier Imported successfully
2025-11-21 18:05:19,341:INFO:Starting cross validation
2025-11-21 18:05:19,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:19,504:INFO:Calculating mean and std
2025-11-21 18:05:19,505:INFO:Creating metrics dataframe
2025-11-21 18:05:19,507:INFO:Uploading results into container
2025-11-21 18:05:19,508:INFO:Uploading model into container now
2025-11-21 18:05:19,509:INFO:_master_model_container: 4
2025-11-21 18:05:19,509:INFO:_display_container: 2
2025-11-21 18:05:19,509:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-21 18:05:19,509:INFO:create_model() successfully completed......................................
2025-11-21 18:05:19,675:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:19,675:INFO:Creating metrics dataframe
2025-11-21 18:05:19,683:INFO:Initializing SVM - Linear Kernel
2025-11-21 18:05:19,683:INFO:Total runtime is 0.3269633968671163 minutes
2025-11-21 18:05:19,687:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:19,688:INFO:Initializing create_model()
2025-11-21 18:05:19,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:19,688:INFO:Checking exceptions
2025-11-21 18:05:19,688:INFO:Importing libraries
2025-11-21 18:05:19,688:INFO:Copying training dataset
2025-11-21 18:05:19,699:INFO:Defining folds
2025-11-21 18:05:19,699:INFO:Declaring metric variables
2025-11-21 18:05:19,703:INFO:Importing untrained model
2025-11-21 18:05:19,707:INFO:SVM - Linear Kernel Imported successfully
2025-11-21 18:05:19,712:INFO:Starting cross validation
2025-11-21 18:05:19,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:19,851:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 18:05:19,865:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 18:05:19,912:INFO:Calculating mean and std
2025-11-21 18:05:19,912:INFO:Creating metrics dataframe
2025-11-21 18:05:19,915:INFO:Uploading results into container
2025-11-21 18:05:19,915:INFO:Uploading model into container now
2025-11-21 18:05:19,915:INFO:_master_model_container: 5
2025-11-21 18:05:19,915:INFO:_display_container: 2
2025-11-21 18:05:19,917:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-21 18:05:19,917:INFO:create_model() successfully completed......................................
2025-11-21 18:05:20,084:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:20,084:INFO:Creating metrics dataframe
2025-11-21 18:05:20,107:INFO:Initializing Ridge Classifier
2025-11-21 18:05:20,107:INFO:Total runtime is 0.3340250809987386 minutes
2025-11-21 18:05:20,113:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:20,113:INFO:Initializing create_model()
2025-11-21 18:05:20,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:20,113:INFO:Checking exceptions
2025-11-21 18:05:20,113:INFO:Importing libraries
2025-11-21 18:05:20,113:INFO:Copying training dataset
2025-11-21 18:05:20,124:INFO:Defining folds
2025-11-21 18:05:20,124:INFO:Declaring metric variables
2025-11-21 18:05:20,127:INFO:Importing untrained model
2025-11-21 18:05:20,127:INFO:Ridge Classifier Imported successfully
2025-11-21 18:05:20,140:INFO:Starting cross validation
2025-11-21 18:05:20,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:20,257:INFO:Calculating mean and std
2025-11-21 18:05:20,259:INFO:Creating metrics dataframe
2025-11-21 18:05:20,260:INFO:Uploading results into container
2025-11-21 18:05:20,260:INFO:Uploading model into container now
2025-11-21 18:05:20,260:INFO:_master_model_container: 6
2025-11-21 18:05:20,260:INFO:_display_container: 2
2025-11-21 18:05:20,260:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-21 18:05:20,260:INFO:create_model() successfully completed......................................
2025-11-21 18:05:20,429:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:20,429:INFO:Creating metrics dataframe
2025-11-21 18:05:20,456:INFO:Initializing Random Forest Classifier
2025-11-21 18:05:20,456:INFO:Total runtime is 0.33984893560409546 minutes
2025-11-21 18:05:20,462:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:20,462:INFO:Initializing create_model()
2025-11-21 18:05:20,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:20,462:INFO:Checking exceptions
2025-11-21 18:05:20,462:INFO:Importing libraries
2025-11-21 18:05:20,462:INFO:Copying training dataset
2025-11-21 18:05:20,474:INFO:Defining folds
2025-11-21 18:05:20,474:INFO:Declaring metric variables
2025-11-21 18:05:20,475:INFO:Importing untrained model
2025-11-21 18:05:20,482:INFO:Random Forest Classifier Imported successfully
2025-11-21 18:05:20,488:INFO:Starting cross validation
2025-11-21 18:05:20,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:21,597:INFO:Calculating mean and std
2025-11-21 18:05:21,600:INFO:Creating metrics dataframe
2025-11-21 18:05:21,600:INFO:Uploading results into container
2025-11-21 18:05:21,600:INFO:Uploading model into container now
2025-11-21 18:05:21,600:INFO:_master_model_container: 7
2025-11-21 18:05:21,605:INFO:_display_container: 2
2025-11-21 18:05:21,605:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:05:21,606:INFO:create_model() successfully completed......................................
2025-11-21 18:05:21,786:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:21,786:INFO:Creating metrics dataframe
2025-11-21 18:05:21,795:INFO:Initializing Quadratic Discriminant Analysis
2025-11-21 18:05:21,796:INFO:Total runtime is 0.36217533349990844 minutes
2025-11-21 18:05:21,799:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:21,800:INFO:Initializing create_model()
2025-11-21 18:05:21,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:21,800:INFO:Checking exceptions
2025-11-21 18:05:21,800:INFO:Importing libraries
2025-11-21 18:05:21,800:INFO:Copying training dataset
2025-11-21 18:05:21,808:INFO:Defining folds
2025-11-21 18:05:21,808:INFO:Declaring metric variables
2025-11-21 18:05:21,815:INFO:Importing untrained model
2025-11-21 18:05:21,820:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-21 18:05:21,829:INFO:Starting cross validation
2025-11-21 18:05:21,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,927:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:05:21,978:INFO:Calculating mean and std
2025-11-21 18:05:21,978:INFO:Creating metrics dataframe
2025-11-21 18:05:21,982:INFO:Uploading results into container
2025-11-21 18:05:21,982:INFO:Uploading model into container now
2025-11-21 18:05:21,982:INFO:_master_model_container: 8
2025-11-21 18:05:21,982:INFO:_display_container: 2
2025-11-21 18:05:21,982:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-21 18:05:21,982:INFO:create_model() successfully completed......................................
2025-11-21 18:05:22,137:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:22,140:INFO:Creating metrics dataframe
2025-11-21 18:05:22,142:INFO:Initializing Ada Boost Classifier
2025-11-21 18:05:22,142:INFO:Total runtime is 0.3679432551066081 minutes
2025-11-21 18:05:22,142:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:22,153:INFO:Initializing create_model()
2025-11-21 18:05:22,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:22,153:INFO:Checking exceptions
2025-11-21 18:05:22,153:INFO:Importing libraries
2025-11-21 18:05:22,153:INFO:Copying training dataset
2025-11-21 18:05:22,161:INFO:Defining folds
2025-11-21 18:05:22,161:INFO:Declaring metric variables
2025-11-21 18:05:22,169:INFO:Importing untrained model
2025-11-21 18:05:22,171:INFO:Ada Boost Classifier Imported successfully
2025-11-21 18:05:22,179:INFO:Starting cross validation
2025-11-21 18:05:22,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:22,231:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,231:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,231:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,241:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,241:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,247:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,247:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,247:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,248:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,248:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:05:22,716:INFO:Calculating mean and std
2025-11-21 18:05:22,717:INFO:Creating metrics dataframe
2025-11-21 18:05:22,717:INFO:Uploading results into container
2025-11-21 18:05:22,717:INFO:Uploading model into container now
2025-11-21 18:05:22,717:INFO:_master_model_container: 9
2025-11-21 18:05:22,717:INFO:_display_container: 2
2025-11-21 18:05:22,717:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-21 18:05:22,717:INFO:create_model() successfully completed......................................
2025-11-21 18:05:22,876:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:22,876:INFO:Creating metrics dataframe
2025-11-21 18:05:22,891:INFO:Initializing Gradient Boosting Classifier
2025-11-21 18:05:22,891:INFO:Total runtime is 0.3804219841957092 minutes
2025-11-21 18:05:22,897:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:22,897:INFO:Initializing create_model()
2025-11-21 18:05:22,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:22,898:INFO:Checking exceptions
2025-11-21 18:05:22,898:INFO:Importing libraries
2025-11-21 18:05:22,898:INFO:Copying training dataset
2025-11-21 18:05:22,905:INFO:Defining folds
2025-11-21 18:05:22,905:INFO:Declaring metric variables
2025-11-21 18:05:22,911:INFO:Importing untrained model
2025-11-21 18:05:22,916:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:05:22,922:INFO:Starting cross validation
2025-11-21 18:05:22,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:24,249:INFO:Calculating mean and std
2025-11-21 18:05:24,251:INFO:Creating metrics dataframe
2025-11-21 18:05:24,253:INFO:Uploading results into container
2025-11-21 18:05:24,253:INFO:Uploading model into container now
2025-11-21 18:05:24,253:INFO:_master_model_container: 10
2025-11-21 18:05:24,253:INFO:_display_container: 2
2025-11-21 18:05:24,253:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:05:24,253:INFO:create_model() successfully completed......................................
2025-11-21 18:05:24,409:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:24,409:INFO:Creating metrics dataframe
2025-11-21 18:05:24,424:INFO:Initializing Linear Discriminant Analysis
2025-11-21 18:05:24,424:INFO:Total runtime is 0.4059839963912964 minutes
2025-11-21 18:05:24,424:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:24,424:INFO:Initializing create_model()
2025-11-21 18:05:24,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:24,424:INFO:Checking exceptions
2025-11-21 18:05:24,424:INFO:Importing libraries
2025-11-21 18:05:24,424:INFO:Copying training dataset
2025-11-21 18:05:24,440:INFO:Defining folds
2025-11-21 18:05:24,440:INFO:Declaring metric variables
2025-11-21 18:05:24,445:INFO:Importing untrained model
2025-11-21 18:05:24,450:INFO:Linear Discriminant Analysis Imported successfully
2025-11-21 18:05:24,455:INFO:Starting cross validation
2025-11-21 18:05:24,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:24,573:INFO:Calculating mean and std
2025-11-21 18:05:24,573:INFO:Creating metrics dataframe
2025-11-21 18:05:24,575:INFO:Uploading results into container
2025-11-21 18:05:24,575:INFO:Uploading model into container now
2025-11-21 18:05:24,575:INFO:_master_model_container: 11
2025-11-21 18:05:24,575:INFO:_display_container: 2
2025-11-21 18:05:24,575:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-21 18:05:24,575:INFO:create_model() successfully completed......................................
2025-11-21 18:05:24,732:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:24,732:INFO:Creating metrics dataframe
2025-11-21 18:05:24,732:INFO:Initializing Extra Trees Classifier
2025-11-21 18:05:24,732:INFO:Total runtime is 0.41111496289571126 minutes
2025-11-21 18:05:24,749:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:24,750:INFO:Initializing create_model()
2025-11-21 18:05:24,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:24,750:INFO:Checking exceptions
2025-11-21 18:05:24,750:INFO:Importing libraries
2025-11-21 18:05:24,750:INFO:Copying training dataset
2025-11-21 18:05:24,758:INFO:Defining folds
2025-11-21 18:05:24,758:INFO:Declaring metric variables
2025-11-21 18:05:24,763:INFO:Importing untrained model
2025-11-21 18:05:24,765:INFO:Extra Trees Classifier Imported successfully
2025-11-21 18:05:24,771:INFO:Starting cross validation
2025-11-21 18:05:24,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:25,587:INFO:Calculating mean and std
2025-11-21 18:05:25,588:INFO:Creating metrics dataframe
2025-11-21 18:05:25,591:INFO:Uploading results into container
2025-11-21 18:05:25,591:INFO:Uploading model into container now
2025-11-21 18:05:25,591:INFO:_master_model_container: 12
2025-11-21 18:05:25,591:INFO:_display_container: 2
2025-11-21 18:05:25,591:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-21 18:05:25,591:INFO:create_model() successfully completed......................................
2025-11-21 18:05:25,758:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:25,758:INFO:Creating metrics dataframe
2025-11-21 18:05:25,769:INFO:Initializing Extreme Gradient Boosting
2025-11-21 18:05:25,769:INFO:Total runtime is 0.4283882737159729 minutes
2025-11-21 18:05:25,772:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:25,772:INFO:Initializing create_model()
2025-11-21 18:05:25,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:25,772:INFO:Checking exceptions
2025-11-21 18:05:25,772:INFO:Importing libraries
2025-11-21 18:05:25,772:INFO:Copying training dataset
2025-11-21 18:05:25,787:INFO:Defining folds
2025-11-21 18:05:25,787:INFO:Declaring metric variables
2025-11-21 18:05:25,787:INFO:Importing untrained model
2025-11-21 18:05:25,797:INFO:Extreme Gradient Boosting Imported successfully
2025-11-21 18:05:25,801:INFO:Starting cross validation
2025-11-21 18:05:25,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:27,315:INFO:Calculating mean and std
2025-11-21 18:05:27,316:INFO:Creating metrics dataframe
2025-11-21 18:05:27,316:INFO:Uploading results into container
2025-11-21 18:05:27,319:INFO:Uploading model into container now
2025-11-21 18:05:27,319:INFO:_master_model_container: 13
2025-11-21 18:05:27,319:INFO:_display_container: 2
2025-11-21 18:05:27,319:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-21 18:05:27,319:INFO:create_model() successfully completed......................................
2025-11-21 18:05:27,477:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:27,477:INFO:Creating metrics dataframe
2025-11-21 18:05:27,487:INFO:Initializing Light Gradient Boosting Machine
2025-11-21 18:05:27,495:INFO:Total runtime is 0.45716487169265746 minutes
2025-11-21 18:05:27,495:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:27,495:INFO:Initializing create_model()
2025-11-21 18:05:27,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:27,495:INFO:Checking exceptions
2025-11-21 18:05:27,495:INFO:Importing libraries
2025-11-21 18:05:27,495:INFO:Copying training dataset
2025-11-21 18:05:27,501:INFO:Defining folds
2025-11-21 18:05:27,501:INFO:Declaring metric variables
2025-11-21 18:05:27,515:INFO:Importing untrained model
2025-11-21 18:05:27,519:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-21 18:05:27,525:INFO:Starting cross validation
2025-11-21 18:05:27,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:31,769:INFO:Calculating mean and std
2025-11-21 18:05:31,773:INFO:Creating metrics dataframe
2025-11-21 18:05:31,777:INFO:Uploading results into container
2025-11-21 18:05:31,777:INFO:Uploading model into container now
2025-11-21 18:05:31,780:INFO:_master_model_container: 14
2025-11-21 18:05:31,780:INFO:_display_container: 2
2025-11-21 18:05:31,782:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-21 18:05:31,784:INFO:create_model() successfully completed......................................
2025-11-21 18:05:31,955:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:31,955:INFO:Creating metrics dataframe
2025-11-21 18:05:31,966:INFO:Initializing Dummy Classifier
2025-11-21 18:05:31,966:INFO:Total runtime is 0.5316771189371745 minutes
2025-11-21 18:05:31,973:INFO:SubProcess create_model() called ==================================
2025-11-21 18:05:31,976:INFO:Initializing create_model()
2025-11-21 18:05:31,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFDF31610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:31,976:INFO:Checking exceptions
2025-11-21 18:05:31,977:INFO:Importing libraries
2025-11-21 18:05:31,977:INFO:Copying training dataset
2025-11-21 18:05:31,987:INFO:Defining folds
2025-11-21 18:05:31,987:INFO:Declaring metric variables
2025-11-21 18:05:31,988:INFO:Importing untrained model
2025-11-21 18:05:31,993:INFO:Dummy Classifier Imported successfully
2025-11-21 18:05:32,003:INFO:Starting cross validation
2025-11-21 18:05:32,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:32,110:INFO:Calculating mean and std
2025-11-21 18:05:32,110:INFO:Creating metrics dataframe
2025-11-21 18:05:32,110:INFO:Uploading results into container
2025-11-21 18:05:32,110:INFO:Uploading model into container now
2025-11-21 18:05:32,110:INFO:_master_model_container: 15
2025-11-21 18:05:32,115:INFO:_display_container: 2
2025-11-21 18:05:32,116:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-21 18:05:32,116:INFO:create_model() successfully completed......................................
2025-11-21 18:05:32,274:INFO:SubProcess create_model() end ==================================
2025-11-21 18:05:32,274:INFO:Creating metrics dataframe
2025-11-21 18:05:32,288:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-21 18:05:32,300:INFO:Initializing create_model()
2025-11-21 18:05:32,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:32,300:INFO:Checking exceptions
2025-11-21 18:05:32,301:INFO:Importing libraries
2025-11-21 18:05:32,302:INFO:Copying training dataset
2025-11-21 18:05:32,307:INFO:Defining folds
2025-11-21 18:05:32,307:INFO:Declaring metric variables
2025-11-21 18:05:32,307:INFO:Importing untrained model
2025-11-21 18:05:32,307:INFO:Declaring custom model
2025-11-21 18:05:32,307:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:05:32,307:INFO:Cross validation set to False
2025-11-21 18:05:32,307:INFO:Fitting Model
2025-11-21 18:05:33,676:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:05:33,676:INFO:create_model() successfully completed......................................
2025-11-21 18:05:33,869:INFO:_master_model_container: 15
2025-11-21 18:05:33,869:INFO:_display_container: 2
2025-11-21 18:05:33,869:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:05:33,869:INFO:compare_models() successfully completed......................................
2025-11-21 18:05:33,910:INFO:Initializing create_model()
2025-11-21 18:05:33,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:05:33,910:INFO:Checking exceptions
2025-11-21 18:05:33,927:INFO:Importing libraries
2025-11-21 18:05:33,927:INFO:Copying training dataset
2025-11-21 18:05:33,942:INFO:Defining folds
2025-11-21 18:05:33,942:INFO:Declaring metric variables
2025-11-21 18:05:33,945:INFO:Importing untrained model
2025-11-21 18:05:33,948:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:05:33,958:INFO:Starting cross validation
2025-11-21 18:05:33,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:05:35,223:INFO:Calculating mean and std
2025-11-21 18:05:35,223:INFO:Creating metrics dataframe
2025-11-21 18:05:35,232:INFO:Finalizing model
2025-11-21 18:05:36,401:INFO:Uploading results into container
2025-11-21 18:05:36,401:INFO:Uploading model into container now
2025-11-21 18:05:36,410:INFO:_master_model_container: 16
2025-11-21 18:05:36,410:INFO:_display_container: 3
2025-11-21 18:05:36,410:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:05:36,410:INFO:create_model() successfully completed......................................
2025-11-21 18:05:36,587:INFO:Initializing tune_model()
2025-11-21 18:05:36,587:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 18:05:36,593:INFO:Checking exceptions
2025-11-21 18:05:36,613:INFO:Copying training dataset
2025-11-21 18:05:36,620:INFO:Checking base model
2025-11-21 18:05:36,620:INFO:Base model : Gradient Boosting Classifier
2025-11-21 18:05:36,620:INFO:Declaring metric variables
2025-11-21 18:05:36,626:INFO:Defining Hyperparameters
2025-11-21 18:05:36,794:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-21 18:05:36,794:INFO:Tuning with n_jobs=-1
2025-11-21 18:05:36,794:INFO:Initializing RandomizedSearchCV
2025-11-21 18:06:01,038:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-21 18:06:01,038:INFO:Hyperparameter search completed
2025-11-21 18:06:01,038:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:01,042:INFO:Initializing create_model()
2025-11-21 18:06:01,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDBB02B250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-21 18:06:01,043:INFO:Checking exceptions
2025-11-21 18:06:01,043:INFO:Importing libraries
2025-11-21 18:06:01,043:INFO:Copying training dataset
2025-11-21 18:06:01,051:INFO:Defining folds
2025-11-21 18:06:01,051:INFO:Declaring metric variables
2025-11-21 18:06:01,058:INFO:Importing untrained model
2025-11-21 18:06:01,058:INFO:Declaring custom model
2025-11-21 18:06:01,060:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:01,071:INFO:Starting cross validation
2025-11-21 18:06:01,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:02,202:INFO:Calculating mean and std
2025-11-21 18:06:02,202:INFO:Creating metrics dataframe
2025-11-21 18:06:02,209:INFO:Finalizing model
2025-11-21 18:06:03,328:INFO:Uploading results into container
2025-11-21 18:06:03,330:INFO:Uploading model into container now
2025-11-21 18:06:03,330:INFO:_master_model_container: 17
2025-11-21 18:06:03,330:INFO:_display_container: 4
2025-11-21 18:06:03,330:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:03,330:INFO:create_model() successfully completed......................................
2025-11-21 18:06:03,508:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:03,508:INFO:choose_better activated
2025-11-21 18:06:03,510:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:03,510:INFO:Initializing create_model()
2025-11-21 18:06:03,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:03,514:INFO:Checking exceptions
2025-11-21 18:06:03,514:INFO:Importing libraries
2025-11-21 18:06:03,514:INFO:Copying training dataset
2025-11-21 18:06:03,514:INFO:Defining folds
2025-11-21 18:06:03,524:INFO:Declaring metric variables
2025-11-21 18:06:03,524:INFO:Importing untrained model
2025-11-21 18:06:03,524:INFO:Declaring custom model
2025-11-21 18:06:03,524:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:03,524:INFO:Starting cross validation
2025-11-21 18:06:03,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:04,804:INFO:Calculating mean and std
2025-11-21 18:06:04,804:INFO:Creating metrics dataframe
2025-11-21 18:06:04,804:INFO:Finalizing model
2025-11-21 18:06:05,969:INFO:Uploading results into container
2025-11-21 18:06:05,969:INFO:Uploading model into container now
2025-11-21 18:06:05,969:INFO:_master_model_container: 18
2025-11-21 18:06:05,969:INFO:_display_container: 5
2025-11-21 18:06:05,969:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:05,969:INFO:create_model() successfully completed......................................
2025-11-21 18:06:06,214:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:06,214:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9418
2025-11-21 18:06:06,214:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.942
2025-11-21 18:06:06,214:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-21 18:06:06,214:INFO:choose_better completed
2025-11-21 18:06:06,232:INFO:_master_model_container: 18
2025-11-21 18:06:06,232:INFO:_display_container: 4
2025-11-21 18:06:06,232:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:06,232:INFO:tune_model() successfully completed......................................
2025-11-21 18:06:06,445:INFO:Initializing plot_model()
2025-11-21 18:06:06,445:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:06:06,445:INFO:Checking exceptions
2025-11-21 18:06:06,454:INFO:Preloading libraries
2025-11-21 18:06:06,467:INFO:Copying training dataset
2025-11-21 18:06:06,467:INFO:Plot type: confusion_matrix
2025-11-21 18:06:06,631:INFO:Fitting Model
2025-11-21 18:06:06,631:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-21 18:06:06,631:INFO:Scoring test/hold-out set
2025-11-21 18:06:06,811:INFO:Visual Rendered Successfully
2025-11-21 18:06:06,972:INFO:plot_model() successfully completed......................................
2025-11-21 18:06:06,992:INFO:Initializing plot_model()
2025-11-21 18:06:06,992:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C15D810>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:06:06,992:INFO:Checking exceptions
2025-11-21 18:06:07,002:INFO:Preloading libraries
2025-11-21 18:06:07,010:INFO:Copying training dataset
2025-11-21 18:06:07,010:INFO:Plot type: feature
2025-11-21 18:06:07,010:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 18:06:07,321:INFO:Visual Rendered Successfully
2025-11-21 18:06:07,472:INFO:plot_model() successfully completed......................................
2025-11-21 18:06:07,521:INFO:PyCaret ClassificationExperiment
2025-11-21 18:06:07,521:INFO:Logging name: clf-default-name
2025-11-21 18:06:07,522:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-21 18:06:07,522:INFO:version 3.3.2
2025-11-21 18:06:07,522:INFO:Initializing setup()
2025-11-21 18:06:07,522:INFO:self.USI: cec9
2025-11-21 18:06:07,522:INFO:self._variable_keys: {'seed', 'y_train', 'X_test', 'exp_name_log', '_available_plots', 'gpu_n_jobs_param', 'memory', 'fold_shuffle_param', 'target_param', 'USI', '_ml_usecase', 'gpu_param', 'n_jobs_param', 'pipeline', 'html_param', 'y_test', 'logging_param', 'fold_generator', 'X', 'idx', 'y', 'fix_imbalance', 'fold_groups_param', 'exp_id', 'is_multiclass', 'log_plots_param', 'data', 'X_train'}
2025-11-21 18:06:07,522:INFO:Checking environment
2025-11-21 18:06:07,522:INFO:python_version: 3.11.9
2025-11-21 18:06:07,522:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-21 18:06:07,522:INFO:machine: AMD64
2025-11-21 18:06:07,522:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-21 18:06:07,522:INFO:Memory: svmem(total=16440479744, available=1454338048, percent=91.2, used=14986141696, free=1454338048)
2025-11-21 18:06:07,523:INFO:Physical Core: 8
2025-11-21 18:06:07,523:INFO:Logical Core: 16
2025-11-21 18:06:07,523:INFO:Checking libraries
2025-11-21 18:06:07,523:INFO:System:
2025-11-21 18:06:07,523:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-21 18:06:07,523:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-21 18:06:07,523:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-21 18:06:07,523:INFO:PyCaret required dependencies:
2025-11-21 18:06:07,523:INFO:                 pip: 24.0
2025-11-21 18:06:07,523:INFO:          setuptools: 65.5.0
2025-11-21 18:06:07,523:INFO:             pycaret: 3.3.2
2025-11-21 18:06:07,523:INFO:             IPython: 9.0.2
2025-11-21 18:06:07,523:INFO:          ipywidgets: 8.1.7
2025-11-21 18:06:07,523:INFO:                tqdm: 4.67.1
2025-11-21 18:06:07,523:INFO:               numpy: 1.26.4
2025-11-21 18:06:07,523:INFO:              pandas: 2.1.4
2025-11-21 18:06:07,523:INFO:              jinja2: 3.1.6
2025-11-21 18:06:07,523:INFO:               scipy: 1.11.4
2025-11-21 18:06:07,523:INFO:              joblib: 1.3.2
2025-11-21 18:06:07,523:INFO:             sklearn: 1.4.2
2025-11-21 18:06:07,523:INFO:                pyod: 2.0.5
2025-11-21 18:06:07,523:INFO:            imblearn: 0.14.0
2025-11-21 18:06:07,523:INFO:   category_encoders: 2.7.0
2025-11-21 18:06:07,525:INFO:            lightgbm: 4.6.0
2025-11-21 18:06:07,525:INFO:               numba: 0.61.2
2025-11-21 18:06:07,525:INFO:            requests: 2.32.5
2025-11-21 18:06:07,525:INFO:          matplotlib: 3.7.5
2025-11-21 18:06:07,525:INFO:          scikitplot: 0.3.7
2025-11-21 18:06:07,525:INFO:         yellowbrick: 1.5
2025-11-21 18:06:07,525:INFO:              plotly: 6.3.0
2025-11-21 18:06:07,525:INFO:    plotly-resampler: Not installed
2025-11-21 18:06:07,525:INFO:             kaleido: 1.1.0
2025-11-21 18:06:07,525:INFO:           schemdraw: 0.15
2025-11-21 18:06:07,525:INFO:         statsmodels: 0.14.5
2025-11-21 18:06:07,525:INFO:              sktime: 0.26.0
2025-11-21 18:06:07,525:INFO:               tbats: 1.1.3
2025-11-21 18:06:07,525:INFO:            pmdarima: 2.0.4
2025-11-21 18:06:07,525:INFO:              psutil: 7.0.0
2025-11-21 18:06:07,525:INFO:          markupsafe: 3.0.2
2025-11-21 18:06:07,525:INFO:             pickle5: Not installed
2025-11-21 18:06:07,525:INFO:         cloudpickle: 3.1.1
2025-11-21 18:06:07,525:INFO:         deprecation: 2.1.0
2025-11-21 18:06:07,525:INFO:              xxhash: 3.5.0
2025-11-21 18:06:07,525:INFO:           wurlitzer: Not installed
2025-11-21 18:06:07,525:INFO:PyCaret optional dependencies:
2025-11-21 18:06:07,525:INFO:                shap: 0.48.0
2025-11-21 18:06:07,525:INFO:           interpret: Not installed
2025-11-21 18:06:07,525:INFO:                umap: 0.5.7
2025-11-21 18:06:07,525:INFO:     ydata_profiling: Not installed
2025-11-21 18:06:07,525:INFO:  explainerdashboard: Not installed
2025-11-21 18:06:07,525:INFO:             autoviz: Not installed
2025-11-21 18:06:07,525:INFO:           fairlearn: Not installed
2025-11-21 18:06:07,525:INFO:          deepchecks: Not installed
2025-11-21 18:06:07,525:INFO:             xgboost: 3.0.5
2025-11-21 18:06:07,525:INFO:            catboost: Not installed
2025-11-21 18:06:07,525:INFO:              kmodes: Not installed
2025-11-21 18:06:07,525:INFO:             mlxtend: Not installed
2025-11-21 18:06:07,525:INFO:       statsforecast: Not installed
2025-11-21 18:06:07,525:INFO:        tune_sklearn: Not installed
2025-11-21 18:06:07,525:INFO:                 ray: Not installed
2025-11-21 18:06:07,525:INFO:            hyperopt: Not installed
2025-11-21 18:06:07,525:INFO:              optuna: 4.5.0
2025-11-21 18:06:07,525:INFO:               skopt: Not installed
2025-11-21 18:06:07,525:INFO:              mlflow: Not installed
2025-11-21 18:06:07,525:INFO:              gradio: Not installed
2025-11-21 18:06:07,525:INFO:             fastapi: Not installed
2025-11-21 18:06:07,525:INFO:             uvicorn: Not installed
2025-11-21 18:06:07,525:INFO:              m2cgen: Not installed
2025-11-21 18:06:07,525:INFO:           evidently: Not installed
2025-11-21 18:06:07,525:INFO:               fugue: Not installed
2025-11-21 18:06:07,525:INFO:           streamlit: Not installed
2025-11-21 18:06:07,525:INFO:             prophet: Not installed
2025-11-21 18:06:07,525:INFO:None
2025-11-21 18:06:07,525:INFO:Set up data.
2025-11-21 18:06:07,534:INFO:Set up folding strategy.
2025-11-21 18:06:07,534:INFO:Set up train/test split.
2025-11-21 18:06:07,537:INFO:Set up index.
2025-11-21 18:06:07,545:INFO:Assigning column types.
2025-11-21 18:06:07,550:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-21 18:06:07,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,638:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:07,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:07,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,693:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,724:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:07,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:07,724:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-21 18:06:07,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,814:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:07,814:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:07,877:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 18:06:07,898:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:07,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:07,898:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-21 18:06:07,993:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:08,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:08,083:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:08,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:08,092:INFO:Preparing preprocessing pipeline...
2025-11-21 18:06:08,092:INFO:Set up date feature engineering.
2025-11-21 18:06:08,092:INFO:Set up simple imputation.
2025-11-21 18:06:08,140:INFO:Finished creating preprocessing pipeline.
2025-11-21 18:06:08,147:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-21 18:06:08,147:INFO:Creating final display dataframe.
2025-11-21 18:06:08,275:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 19)
5   Transformed train set shape           (5961, 19)
6    Transformed test set shape           (2555, 19)
7               Ignore features                    2
8              Numeric features                   15
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 cec9
2025-11-21 18:06:08,370:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:08,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:08,465:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 18:06:08,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 18:06:08,465:INFO:setup() successfully completed in 0.97s...............
2025-11-21 18:06:08,481:INFO:Initializing compare_models()
2025-11-21 18:06:08,481:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-21 18:06:08,481:INFO:Checking exceptions
2025-11-21 18:06:08,481:INFO:Preparing display monitor
2025-11-21 18:06:08,514:INFO:Initializing Logistic Regression
2025-11-21 18:06:08,514:INFO:Total runtime is 0.0 minutes
2025-11-21 18:06:08,518:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:08,518:INFO:Initializing create_model()
2025-11-21 18:06:08,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:08,518:INFO:Checking exceptions
2025-11-21 18:06:08,518:INFO:Importing libraries
2025-11-21 18:06:08,518:INFO:Copying training dataset
2025-11-21 18:06:08,530:INFO:Defining folds
2025-11-21 18:06:08,530:INFO:Declaring metric variables
2025-11-21 18:06:08,530:INFO:Importing untrained model
2025-11-21 18:06:08,538:INFO:Logistic Regression Imported successfully
2025-11-21 18:06:08,540:INFO:Starting cross validation
2025-11-21 18:06:08,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:09,059:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,068:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,087:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,092:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,097:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,099:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,107:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,124:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,129:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,138:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:09,169:INFO:Calculating mean and std
2025-11-21 18:06:09,169:INFO:Creating metrics dataframe
2025-11-21 18:06:09,171:INFO:Uploading results into container
2025-11-21 18:06:09,171:INFO:Uploading model into container now
2025-11-21 18:06:09,171:INFO:_master_model_container: 1
2025-11-21 18:06:09,171:INFO:_display_container: 2
2025-11-21 18:06:09,171:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:06:09,171:INFO:create_model() successfully completed......................................
2025-11-21 18:06:09,334:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:09,334:INFO:Creating metrics dataframe
2025-11-21 18:06:09,343:INFO:Initializing K Neighbors Classifier
2025-11-21 18:06:09,343:INFO:Total runtime is 0.013831369082132975 minutes
2025-11-21 18:06:09,348:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:09,348:INFO:Initializing create_model()
2025-11-21 18:06:09,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:09,348:INFO:Checking exceptions
2025-11-21 18:06:09,348:INFO:Importing libraries
2025-11-21 18:06:09,348:INFO:Copying training dataset
2025-11-21 18:06:09,355:INFO:Defining folds
2025-11-21 18:06:09,355:INFO:Declaring metric variables
2025-11-21 18:06:09,362:INFO:Importing untrained model
2025-11-21 18:06:09,366:INFO:K Neighbors Classifier Imported successfully
2025-11-21 18:06:09,372:INFO:Starting cross validation
2025-11-21 18:06:09,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:09,572:INFO:Calculating mean and std
2025-11-21 18:06:09,572:INFO:Creating metrics dataframe
2025-11-21 18:06:09,572:INFO:Uploading results into container
2025-11-21 18:06:09,577:INFO:Uploading model into container now
2025-11-21 18:06:09,578:INFO:_master_model_container: 2
2025-11-21 18:06:09,578:INFO:_display_container: 2
2025-11-21 18:06:09,578:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-21 18:06:09,578:INFO:create_model() successfully completed......................................
2025-11-21 18:06:09,737:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:09,737:INFO:Creating metrics dataframe
2025-11-21 18:06:09,744:INFO:Initializing Naive Bayes
2025-11-21 18:06:09,744:INFO:Total runtime is 0.02050047318140666 minutes
2025-11-21 18:06:09,744:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:09,744:INFO:Initializing create_model()
2025-11-21 18:06:09,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:09,744:INFO:Checking exceptions
2025-11-21 18:06:09,744:INFO:Importing libraries
2025-11-21 18:06:09,744:INFO:Copying training dataset
2025-11-21 18:06:09,757:INFO:Defining folds
2025-11-21 18:06:09,757:INFO:Declaring metric variables
2025-11-21 18:06:09,764:INFO:Importing untrained model
2025-11-21 18:06:09,764:INFO:Naive Bayes Imported successfully
2025-11-21 18:06:09,776:INFO:Starting cross validation
2025-11-21 18:06:09,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:09,883:INFO:Calculating mean and std
2025-11-21 18:06:09,883:INFO:Creating metrics dataframe
2025-11-21 18:06:09,883:INFO:Uploading results into container
2025-11-21 18:06:09,883:INFO:Uploading model into container now
2025-11-21 18:06:09,883:INFO:_master_model_container: 3
2025-11-21 18:06:09,883:INFO:_display_container: 2
2025-11-21 18:06:09,883:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-21 18:06:09,883:INFO:create_model() successfully completed......................................
2025-11-21 18:06:10,043:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:10,043:INFO:Creating metrics dataframe
2025-11-21 18:06:10,050:INFO:Initializing Decision Tree Classifier
2025-11-21 18:06:10,050:INFO:Total runtime is 0.025603389739990236 minutes
2025-11-21 18:06:10,058:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:10,058:INFO:Initializing create_model()
2025-11-21 18:06:10,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:10,058:INFO:Checking exceptions
2025-11-21 18:06:10,058:INFO:Importing libraries
2025-11-21 18:06:10,058:INFO:Copying training dataset
2025-11-21 18:06:10,070:INFO:Defining folds
2025-11-21 18:06:10,070:INFO:Declaring metric variables
2025-11-21 18:06:10,073:INFO:Importing untrained model
2025-11-21 18:06:10,077:INFO:Decision Tree Classifier Imported successfully
2025-11-21 18:06:10,085:INFO:Starting cross validation
2025-11-21 18:06:10,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:10,224:INFO:Calculating mean and std
2025-11-21 18:06:10,224:INFO:Creating metrics dataframe
2025-11-21 18:06:10,224:INFO:Uploading results into container
2025-11-21 18:06:10,224:INFO:Uploading model into container now
2025-11-21 18:06:10,224:INFO:_master_model_container: 4
2025-11-21 18:06:10,224:INFO:_display_container: 2
2025-11-21 18:06:10,224:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-21 18:06:10,224:INFO:create_model() successfully completed......................................
2025-11-21 18:06:10,374:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:10,374:INFO:Creating metrics dataframe
2025-11-21 18:06:10,390:INFO:Initializing SVM - Linear Kernel
2025-11-21 18:06:10,390:INFO:Total runtime is 0.031272669633229576 minutes
2025-11-21 18:06:10,390:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:10,390:INFO:Initializing create_model()
2025-11-21 18:06:10,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:10,390:INFO:Checking exceptions
2025-11-21 18:06:10,390:INFO:Importing libraries
2025-11-21 18:06:10,390:INFO:Copying training dataset
2025-11-21 18:06:10,409:INFO:Defining folds
2025-11-21 18:06:10,409:INFO:Declaring metric variables
2025-11-21 18:06:10,409:INFO:Importing untrained model
2025-11-21 18:06:10,421:INFO:SVM - Linear Kernel Imported successfully
2025-11-21 18:06:10,421:INFO:Starting cross validation
2025-11-21 18:06:10,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:10,626:INFO:Calculating mean and std
2025-11-21 18:06:10,626:INFO:Creating metrics dataframe
2025-11-21 18:06:10,626:INFO:Uploading results into container
2025-11-21 18:06:10,626:INFO:Uploading model into container now
2025-11-21 18:06:10,626:INFO:_master_model_container: 5
2025-11-21 18:06:10,632:INFO:_display_container: 2
2025-11-21 18:06:10,632:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-21 18:06:10,632:INFO:create_model() successfully completed......................................
2025-11-21 18:06:10,785:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:10,785:INFO:Creating metrics dataframe
2025-11-21 18:06:10,785:INFO:Initializing Ridge Classifier
2025-11-21 18:06:10,785:INFO:Total runtime is 0.03784939448038737 minutes
2025-11-21 18:06:10,800:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:10,800:INFO:Initializing create_model()
2025-11-21 18:06:10,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:10,800:INFO:Checking exceptions
2025-11-21 18:06:10,800:INFO:Importing libraries
2025-11-21 18:06:10,800:INFO:Copying training dataset
2025-11-21 18:06:10,813:INFO:Defining folds
2025-11-21 18:06:10,813:INFO:Declaring metric variables
2025-11-21 18:06:10,817:INFO:Importing untrained model
2025-11-21 18:06:10,817:INFO:Ridge Classifier Imported successfully
2025-11-21 18:06:10,828:INFO:Starting cross validation
2025-11-21 18:06:10,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:10,935:INFO:Calculating mean and std
2025-11-21 18:06:10,935:INFO:Creating metrics dataframe
2025-11-21 18:06:10,940:INFO:Uploading results into container
2025-11-21 18:06:10,940:INFO:Uploading model into container now
2025-11-21 18:06:10,940:INFO:_master_model_container: 6
2025-11-21 18:06:10,940:INFO:_display_container: 2
2025-11-21 18:06:10,940:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-21 18:06:10,940:INFO:create_model() successfully completed......................................
2025-11-21 18:06:11,098:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:11,098:INFO:Creating metrics dataframe
2025-11-21 18:06:11,105:INFO:Initializing Random Forest Classifier
2025-11-21 18:06:11,105:INFO:Total runtime is 0.043182810147603355 minutes
2025-11-21 18:06:11,105:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:11,111:INFO:Initializing create_model()
2025-11-21 18:06:11,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:11,112:INFO:Checking exceptions
2025-11-21 18:06:11,112:INFO:Importing libraries
2025-11-21 18:06:11,112:INFO:Copying training dataset
2025-11-21 18:06:11,120:INFO:Defining folds
2025-11-21 18:06:11,120:INFO:Declaring metric variables
2025-11-21 18:06:11,127:INFO:Importing untrained model
2025-11-21 18:06:11,133:INFO:Random Forest Classifier Imported successfully
2025-11-21 18:06:11,140:INFO:Starting cross validation
2025-11-21 18:06:11,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:12,147:INFO:Calculating mean and std
2025-11-21 18:06:12,147:INFO:Creating metrics dataframe
2025-11-21 18:06:12,147:INFO:Uploading results into container
2025-11-21 18:06:12,147:INFO:Uploading model into container now
2025-11-21 18:06:12,147:INFO:_master_model_container: 7
2025-11-21 18:06:12,147:INFO:_display_container: 2
2025-11-21 18:06:12,147:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:06:12,147:INFO:create_model() successfully completed......................................
2025-11-21 18:06:12,314:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:12,314:INFO:Creating metrics dataframe
2025-11-21 18:06:12,322:INFO:Initializing Quadratic Discriminant Analysis
2025-11-21 18:06:12,322:INFO:Total runtime is 0.06347357034683228 minutes
2025-11-21 18:06:12,327:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:12,327:INFO:Initializing create_model()
2025-11-21 18:06:12,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:12,327:INFO:Checking exceptions
2025-11-21 18:06:12,330:INFO:Importing libraries
2025-11-21 18:06:12,330:INFO:Copying training dataset
2025-11-21 18:06:12,341:INFO:Defining folds
2025-11-21 18:06:12,341:INFO:Declaring metric variables
2025-11-21 18:06:12,348:INFO:Importing untrained model
2025-11-21 18:06:12,351:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-21 18:06:12,359:INFO:Starting cross validation
2025-11-21 18:06:12,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:12,405:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,405:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,405:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,418:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,418:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,422:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,426:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,431:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,438:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,444:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 18:06:12,478:INFO:Calculating mean and std
2025-11-21 18:06:12,478:INFO:Creating metrics dataframe
2025-11-21 18:06:12,478:INFO:Uploading results into container
2025-11-21 18:06:12,478:INFO:Uploading model into container now
2025-11-21 18:06:12,478:INFO:_master_model_container: 8
2025-11-21 18:06:12,478:INFO:_display_container: 2
2025-11-21 18:06:12,478:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-21 18:06:12,478:INFO:create_model() successfully completed......................................
2025-11-21 18:06:12,643:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:12,643:INFO:Creating metrics dataframe
2025-11-21 18:06:12,651:INFO:Initializing Ada Boost Classifier
2025-11-21 18:06:12,651:INFO:Total runtime is 0.06896448135375977 minutes
2025-11-21 18:06:12,658:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:12,660:INFO:Initializing create_model()
2025-11-21 18:06:12,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:12,661:INFO:Checking exceptions
2025-11-21 18:06:12,661:INFO:Importing libraries
2025-11-21 18:06:12,661:INFO:Copying training dataset
2025-11-21 18:06:12,668:INFO:Defining folds
2025-11-21 18:06:12,668:INFO:Declaring metric variables
2025-11-21 18:06:12,676:INFO:Importing untrained model
2025-11-21 18:06:12,680:INFO:Ada Boost Classifier Imported successfully
2025-11-21 18:06:12,688:INFO:Starting cross validation
2025-11-21 18:06:12,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:12,743:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,747:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,751:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,751:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,754:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,759:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,761:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,764:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,764:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:12,765:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 18:06:13,210:INFO:Calculating mean and std
2025-11-21 18:06:13,210:INFO:Creating metrics dataframe
2025-11-21 18:06:13,210:INFO:Uploading results into container
2025-11-21 18:06:13,210:INFO:Uploading model into container now
2025-11-21 18:06:13,210:INFO:_master_model_container: 9
2025-11-21 18:06:13,210:INFO:_display_container: 2
2025-11-21 18:06:13,210:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-21 18:06:13,210:INFO:create_model() successfully completed......................................
2025-11-21 18:06:13,376:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:13,376:INFO:Creating metrics dataframe
2025-11-21 18:06:13,383:INFO:Initializing Gradient Boosting Classifier
2025-11-21 18:06:13,383:INFO:Total runtime is 0.08115394512812296 minutes
2025-11-21 18:06:13,389:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:13,389:INFO:Initializing create_model()
2025-11-21 18:06:13,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:13,389:INFO:Checking exceptions
2025-11-21 18:06:13,389:INFO:Importing libraries
2025-11-21 18:06:13,389:INFO:Copying training dataset
2025-11-21 18:06:13,398:INFO:Defining folds
2025-11-21 18:06:13,398:INFO:Declaring metric variables
2025-11-21 18:06:13,404:INFO:Importing untrained model
2025-11-21 18:06:13,409:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:13,416:INFO:Starting cross validation
2025-11-21 18:06:13,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:14,672:INFO:Calculating mean and std
2025-11-21 18:06:14,675:INFO:Creating metrics dataframe
2025-11-21 18:06:14,675:INFO:Uploading results into container
2025-11-21 18:06:14,675:INFO:Uploading model into container now
2025-11-21 18:06:14,675:INFO:_master_model_container: 10
2025-11-21 18:06:14,675:INFO:_display_container: 2
2025-11-21 18:06:14,675:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:14,675:INFO:create_model() successfully completed......................................
2025-11-21 18:06:14,834:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:14,834:INFO:Creating metrics dataframe
2025-11-21 18:06:14,848:INFO:Initializing Linear Discriminant Analysis
2025-11-21 18:06:14,848:INFO:Total runtime is 0.10556623140970865 minutes
2025-11-21 18:06:14,854:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:14,854:INFO:Initializing create_model()
2025-11-21 18:06:14,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:14,854:INFO:Checking exceptions
2025-11-21 18:06:14,854:INFO:Importing libraries
2025-11-21 18:06:14,854:INFO:Copying training dataset
2025-11-21 18:06:14,862:INFO:Defining folds
2025-11-21 18:06:14,868:INFO:Declaring metric variables
2025-11-21 18:06:14,869:INFO:Importing untrained model
2025-11-21 18:06:14,876:INFO:Linear Discriminant Analysis Imported successfully
2025-11-21 18:06:14,883:INFO:Starting cross validation
2025-11-21 18:06:14,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:15,033:INFO:Calculating mean and std
2025-11-21 18:06:15,035:INFO:Creating metrics dataframe
2025-11-21 18:06:15,035:INFO:Uploading results into container
2025-11-21 18:06:15,035:INFO:Uploading model into container now
2025-11-21 18:06:15,035:INFO:_master_model_container: 11
2025-11-21 18:06:15,035:INFO:_display_container: 2
2025-11-21 18:06:15,035:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-21 18:06:15,035:INFO:create_model() successfully completed......................................
2025-11-21 18:06:15,206:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:15,206:INFO:Creating metrics dataframe
2025-11-21 18:06:15,222:INFO:Initializing Extra Trees Classifier
2025-11-21 18:06:15,222:INFO:Total runtime is 0.11180333296457926 minutes
2025-11-21 18:06:15,222:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:15,222:INFO:Initializing create_model()
2025-11-21 18:06:15,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:15,222:INFO:Checking exceptions
2025-11-21 18:06:15,222:INFO:Importing libraries
2025-11-21 18:06:15,222:INFO:Copying training dataset
2025-11-21 18:06:15,237:INFO:Defining folds
2025-11-21 18:06:15,237:INFO:Declaring metric variables
2025-11-21 18:06:15,237:INFO:Importing untrained model
2025-11-21 18:06:15,254:INFO:Extra Trees Classifier Imported successfully
2025-11-21 18:06:15,254:INFO:Starting cross validation
2025-11-21 18:06:15,254:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:16,188:INFO:Calculating mean and std
2025-11-21 18:06:16,188:INFO:Creating metrics dataframe
2025-11-21 18:06:16,188:INFO:Uploading results into container
2025-11-21 18:06:16,195:INFO:Uploading model into container now
2025-11-21 18:06:16,195:INFO:_master_model_container: 12
2025-11-21 18:06:16,195:INFO:_display_container: 2
2025-11-21 18:06:16,195:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-21 18:06:16,195:INFO:create_model() successfully completed......................................
2025-11-21 18:06:16,350:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:16,350:INFO:Creating metrics dataframe
2025-11-21 18:06:16,366:INFO:Initializing Extreme Gradient Boosting
2025-11-21 18:06:16,366:INFO:Total runtime is 0.130869189898173 minutes
2025-11-21 18:06:16,384:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:16,384:INFO:Initializing create_model()
2025-11-21 18:06:16,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:16,384:INFO:Checking exceptions
2025-11-21 18:06:16,384:INFO:Importing libraries
2025-11-21 18:06:16,384:INFO:Copying training dataset
2025-11-21 18:06:16,398:INFO:Defining folds
2025-11-21 18:06:16,398:INFO:Declaring metric variables
2025-11-21 18:06:16,398:INFO:Importing untrained model
2025-11-21 18:06:16,398:INFO:Extreme Gradient Boosting Imported successfully
2025-11-21 18:06:16,413:INFO:Starting cross validation
2025-11-21 18:06:16,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:17,253:INFO:Calculating mean and std
2025-11-21 18:06:17,253:INFO:Creating metrics dataframe
2025-11-21 18:06:17,253:INFO:Uploading results into container
2025-11-21 18:06:17,253:INFO:Uploading model into container now
2025-11-21 18:06:17,258:INFO:_master_model_container: 13
2025-11-21 18:06:17,258:INFO:_display_container: 2
2025-11-21 18:06:17,258:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-21 18:06:17,258:INFO:create_model() successfully completed......................................
2025-11-21 18:06:17,418:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:17,418:INFO:Creating metrics dataframe
2025-11-21 18:06:17,434:INFO:Initializing Light Gradient Boosting Machine
2025-11-21 18:06:17,434:INFO:Total runtime is 0.1486691872278849 minutes
2025-11-21 18:06:17,450:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:17,450:INFO:Initializing create_model()
2025-11-21 18:06:17,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:17,450:INFO:Checking exceptions
2025-11-21 18:06:17,450:INFO:Importing libraries
2025-11-21 18:06:17,450:INFO:Copying training dataset
2025-11-21 18:06:17,453:INFO:Defining folds
2025-11-21 18:06:17,466:INFO:Declaring metric variables
2025-11-21 18:06:17,470:INFO:Importing untrained model
2025-11-21 18:06:17,470:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-21 18:06:17,482:INFO:Starting cross validation
2025-11-21 18:06:17,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:19,682:INFO:Calculating mean and std
2025-11-21 18:06:19,684:INFO:Creating metrics dataframe
2025-11-21 18:06:19,686:INFO:Uploading results into container
2025-11-21 18:06:19,688:INFO:Uploading model into container now
2025-11-21 18:06:19,688:INFO:_master_model_container: 14
2025-11-21 18:06:19,688:INFO:_display_container: 2
2025-11-21 18:06:19,690:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-21 18:06:19,690:INFO:create_model() successfully completed......................................
2025-11-21 18:06:19,862:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:19,862:INFO:Creating metrics dataframe
2025-11-21 18:06:19,872:INFO:Initializing Dummy Classifier
2025-11-21 18:06:19,872:INFO:Total runtime is 0.18931506872177123 minutes
2025-11-21 18:06:19,879:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:19,880:INFO:Initializing create_model()
2025-11-21 18:06:19,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF0300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:19,880:INFO:Checking exceptions
2025-11-21 18:06:19,880:INFO:Importing libraries
2025-11-21 18:06:19,880:INFO:Copying training dataset
2025-11-21 18:06:19,891:INFO:Defining folds
2025-11-21 18:06:19,891:INFO:Declaring metric variables
2025-11-21 18:06:19,896:INFO:Importing untrained model
2025-11-21 18:06:19,900:INFO:Dummy Classifier Imported successfully
2025-11-21 18:06:19,904:INFO:Starting cross validation
2025-11-21 18:06:19,913:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:20,030:INFO:Calculating mean and std
2025-11-21 18:06:20,030:INFO:Creating metrics dataframe
2025-11-21 18:06:20,030:INFO:Uploading results into container
2025-11-21 18:06:20,030:INFO:Uploading model into container now
2025-11-21 18:06:20,035:INFO:_master_model_container: 15
2025-11-21 18:06:20,035:INFO:_display_container: 2
2025-11-21 18:06:20,035:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-21 18:06:20,035:INFO:create_model() successfully completed......................................
2025-11-21 18:06:20,187:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:20,187:INFO:Creating metrics dataframe
2025-11-21 18:06:20,201:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-21 18:06:20,217:INFO:Initializing create_model()
2025-11-21 18:06:20,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:20,217:INFO:Checking exceptions
2025-11-21 18:06:20,219:INFO:Importing libraries
2025-11-21 18:06:20,219:INFO:Copying training dataset
2025-11-21 18:06:20,230:INFO:Defining folds
2025-11-21 18:06:20,233:INFO:Declaring metric variables
2025-11-21 18:06:20,233:INFO:Importing untrained model
2025-11-21 18:06:20,233:INFO:Declaring custom model
2025-11-21 18:06:20,233:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:20,233:INFO:Cross validation set to False
2025-11-21 18:06:20,233:INFO:Fitting Model
2025-11-21 18:06:21,486:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:21,486:INFO:create_model() successfully completed......................................
2025-11-21 18:06:21,701:INFO:_master_model_container: 15
2025-11-21 18:06:21,701:INFO:_display_container: 2
2025-11-21 18:06:21,701:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:21,701:INFO:compare_models() successfully completed......................................
2025-11-21 18:06:21,752:INFO:Initializing create_model()
2025-11-21 18:06:21,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:21,754:INFO:Checking exceptions
2025-11-21 18:06:21,770:INFO:Importing libraries
2025-11-21 18:06:21,770:INFO:Copying training dataset
2025-11-21 18:06:21,789:INFO:Defining folds
2025-11-21 18:06:21,789:INFO:Declaring metric variables
2025-11-21 18:06:21,792:INFO:Importing untrained model
2025-11-21 18:06:21,798:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:21,805:INFO:Starting cross validation
2025-11-21 18:06:21,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:23,124:INFO:Calculating mean and std
2025-11-21 18:06:23,124:INFO:Creating metrics dataframe
2025-11-21 18:06:23,127:INFO:Finalizing model
2025-11-21 18:06:24,326:INFO:Uploading results into container
2025-11-21 18:06:24,328:INFO:Uploading model into container now
2025-11-21 18:06:24,337:INFO:_master_model_container: 16
2025-11-21 18:06:24,337:INFO:_display_container: 3
2025-11-21 18:06:24,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:24,337:INFO:create_model() successfully completed......................................
2025-11-21 18:06:24,497:INFO:Initializing tune_model()
2025-11-21 18:06:24,497:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 18:06:24,501:INFO:Checking exceptions
2025-11-21 18:06:24,519:INFO:Copying training dataset
2025-11-21 18:06:24,527:INFO:Checking base model
2025-11-21 18:06:24,527:INFO:Base model : Gradient Boosting Classifier
2025-11-21 18:06:24,532:INFO:Declaring metric variables
2025-11-21 18:06:24,537:INFO:Defining Hyperparameters
2025-11-21 18:06:24,699:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-21 18:06:24,699:INFO:Tuning with n_jobs=-1
2025-11-21 18:06:24,699:INFO:Initializing RandomizedSearchCV
2025-11-21 18:06:49,838:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-21 18:06:49,838:INFO:Hyperparameter search completed
2025-11-21 18:06:49,838:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:49,838:INFO:Initializing create_model()
2025-11-21 18:06:49,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE07D08A50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-21 18:06:49,838:INFO:Checking exceptions
2025-11-21 18:06:49,838:INFO:Importing libraries
2025-11-21 18:06:49,838:INFO:Copying training dataset
2025-11-21 18:06:49,853:INFO:Defining folds
2025-11-21 18:06:49,853:INFO:Declaring metric variables
2025-11-21 18:06:49,853:INFO:Importing untrained model
2025-11-21 18:06:49,853:INFO:Declaring custom model
2025-11-21 18:06:49,863:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:49,869:INFO:Starting cross validation
2025-11-21 18:06:49,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:51,064:INFO:Calculating mean and std
2025-11-21 18:06:51,064:INFO:Creating metrics dataframe
2025-11-21 18:06:51,070:INFO:Finalizing model
2025-11-21 18:06:52,169:INFO:Uploading results into container
2025-11-21 18:06:52,169:INFO:Uploading model into container now
2025-11-21 18:06:52,171:INFO:_master_model_container: 17
2025-11-21 18:06:52,171:INFO:_display_container: 4
2025-11-21 18:06:52,171:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:52,171:INFO:create_model() successfully completed......................................
2025-11-21 18:06:52,355:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:52,355:INFO:choose_better activated
2025-11-21 18:06:52,357:INFO:SubProcess create_model() called ==================================
2025-11-21 18:06:52,360:INFO:Initializing create_model()
2025-11-21 18:06:52,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:52,360:INFO:Checking exceptions
2025-11-21 18:06:52,362:INFO:Importing libraries
2025-11-21 18:06:52,362:INFO:Copying training dataset
2025-11-21 18:06:52,370:INFO:Defining folds
2025-11-21 18:06:52,370:INFO:Declaring metric variables
2025-11-21 18:06:52,370:INFO:Importing untrained model
2025-11-21 18:06:52,370:INFO:Declaring custom model
2025-11-21 18:06:52,370:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 18:06:52,370:INFO:Starting cross validation
2025-11-21 18:06:52,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:53,676:INFO:Calculating mean and std
2025-11-21 18:06:53,676:INFO:Creating metrics dataframe
2025-11-21 18:06:53,680:INFO:Finalizing model
2025-11-21 18:06:54,841:INFO:Uploading results into container
2025-11-21 18:06:54,841:INFO:Uploading model into container now
2025-11-21 18:06:54,841:INFO:_master_model_container: 18
2025-11-21 18:06:54,844:INFO:_display_container: 5
2025-11-21 18:06:54,844:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:54,844:INFO:create_model() successfully completed......................................
2025-11-21 18:06:55,015:INFO:SubProcess create_model() end ==================================
2025-11-21 18:06:55,015:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.839
2025-11-21 18:06:55,015:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8394
2025-11-21 18:06:55,015:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-21 18:06:55,015:INFO:choose_better completed
2025-11-21 18:06:55,027:INFO:_master_model_container: 18
2025-11-21 18:06:55,027:INFO:_display_container: 4
2025-11-21 18:06:55,027:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 18:06:55,027:INFO:tune_model() successfully completed......................................
2025-11-21 18:06:55,242:INFO:Initializing plot_model()
2025-11-21 18:06:55,243:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:06:55,243:INFO:Checking exceptions
2025-11-21 18:06:55,250:INFO:Preloading libraries
2025-11-21 18:06:55,265:INFO:Copying training dataset
2025-11-21 18:06:55,265:INFO:Plot type: confusion_matrix
2025-11-21 18:06:55,445:INFO:Fitting Model
2025-11-21 18:06:55,445:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-21 18:06:55,445:INFO:Scoring test/hold-out set
2025-11-21 18:06:55,633:INFO:Visual Rendered Successfully
2025-11-21 18:06:55,812:INFO:plot_model() successfully completed......................................
2025-11-21 18:06:55,830:INFO:Initializing plot_model()
2025-11-21 18:06:55,841:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:06:55,841:INFO:Checking exceptions
2025-11-21 18:06:55,848:INFO:Preloading libraries
2025-11-21 18:06:55,854:INFO:Copying training dataset
2025-11-21 18:06:55,854:INFO:Plot type: feature
2025-11-21 18:06:55,854:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 18:06:56,148:INFO:Visual Rendered Successfully
2025-11-21 18:06:56,319:INFO:plot_model() successfully completed......................................
2025-11-21 18:06:56,334:INFO:Initializing create_model()
2025-11-21 18:06:56,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:06:56,334:INFO:Checking exceptions
2025-11-21 18:06:56,347:INFO:Importing libraries
2025-11-21 18:06:56,353:INFO:Copying training dataset
2025-11-21 18:06:56,364:INFO:Defining folds
2025-11-21 18:06:56,364:INFO:Declaring metric variables
2025-11-21 18:06:56,367:INFO:Importing untrained model
2025-11-21 18:06:56,369:INFO:Logistic Regression Imported successfully
2025-11-21 18:06:56,378:INFO:Starting cross validation
2025-11-21 18:06:56,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:06:57,009:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,065:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,067:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,069:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,069:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,073:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,077:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,091:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,093:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,103:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:57,142:INFO:Calculating mean and std
2025-11-21 18:06:57,142:INFO:Creating metrics dataframe
2025-11-21 18:06:57,148:INFO:Finalizing model
2025-11-21 18:06:58,242:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:58,249:INFO:Uploading results into container
2025-11-21 18:06:58,249:INFO:Uploading model into container now
2025-11-21 18:06:58,263:INFO:_master_model_container: 19
2025-11-21 18:06:58,263:INFO:_display_container: 5
2025-11-21 18:06:58,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:06:58,263:INFO:create_model() successfully completed......................................
2025-11-21 18:06:58,430:INFO:Initializing tune_model()
2025-11-21 18:06:58,430:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'class_weight': ['balanced', None], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 18:06:58,430:INFO:Checking exceptions
2025-11-21 18:06:58,451:INFO:Copying training dataset
2025-11-21 18:06:58,461:INFO:Checking base model
2025-11-21 18:06:58,461:INFO:Base model : Logistic Regression
2025-11-21 18:06:58,465:INFO:Declaring metric variables
2025-11-21 18:06:58,473:INFO:Defining Hyperparameters
2025-11-21 18:06:58,631:INFO:custom_grid: {'actual_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100], 'actual_estimator__class_weight': ['balanced', None], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-11-21 18:06:58,631:INFO:Tuning with n_jobs=-1
2025-11-21 18:06:58,631:INFO:Initializing RandomizedSearchCV
2025-11-21 18:06:59,401:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,421:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,440:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,444:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,458:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,482:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,563:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,574:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:06:59,802:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,115:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,176:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,203:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,221:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,251:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,293:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,324:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,371:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,378:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,392:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,406:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,412:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,446:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,470:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,522:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,541:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,715:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,857:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,864:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,902:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:00,947:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,013:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,041:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,057:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,057:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,130:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,149:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,173:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,217:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,232:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,236:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,274:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,312:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,451:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,451:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,499:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,839:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,930:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,957:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:01,999:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,026:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1}
2025-11-21 18:07:02,027:INFO:Hyperparameter search completed
2025-11-21 18:07:02,027:INFO:SubProcess create_model() called ==================================
2025-11-21 18:07:02,027:INFO:Initializing create_model()
2025-11-21 18:07:02,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF2B63D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 1})
2025-11-21 18:07:02,027:INFO:Checking exceptions
2025-11-21 18:07:02,027:INFO:Importing libraries
2025-11-21 18:07:02,027:INFO:Copying training dataset
2025-11-21 18:07:02,040:INFO:Defining folds
2025-11-21 18:07:02,040:INFO:Declaring metric variables
2025-11-21 18:07:02,042:INFO:Importing untrained model
2025-11-21 18:07:02,042:INFO:Declaring custom model
2025-11-21 18:07:02,048:INFO:Logistic Regression Imported successfully
2025-11-21 18:07:02,055:INFO:Starting cross validation
2025-11-21 18:07:02,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:07:02,631:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,652:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,659:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,665:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,673:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,682:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,686:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:02,729:INFO:Calculating mean and std
2025-11-21 18:07:02,729:INFO:Creating metrics dataframe
2025-11-21 18:07:02,735:INFO:Finalizing model
2025-11-21 18:07:03,784:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:03,791:INFO:Uploading results into container
2025-11-21 18:07:03,791:INFO:Uploading model into container now
2025-11-21 18:07:03,791:INFO:_master_model_container: 20
2025-11-21 18:07:03,791:INFO:_display_container: 6
2025-11-21 18:07:03,791:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:07:03,791:INFO:create_model() successfully completed......................................
2025-11-21 18:07:04,014:INFO:SubProcess create_model() end ==================================
2025-11-21 18:07:04,021:INFO:choose_better activated
2025-11-21 18:07:04,021:INFO:SubProcess create_model() called ==================================
2025-11-21 18:07:04,026:INFO:Initializing create_model()
2025-11-21 18:07:04,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:07:04,027:INFO:Checking exceptions
2025-11-21 18:07:04,027:INFO:Importing libraries
2025-11-21 18:07:04,027:INFO:Copying training dataset
2025-11-21 18:07:04,039:INFO:Defining folds
2025-11-21 18:07:04,039:INFO:Declaring metric variables
2025-11-21 18:07:04,039:INFO:Importing untrained model
2025-11-21 18:07:04,039:INFO:Declaring custom model
2025-11-21 18:07:04,040:INFO:Logistic Regression Imported successfully
2025-11-21 18:07:04,040:INFO:Starting cross validation
2025-11-21 18:07:04,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:07:04,596:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,607:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,613:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,615:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,618:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,618:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,623:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,623:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,631:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,638:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:04,675:INFO:Calculating mean and std
2025-11-21 18:07:04,675:INFO:Creating metrics dataframe
2025-11-21 18:07:04,679:INFO:Finalizing model
2025-11-21 18:07:05,743:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 18:07:05,743:INFO:Uploading results into container
2025-11-21 18:07:05,743:INFO:Uploading model into container now
2025-11-21 18:07:05,743:INFO:_master_model_container: 21
2025-11-21 18:07:05,743:INFO:_display_container: 7
2025-11-21 18:07:05,743:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:07:05,743:INFO:create_model() successfully completed......................................
2025-11-21 18:07:05,995:INFO:SubProcess create_model() end ==================================
2025-11-21 18:07:05,995:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8128
2025-11-21 18:07:05,995:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8134
2025-11-21 18:07:05,995:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-11-21 18:07:05,995:INFO:choose_better completed
2025-11-21 18:07:06,003:INFO:_master_model_container: 21
2025-11-21 18:07:06,003:INFO:_display_container: 6
2025-11-21 18:07:06,003:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 18:07:06,003:INFO:tune_model() successfully completed......................................
2025-11-21 18:07:06,212:INFO:Initializing plot_model()
2025-11-21 18:07:06,212:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:07:06,212:INFO:Checking exceptions
2025-11-21 18:07:06,220:INFO:Preloading libraries
2025-11-21 18:07:06,220:INFO:Copying training dataset
2025-11-21 18:07:06,220:INFO:Plot type: confusion_matrix
2025-11-21 18:07:06,392:INFO:Fitting Model
2025-11-21 18:07:06,392:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-11-21 18:07:06,392:INFO:Scoring test/hold-out set
2025-11-21 18:07:06,547:INFO:Visual Rendered Successfully
2025-11-21 18:07:06,721:INFO:plot_model() successfully completed......................................
2025-11-21 18:07:06,737:INFO:Initializing plot_model()
2025-11-21 18:07:06,750:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:07:06,750:INFO:Checking exceptions
2025-11-21 18:07:06,758:INFO:Preloading libraries
2025-11-21 18:07:06,758:INFO:Copying training dataset
2025-11-21 18:07:06,758:INFO:Plot type: feature
2025-11-21 18:07:07,062:INFO:Visual Rendered Successfully
2025-11-21 18:07:07,229:INFO:plot_model() successfully completed......................................
2025-11-21 18:07:07,248:INFO:Initializing create_model()
2025-11-21 18:07:07,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:07:07,248:INFO:Checking exceptions
2025-11-21 18:07:07,262:INFO:Importing libraries
2025-11-21 18:07:07,262:INFO:Copying training dataset
2025-11-21 18:07:07,277:INFO:Defining folds
2025-11-21 18:07:07,277:INFO:Declaring metric variables
2025-11-21 18:07:07,277:INFO:Importing untrained model
2025-11-21 18:07:07,285:INFO:Random Forest Classifier Imported successfully
2025-11-21 18:07:07,285:INFO:Starting cross validation
2025-11-21 18:07:07,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:07:08,321:INFO:Calculating mean and std
2025-11-21 18:07:08,321:INFO:Creating metrics dataframe
2025-11-21 18:07:08,328:INFO:Finalizing model
2025-11-21 18:07:08,626:INFO:Uploading results into container
2025-11-21 18:07:08,626:INFO:Uploading model into container now
2025-11-21 18:07:08,642:INFO:_master_model_container: 22
2025-11-21 18:07:08,642:INFO:_display_container: 7
2025-11-21 18:07:08,642:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:07:08,642:INFO:create_model() successfully completed......................................
2025-11-21 18:07:08,849:INFO:Initializing tune_model()
2025-11-21 18:07:08,849:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', 'balanced_subsample', None]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 18:07:08,849:INFO:Checking exceptions
2025-11-21 18:07:08,881:INFO:Copying training dataset
2025-11-21 18:07:08,881:INFO:Checking base model
2025-11-21 18:07:08,881:INFO:Base model : Random Forest Classifier
2025-11-21 18:07:08,897:INFO:Declaring metric variables
2025-11-21 18:07:08,897:INFO:Defining Hyperparameters
2025-11-21 18:07:09,067:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [10, 20, None], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__criterion': ['gini', 'entropy'], 'actual_estimator__class_weight': ['balanced', 'balanced_subsample', None]}
2025-11-21 18:07:09,067:INFO:Tuning with n_jobs=-1
2025-11-21 18:07:09,067:INFO:Initializing RandomizedSearchCV
2025-11-21 18:07:30,333:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2025-11-21 18:07:30,333:INFO:Hyperparameter search completed
2025-11-21 18:07:30,333:INFO:SubProcess create_model() called ==================================
2025-11-21 18:07:30,333:INFO:Initializing create_model()
2025-11-21 18:07:30,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FDFF2B7790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced'})
2025-11-21 18:07:30,333:INFO:Checking exceptions
2025-11-21 18:07:30,333:INFO:Importing libraries
2025-11-21 18:07:30,333:INFO:Copying training dataset
2025-11-21 18:07:30,347:INFO:Defining folds
2025-11-21 18:07:30,347:INFO:Declaring metric variables
2025-11-21 18:07:30,347:INFO:Importing untrained model
2025-11-21 18:07:30,347:INFO:Declaring custom model
2025-11-21 18:07:30,355:INFO:Random Forest Classifier Imported successfully
2025-11-21 18:07:30,363:INFO:Starting cross validation
2025-11-21 18:07:30,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:07:32,649:INFO:Calculating mean and std
2025-11-21 18:07:32,651:INFO:Creating metrics dataframe
2025-11-21 18:07:32,652:INFO:Finalizing model
2025-11-21 18:07:33,472:INFO:Uploading results into container
2025-11-21 18:07:33,473:INFO:Uploading model into container now
2025-11-21 18:07:33,473:INFO:_master_model_container: 23
2025-11-21 18:07:33,473:INFO:_display_container: 8
2025-11-21 18:07:33,473:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:07:33,474:INFO:create_model() successfully completed......................................
2025-11-21 18:07:33,676:INFO:SubProcess create_model() end ==================================
2025-11-21 18:07:33,676:INFO:choose_better activated
2025-11-21 18:07:33,682:INFO:SubProcess create_model() called ==================================
2025-11-21 18:07:33,682:INFO:Initializing create_model()
2025-11-21 18:07:33,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 18:07:33,682:INFO:Checking exceptions
2025-11-21 18:07:33,685:INFO:Importing libraries
2025-11-21 18:07:33,685:INFO:Copying training dataset
2025-11-21 18:07:33,692:INFO:Defining folds
2025-11-21 18:07:33,692:INFO:Declaring metric variables
2025-11-21 18:07:33,692:INFO:Importing untrained model
2025-11-21 18:07:33,692:INFO:Declaring custom model
2025-11-21 18:07:33,692:INFO:Random Forest Classifier Imported successfully
2025-11-21 18:07:33,700:INFO:Starting cross validation
2025-11-21 18:07:33,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 18:07:34,888:INFO:Calculating mean and std
2025-11-21 18:07:34,888:INFO:Creating metrics dataframe
2025-11-21 18:07:34,888:INFO:Finalizing model
2025-11-21 18:07:35,196:INFO:Uploading results into container
2025-11-21 18:07:35,196:INFO:Uploading model into container now
2025-11-21 18:07:35,196:INFO:_master_model_container: 24
2025-11-21 18:07:35,199:INFO:_display_container: 9
2025-11-21 18:07:35,199:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:07:35,199:INFO:create_model() successfully completed......................................
2025-11-21 18:07:35,367:INFO:SubProcess create_model() end ==================================
2025-11-21 18:07:35,367:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8219
2025-11-21 18:07:35,367:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8365
2025-11-21 18:07:35,367:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-11-21 18:07:35,367:INFO:choose_better completed
2025-11-21 18:07:35,395:INFO:_master_model_container: 24
2025-11-21 18:07:35,396:INFO:_display_container: 8
2025-11-21 18:07:35,396:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 18:07:35,396:INFO:tune_model() successfully completed......................................
2025-11-21 18:07:35,626:INFO:Initializing plot_model()
2025-11-21 18:07:35,626:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:07:35,626:INFO:Checking exceptions
2025-11-21 18:07:35,703:INFO:Preloading libraries
2025-11-21 18:07:35,749:INFO:Copying training dataset
2025-11-21 18:07:35,749:INFO:Plot type: confusion_matrix
2025-11-21 18:07:35,932:INFO:Fitting Model
2025-11-21 18:07:35,932:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-11-21 18:07:35,932:INFO:Scoring test/hold-out set
2025-11-21 18:07:36,306:INFO:Visual Rendered Successfully
2025-11-21 18:07:36,491:INFO:plot_model() successfully completed......................................
2025-11-21 18:07:36,509:INFO:Initializing plot_model()
2025-11-21 18:07:36,509:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 18:07:36,509:INFO:Checking exceptions
2025-11-21 18:07:36,568:INFO:Preloading libraries
2025-11-21 18:07:36,606:INFO:Copying training dataset
2025-11-21 18:07:36,606:INFO:Plot type: feature
2025-11-21 18:07:36,606:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 18:07:36,950:INFO:Visual Rendered Successfully
2025-11-21 18:07:37,127:INFO:plot_model() successfully completed......................................
2025-11-21 19:11:39,749:INFO:Initializing create_model()
2025-11-21 19:11:39,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 19:11:39,751:INFO:Checking exceptions
2025-11-21 19:11:39,829:INFO:Importing libraries
2025-11-21 19:11:39,829:INFO:Copying training dataset
2025-11-21 19:11:39,872:INFO:Defining folds
2025-11-21 19:11:39,873:INFO:Declaring metric variables
2025-11-21 19:11:39,880:INFO:Importing untrained model
2025-11-21 19:11:39,888:INFO:Logistic Regression Imported successfully
2025-11-21 19:11:39,900:INFO:Starting cross validation
2025-11-21 19:11:39,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,562:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,565:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,571:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,571:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:18,629:INFO:Calculating mean and std
2025-11-21 19:12:18,634:INFO:Creating metrics dataframe
2025-11-21 19:12:18,650:INFO:Finalizing model
2025-11-21 19:12:19,689:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:19,696:INFO:Uploading results into container
2025-11-21 19:12:19,697:INFO:Uploading model into container now
2025-11-21 19:12:19,723:INFO:_master_model_container: 25
2025-11-21 19:12:19,723:INFO:_display_container: 9
2025-11-21 19:12:19,724:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 19:12:19,725:INFO:create_model() successfully completed......................................
2025-11-21 19:12:20,349:INFO:Initializing tune_model()
2025-11-21 19:12:20,349:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'class_weight': ['balanced', None], 'solver': ['liblinear', 'lbfgs']}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 19:12:20,350:INFO:Checking exceptions
2025-11-21 19:12:20,370:INFO:Copying training dataset
2025-11-21 19:12:20,381:INFO:Checking base model
2025-11-21 19:12:20,381:INFO:Base model : Logistic Regression
2025-11-21 19:12:20,389:INFO:Declaring metric variables
2025-11-21 19:12:20,393:INFO:Defining Hyperparameters
2025-11-21 19:12:20,569:INFO:custom_grid: {'actual_estimator__C': [0.001, 0.01, 0.1, 1, 10, 100], 'actual_estimator__class_weight': ['balanced', None], 'actual_estimator__solver': ['liblinear', 'lbfgs']}
2025-11-21 19:12:20,570:INFO:Tuning with n_jobs=-1
2025-11-21 19:12:20,570:INFO:Initializing RandomizedSearchCV
2025-11-21 19:12:21,465:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,475:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,479:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,487:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,508:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,597:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,598:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,602:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:21,676:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,721:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,764:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,766:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,786:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,812:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,853:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,864:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,879:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,945:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:22,989:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,400:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,404:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,478:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,487:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,487:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,500:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,500:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,503:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,668:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:23,672:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,102:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,133:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,135:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,176:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,187:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,199:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,203:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,209:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,403:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,403:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,784:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,791:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,835:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,870:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,874:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,894:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,914:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:24,935:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:25,089:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:25,133:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:27,421:INFO:best_params: {'actual_estimator__solver': 'lbfgs', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 1}
2025-11-21 19:12:27,421:INFO:Hyperparameter search completed
2025-11-21 19:12:27,421:INFO:SubProcess create_model() called ==================================
2025-11-21 19:12:27,423:INFO:Initializing create_model()
2025-11-21 19:12:27,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE033F3510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 1})
2025-11-21 19:12:27,423:INFO:Checking exceptions
2025-11-21 19:12:27,423:INFO:Importing libraries
2025-11-21 19:12:27,423:INFO:Copying training dataset
2025-11-21 19:12:27,441:INFO:Defining folds
2025-11-21 19:12:27,441:INFO:Declaring metric variables
2025-11-21 19:12:27,446:INFO:Importing untrained model
2025-11-21 19:12:27,447:INFO:Declaring custom model
2025-11-21 19:12:27,452:INFO:Logistic Regression Imported successfully
2025-11-21 19:12:27,455:INFO:Starting cross validation
2025-11-21 19:12:27,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:12:27,989:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,012:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,019:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,028:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,030:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,032:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,040:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,052:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,055:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,068:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:28,102:INFO:Calculating mean and std
2025-11-21 19:12:28,104:INFO:Creating metrics dataframe
2025-11-21 19:12:28,107:INFO:Finalizing model
2025-11-21 19:12:29,136:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,149:INFO:Uploading results into container
2025-11-21 19:12:29,150:INFO:Uploading model into container now
2025-11-21 19:12:29,151:INFO:_master_model_container: 26
2025-11-21 19:12:29,151:INFO:_display_container: 10
2025-11-21 19:12:29,152:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 19:12:29,152:INFO:create_model() successfully completed......................................
2025-11-21 19:12:29,348:INFO:SubProcess create_model() end ==================================
2025-11-21 19:12:29,348:INFO:choose_better activated
2025-11-21 19:12:29,348:INFO:SubProcess create_model() called ==================================
2025-11-21 19:12:29,348:INFO:Initializing create_model()
2025-11-21 19:12:29,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 19:12:29,348:INFO:Checking exceptions
2025-11-21 19:12:29,348:INFO:Importing libraries
2025-11-21 19:12:29,348:INFO:Copying training dataset
2025-11-21 19:12:29,364:INFO:Defining folds
2025-11-21 19:12:29,364:INFO:Declaring metric variables
2025-11-21 19:12:29,364:INFO:Importing untrained model
2025-11-21 19:12:29,364:INFO:Declaring custom model
2025-11-21 19:12:29,364:INFO:Logistic Regression Imported successfully
2025-11-21 19:12:29,364:INFO:Starting cross validation
2025-11-21 19:12:29,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:12:29,950:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,950:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,960:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,970:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,978:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:29,994:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:30,012:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:30,027:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:30,035:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:30,035:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:30,064:INFO:Calculating mean and std
2025-11-21 19:12:30,065:INFO:Creating metrics dataframe
2025-11-21 19:12:30,066:INFO:Finalizing model
2025-11-21 19:12:31,066:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 19:12:31,066:INFO:Uploading results into container
2025-11-21 19:12:31,066:INFO:Uploading model into container now
2025-11-21 19:12:31,066:INFO:_master_model_container: 27
2025-11-21 19:12:31,066:INFO:_display_container: 11
2025-11-21 19:12:31,066:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 19:12:31,066:INFO:create_model() successfully completed......................................
2025-11-21 19:12:31,294:INFO:SubProcess create_model() end ==================================
2025-11-21 19:12:31,294:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8128
2025-11-21 19:12:31,294:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8134
2025-11-21 19:12:31,294:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-11-21 19:12:31,294:INFO:choose_better completed
2025-11-21 19:12:31,307:INFO:_master_model_container: 27
2025-11-21 19:12:31,308:INFO:_display_container: 10
2025-11-21 19:12:31,309:INFO:LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 19:12:31,309:INFO:tune_model() successfully completed......................................
2025-11-21 19:19:31,554:INFO:Initializing create_model()
2025-11-21 19:19:31,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 19:19:31,554:INFO:Checking exceptions
2025-11-21 19:19:31,577:INFO:Importing libraries
2025-11-21 19:19:31,577:INFO:Copying training dataset
2025-11-21 19:19:31,599:INFO:Defining folds
2025-11-21 19:19:31,599:INFO:Declaring metric variables
2025-11-21 19:19:31,607:INFO:Importing untrained model
2025-11-21 19:19:31,614:INFO:Random Forest Classifier Imported successfully
2025-11-21 19:19:31,624:INFO:Starting cross validation
2025-11-21 19:19:31,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:19:38,675:INFO:Calculating mean and std
2025-11-21 19:19:38,677:INFO:Creating metrics dataframe
2025-11-21 19:19:38,688:INFO:Finalizing model
2025-11-21 19:19:38,956:INFO:Uploading results into container
2025-11-21 19:19:38,958:INFO:Uploading model into container now
2025-11-21 19:19:38,972:INFO:_master_model_container: 28
2025-11-21 19:19:38,972:INFO:_display_container: 11
2025-11-21 19:19:38,973:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 19:19:38,973:INFO:create_model() successfully completed......................................
2025-11-21 19:19:39,149:INFO:Initializing tune_model()
2025-11-21 19:19:39,149:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', 'balanced_subsample', None]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 19:19:39,149:INFO:Checking exceptions
2025-11-21 19:19:39,166:INFO:Copying training dataset
2025-11-21 19:19:39,172:INFO:Checking base model
2025-11-21 19:19:39,172:INFO:Base model : Random Forest Classifier
2025-11-21 19:19:39,177:INFO:Declaring metric variables
2025-11-21 19:19:39,182:INFO:Defining Hyperparameters
2025-11-21 19:19:39,377:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__max_depth': [10, 20, None], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__criterion': ['gini', 'entropy'], 'actual_estimator__class_weight': ['balanced', 'balanced_subsample', None]}
2025-11-21 19:19:39,377:INFO:Tuning with n_jobs=-1
2025-11-21 19:19:39,377:INFO:Initializing RandomizedSearchCV
2025-11-21 19:20:01,858:INFO:best_params: {'actual_estimator__n_estimators': 300, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2025-11-21 19:20:01,860:INFO:Hyperparameter search completed
2025-11-21 19:20:01,860:INFO:SubProcess create_model() called ==================================
2025-11-21 19:20:01,861:INFO:Initializing create_model()
2025-11-21 19:20:01,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE0C13E090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10, 'criterion': 'gini', 'class_weight': 'balanced'})
2025-11-21 19:20:01,861:INFO:Checking exceptions
2025-11-21 19:20:01,861:INFO:Importing libraries
2025-11-21 19:20:01,861:INFO:Copying training dataset
2025-11-21 19:20:01,876:INFO:Defining folds
2025-11-21 19:20:01,876:INFO:Declaring metric variables
2025-11-21 19:20:01,881:INFO:Importing untrained model
2025-11-21 19:20:01,882:INFO:Declaring custom model
2025-11-21 19:20:01,886:INFO:Random Forest Classifier Imported successfully
2025-11-21 19:20:01,897:INFO:Starting cross validation
2025-11-21 19:20:01,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:20:04,293:INFO:Calculating mean and std
2025-11-21 19:20:04,296:INFO:Creating metrics dataframe
2025-11-21 19:20:04,302:INFO:Finalizing model
2025-11-21 19:20:04,984:INFO:Uploading results into container
2025-11-21 19:20:04,985:INFO:Uploading model into container now
2025-11-21 19:20:04,987:INFO:_master_model_container: 29
2025-11-21 19:20:04,987:INFO:_display_container: 12
2025-11-21 19:20:04,987:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 19:20:04,987:INFO:create_model() successfully completed......................................
2025-11-21 19:20:05,171:INFO:SubProcess create_model() end ==================================
2025-11-21 19:20:05,171:INFO:choose_better activated
2025-11-21 19:20:05,171:INFO:SubProcess create_model() called ==================================
2025-11-21 19:20:05,179:INFO:Initializing create_model()
2025-11-21 19:20:05,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FE0C186BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 19:20:05,179:INFO:Checking exceptions
2025-11-21 19:20:05,182:INFO:Importing libraries
2025-11-21 19:20:05,182:INFO:Copying training dataset
2025-11-21 19:20:05,192:INFO:Defining folds
2025-11-21 19:20:05,192:INFO:Declaring metric variables
2025-11-21 19:20:05,192:INFO:Importing untrained model
2025-11-21 19:20:05,193:INFO:Declaring custom model
2025-11-21 19:20:05,193:INFO:Random Forest Classifier Imported successfully
2025-11-21 19:20:05,194:INFO:Starting cross validation
2025-11-21 19:20:05,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 19:20:06,371:INFO:Calculating mean and std
2025-11-21 19:20:06,372:INFO:Creating metrics dataframe
2025-11-21 19:20:06,372:INFO:Finalizing model
2025-11-21 19:20:06,637:INFO:Uploading results into container
2025-11-21 19:20:06,638:INFO:Uploading model into container now
2025-11-21 19:20:06,639:INFO:_master_model_container: 30
2025-11-21 19:20:06,639:INFO:_display_container: 13
2025-11-21 19:20:06,639:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 19:20:06,639:INFO:create_model() successfully completed......................................
2025-11-21 19:20:06,830:INFO:SubProcess create_model() end ==================================
2025-11-21 19:20:06,830:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8219
2025-11-21 19:20:06,830:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for AUC is 0.8365
2025-11-21 19:20:06,837:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2025-11-21 19:20:06,837:INFO:choose_better completed
2025-11-21 19:20:06,844:INFO:_master_model_container: 30
2025-11-21 19:20:06,844:INFO:_display_container: 12
2025-11-21 19:20:06,844:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=2,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=300, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 19:20:06,844:INFO:tune_model() successfully completed......................................
2025-11-21 20:25:10,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-21 20:25:10,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-21 20:25:10,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-21 20:25:10,680:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-21 20:25:13,091:INFO:PyCaret ClassificationExperiment
2025-11-21 20:25:13,091:INFO:Logging name: clf-default-name
2025-11-21 20:25:13,091:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-21 20:25:13,091:INFO:version 3.3.2
2025-11-21 20:25:13,092:INFO:Initializing setup()
2025-11-21 20:25:13,092:INFO:self.USI: b6ac
2025-11-21 20:25:13,092:INFO:self._variable_keys: {'log_plots_param', 'X_train', 'seed', 'USI', 'X_test', 'X', 'is_multiclass', 'exp_id', 'target_param', 'gpu_param', 'html_param', 'idx', 'n_jobs_param', 'logging_param', 'gpu_n_jobs_param', 'y_train', 'y_test', 'pipeline', 'y', '_available_plots', 'data', 'fix_imbalance', 'fold_generator', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'exp_name_log', '_ml_usecase'}
2025-11-21 20:25:13,092:INFO:Checking environment
2025-11-21 20:25:13,093:INFO:python_version: 3.11.9
2025-11-21 20:25:13,093:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-11-21 20:25:13,093:INFO:machine: AMD64
2025-11-21 20:25:13,093:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-21 20:25:13,093:INFO:Memory: svmem(total=16440479744, available=1725775872, percent=89.5, used=14714703872, free=1725775872)
2025-11-21 20:25:13,093:INFO:Physical Core: 8
2025-11-21 20:25:13,093:INFO:Logical Core: 16
2025-11-21 20:25:13,093:INFO:Checking libraries
2025-11-21 20:25:13,093:INFO:System:
2025-11-21 20:25:13,093:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-11-21 20:25:13,093:INFO:executable: C:\Users\sivv1\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-11-21 20:25:13,093:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-21 20:25:13,093:INFO:PyCaret required dependencies:
2025-11-21 20:25:13,216:INFO:                 pip: 24.0
2025-11-21 20:25:13,216:INFO:          setuptools: 65.5.0
2025-11-21 20:25:13,216:INFO:             pycaret: 3.3.2
2025-11-21 20:25:13,222:INFO:             IPython: 9.0.2
2025-11-21 20:25:13,222:INFO:          ipywidgets: 8.1.7
2025-11-21 20:25:13,222:INFO:                tqdm: 4.67.1
2025-11-21 20:25:13,222:INFO:               numpy: 1.26.4
2025-11-21 20:25:13,222:INFO:              pandas: 2.1.4
2025-11-21 20:25:13,222:INFO:              jinja2: 3.1.6
2025-11-21 20:25:13,222:INFO:               scipy: 1.11.4
2025-11-21 20:25:13,222:INFO:              joblib: 1.3.2
2025-11-21 20:25:13,222:INFO:             sklearn: 1.4.2
2025-11-21 20:25:13,222:INFO:                pyod: 2.0.5
2025-11-21 20:25:13,222:INFO:            imblearn: 0.14.0
2025-11-21 20:25:13,223:INFO:   category_encoders: 2.7.0
2025-11-21 20:25:13,223:INFO:            lightgbm: 4.6.0
2025-11-21 20:25:13,223:INFO:               numba: 0.61.2
2025-11-21 20:25:13,224:INFO:            requests: 2.32.5
2025-11-21 20:25:13,224:INFO:          matplotlib: 3.7.5
2025-11-21 20:25:13,224:INFO:          scikitplot: 0.3.7
2025-11-21 20:25:13,224:INFO:         yellowbrick: 1.5
2025-11-21 20:25:13,224:INFO:              plotly: 6.3.0
2025-11-21 20:25:13,224:INFO:    plotly-resampler: Not installed
2025-11-21 20:25:13,224:INFO:             kaleido: 1.1.0
2025-11-21 20:25:13,224:INFO:           schemdraw: 0.15
2025-11-21 20:25:13,224:INFO:         statsmodels: 0.14.5
2025-11-21 20:25:13,224:INFO:              sktime: 0.26.0
2025-11-21 20:25:13,224:INFO:               tbats: 1.1.3
2025-11-21 20:25:13,224:INFO:            pmdarima: 2.0.4
2025-11-21 20:25:13,224:INFO:              psutil: 7.0.0
2025-11-21 20:25:13,224:INFO:          markupsafe: 3.0.2
2025-11-21 20:25:13,224:INFO:             pickle5: Not installed
2025-11-21 20:25:13,224:INFO:         cloudpickle: 3.1.1
2025-11-21 20:25:13,224:INFO:         deprecation: 2.1.0
2025-11-21 20:25:13,224:INFO:              xxhash: 3.5.0
2025-11-21 20:25:13,224:INFO:           wurlitzer: Not installed
2025-11-21 20:25:13,224:INFO:PyCaret optional dependencies:
2025-11-21 20:25:13,508:INFO:                shap: 0.48.0
2025-11-21 20:25:13,508:INFO:           interpret: Not installed
2025-11-21 20:25:13,508:INFO:                umap: 0.5.7
2025-11-21 20:25:13,508:INFO:     ydata_profiling: Not installed
2025-11-21 20:25:13,508:INFO:  explainerdashboard: Not installed
2025-11-21 20:25:13,508:INFO:             autoviz: Not installed
2025-11-21 20:25:13,508:INFO:           fairlearn: Not installed
2025-11-21 20:25:13,509:INFO:          deepchecks: Not installed
2025-11-21 20:25:13,509:INFO:             xgboost: 3.0.5
2025-11-21 20:25:13,509:INFO:            catboost: Not installed
2025-11-21 20:25:13,509:INFO:              kmodes: Not installed
2025-11-21 20:25:13,509:INFO:             mlxtend: Not installed
2025-11-21 20:25:13,509:INFO:       statsforecast: Not installed
2025-11-21 20:25:13,509:INFO:        tune_sklearn: Not installed
2025-11-21 20:25:13,509:INFO:                 ray: Not installed
2025-11-21 20:25:13,510:INFO:            hyperopt: Not installed
2025-11-21 20:25:13,510:INFO:              optuna: 4.5.0
2025-11-21 20:25:13,510:INFO:               skopt: Not installed
2025-11-21 20:25:13,510:INFO:              mlflow: Not installed
2025-11-21 20:25:13,510:INFO:              gradio: Not installed
2025-11-21 20:25:13,510:INFO:             fastapi: Not installed
2025-11-21 20:25:13,510:INFO:             uvicorn: Not installed
2025-11-21 20:25:13,510:INFO:              m2cgen: Not installed
2025-11-21 20:25:13,510:INFO:           evidently: Not installed
2025-11-21 20:25:13,510:INFO:               fugue: Not installed
2025-11-21 20:25:13,510:INFO:           streamlit: Not installed
2025-11-21 20:25:13,510:INFO:             prophet: Not installed
2025-11-21 20:25:13,510:INFO:None
2025-11-21 20:25:13,510:INFO:Set up data.
2025-11-21 20:25:13,522:INFO:Set up folding strategy.
2025-11-21 20:25:13,522:INFO:Set up train/test split.
2025-11-21 20:25:13,538:INFO:Set up index.
2025-11-21 20:25:13,538:INFO:Assigning column types.
2025-11-21 20:25:13,546:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-21 20:25:13,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 20:25:13,625:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 20:25:13,750:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:13,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:13,827:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-21 20:25:13,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 20:25:13,862:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:13,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:13,866:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-21 20:25:13,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 20:25:13,950:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:13,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-21 20:25:14,040:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:14,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,045:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-21 20:25:14,140:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:14,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,255:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:14,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,264:INFO:Preparing preprocessing pipeline...
2025-11-21 20:25:14,264:INFO:Set up date feature engineering.
2025-11-21 20:25:14,264:INFO:Set up simple imputation.
2025-11-21 20:25:14,333:INFO:Finished creating preprocessing pipeline.
2025-11-21 20:25:14,357:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\sivv1\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['DropoutDate'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['IDschool', 'SchoolGrade2022',
                                             'DayOfWeekDroppedOut'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-11-21 20:25:14,357:INFO:Creating final display dataframe.
2025-11-21 20:25:14,576:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  EnrolledByAug312022
2                   Target type               Binary
3           Original data shape           (8516, 19)
4        Transformed data shape           (8516, 20)
5   Transformed train set shape           (5961, 20)
6    Transformed test set shape           (2555, 20)
7               Ignore features                    1
8              Numeric features                   16
9                 Date features                    1
10                   Preprocess                 True
11              Imputation type               simple
12           Numeric imputation                 mean
13       Categorical imputation                 mode
14               Fold Generator      StratifiedKFold
15                  Fold Number                   10
16                     CPU Jobs                   -1
17                      Use GPU                False
18               Log Experiment                False
19              Experiment Name     clf-default-name
20                          USI                 b6ac
2025-11-21 20:25:14,682:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:14,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,795:INFO:Soft dependency imported: xgboost: 3.0.5
2025-11-21 20:25:14,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-21 20:25:14,800:INFO:setup() successfully completed in 1.73s...............
2025-11-21 20:25:14,800:INFO:Initializing compare_models()
2025-11-21 20:25:14,800:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-11-21 20:25:14,800:INFO:Checking exceptions
2025-11-21 20:25:14,810:INFO:Preparing display monitor
2025-11-21 20:25:14,847:INFO:Initializing Logistic Regression
2025-11-21 20:25:14,847:INFO:Total runtime is 0.0 minutes
2025-11-21 20:25:14,852:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:14,853:INFO:Initializing create_model()
2025-11-21 20:25:14,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:14,853:INFO:Checking exceptions
2025-11-21 20:25:14,853:INFO:Importing libraries
2025-11-21 20:25:14,853:INFO:Copying training dataset
2025-11-21 20:25:14,865:INFO:Defining folds
2025-11-21 20:25:14,866:INFO:Declaring metric variables
2025-11-21 20:25:14,871:INFO:Importing untrained model
2025-11-21 20:25:14,877:INFO:Logistic Regression Imported successfully
2025-11-21 20:25:14,887:INFO:Starting cross validation
2025-11-21 20:25:14,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:22,201:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,211:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,228:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,263:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,316:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,416:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,429:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,452:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,492:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,554:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-11-21 20:25:22,595:INFO:Calculating mean and std
2025-11-21 20:25:22,595:INFO:Creating metrics dataframe
2025-11-21 20:25:22,595:INFO:Uploading results into container
2025-11-21 20:25:22,595:INFO:Uploading model into container now
2025-11-21 20:25:22,595:INFO:_master_model_container: 1
2025-11-21 20:25:22,595:INFO:_display_container: 2
2025-11-21 20:25:22,595:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-21 20:25:22,604:INFO:create_model() successfully completed......................................
2025-11-21 20:25:22,739:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:22,739:INFO:Creating metrics dataframe
2025-11-21 20:25:22,739:INFO:Initializing K Neighbors Classifier
2025-11-21 20:25:22,739:INFO:Total runtime is 0.1315266966819763 minutes
2025-11-21 20:25:22,739:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:22,739:INFO:Initializing create_model()
2025-11-21 20:25:22,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:22,739:INFO:Checking exceptions
2025-11-21 20:25:22,739:INFO:Importing libraries
2025-11-21 20:25:22,739:INFO:Copying training dataset
2025-11-21 20:25:22,763:INFO:Defining folds
2025-11-21 20:25:22,763:INFO:Declaring metric variables
2025-11-21 20:25:22,772:INFO:Importing untrained model
2025-11-21 20:25:22,774:INFO:K Neighbors Classifier Imported successfully
2025-11-21 20:25:22,786:INFO:Starting cross validation
2025-11-21 20:25:22,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:28,758:INFO:Calculating mean and std
2025-11-21 20:25:28,760:INFO:Creating metrics dataframe
2025-11-21 20:25:28,763:INFO:Uploading results into container
2025-11-21 20:25:28,763:INFO:Uploading model into container now
2025-11-21 20:25:28,763:INFO:_master_model_container: 2
2025-11-21 20:25:28,763:INFO:_display_container: 2
2025-11-21 20:25:28,763:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-21 20:25:28,763:INFO:create_model() successfully completed......................................
2025-11-21 20:25:28,901:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:28,901:INFO:Creating metrics dataframe
2025-11-21 20:25:28,910:INFO:Initializing Naive Bayes
2025-11-21 20:25:28,910:INFO:Total runtime is 0.23438026905059814 minutes
2025-11-21 20:25:28,914:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:28,915:INFO:Initializing create_model()
2025-11-21 20:25:28,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:28,915:INFO:Checking exceptions
2025-11-21 20:25:28,915:INFO:Importing libraries
2025-11-21 20:25:28,915:INFO:Copying training dataset
2025-11-21 20:25:28,928:INFO:Defining folds
2025-11-21 20:25:28,928:INFO:Declaring metric variables
2025-11-21 20:25:28,933:INFO:Importing untrained model
2025-11-21 20:25:28,938:INFO:Naive Bayes Imported successfully
2025-11-21 20:25:28,943:INFO:Starting cross validation
2025-11-21 20:25:28,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:29,077:INFO:Calculating mean and std
2025-11-21 20:25:29,078:INFO:Creating metrics dataframe
2025-11-21 20:25:29,080:INFO:Uploading results into container
2025-11-21 20:25:29,081:INFO:Uploading model into container now
2025-11-21 20:25:29,082:INFO:_master_model_container: 3
2025-11-21 20:25:29,082:INFO:_display_container: 2
2025-11-21 20:25:29,082:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-21 20:25:29,082:INFO:create_model() successfully completed......................................
2025-11-21 20:25:29,194:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:29,194:INFO:Creating metrics dataframe
2025-11-21 20:25:29,207:INFO:Initializing Decision Tree Classifier
2025-11-21 20:25:29,207:INFO:Total runtime is 0.2393316586812337 minutes
2025-11-21 20:25:29,212:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:29,212:INFO:Initializing create_model()
2025-11-21 20:25:29,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:29,212:INFO:Checking exceptions
2025-11-21 20:25:29,212:INFO:Importing libraries
2025-11-21 20:25:29,213:INFO:Copying training dataset
2025-11-21 20:25:29,221:INFO:Defining folds
2025-11-21 20:25:29,221:INFO:Declaring metric variables
2025-11-21 20:25:29,229:INFO:Importing untrained model
2025-11-21 20:25:29,233:INFO:Decision Tree Classifier Imported successfully
2025-11-21 20:25:29,241:INFO:Starting cross validation
2025-11-21 20:25:29,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:29,391:INFO:Calculating mean and std
2025-11-21 20:25:29,394:INFO:Creating metrics dataframe
2025-11-21 20:25:29,394:INFO:Uploading results into container
2025-11-21 20:25:29,394:INFO:Uploading model into container now
2025-11-21 20:25:29,394:INFO:_master_model_container: 4
2025-11-21 20:25:29,394:INFO:_display_container: 2
2025-11-21 20:25:29,394:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-11-21 20:25:29,394:INFO:create_model() successfully completed......................................
2025-11-21 20:25:29,516:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:29,516:INFO:Creating metrics dataframe
2025-11-21 20:25:29,518:INFO:Initializing SVM - Linear Kernel
2025-11-21 20:25:29,518:INFO:Total runtime is 0.24452276627222697 minutes
2025-11-21 20:25:29,529:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:29,529:INFO:Initializing create_model()
2025-11-21 20:25:29,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:29,530:INFO:Checking exceptions
2025-11-21 20:25:29,530:INFO:Importing libraries
2025-11-21 20:25:29,530:INFO:Copying training dataset
2025-11-21 20:25:29,539:INFO:Defining folds
2025-11-21 20:25:29,539:INFO:Declaring metric variables
2025-11-21 20:25:29,548:INFO:Importing untrained model
2025-11-21 20:25:29,552:INFO:SVM - Linear Kernel Imported successfully
2025-11-21 20:25:29,560:INFO:Starting cross validation
2025-11-21 20:25:29,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:29,724:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 20:25:29,729:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-21 20:25:29,776:INFO:Calculating mean and std
2025-11-21 20:25:29,777:INFO:Creating metrics dataframe
2025-11-21 20:25:29,779:INFO:Uploading results into container
2025-11-21 20:25:29,780:INFO:Uploading model into container now
2025-11-21 20:25:29,780:INFO:_master_model_container: 5
2025-11-21 20:25:29,780:INFO:_display_container: 2
2025-11-21 20:25:29,781:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-11-21 20:25:29,781:INFO:create_model() successfully completed......................................
2025-11-21 20:25:29,911:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:29,912:INFO:Creating metrics dataframe
2025-11-21 20:25:29,920:INFO:Initializing Ridge Classifier
2025-11-21 20:25:29,920:INFO:Total runtime is 0.25121378898620605 minutes
2025-11-21 20:25:29,921:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:29,921:INFO:Initializing create_model()
2025-11-21 20:25:29,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:29,921:INFO:Checking exceptions
2025-11-21 20:25:29,921:INFO:Importing libraries
2025-11-21 20:25:29,921:INFO:Copying training dataset
2025-11-21 20:25:29,940:INFO:Defining folds
2025-11-21 20:25:29,940:INFO:Declaring metric variables
2025-11-21 20:25:29,943:INFO:Importing untrained model
2025-11-21 20:25:29,950:INFO:Ridge Classifier Imported successfully
2025-11-21 20:25:29,957:INFO:Starting cross validation
2025-11-21 20:25:29,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:30,078:INFO:Calculating mean and std
2025-11-21 20:25:30,079:INFO:Creating metrics dataframe
2025-11-21 20:25:30,081:INFO:Uploading results into container
2025-11-21 20:25:30,081:INFO:Uploading model into container now
2025-11-21 20:25:30,081:INFO:_master_model_container: 6
2025-11-21 20:25:30,081:INFO:_display_container: 2
2025-11-21 20:25:30,081:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-11-21 20:25:30,081:INFO:create_model() successfully completed......................................
2025-11-21 20:25:30,214:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:30,214:INFO:Creating metrics dataframe
2025-11-21 20:25:30,220:INFO:Initializing Random Forest Classifier
2025-11-21 20:25:30,220:INFO:Total runtime is 0.25621001720428466 minutes
2025-11-21 20:25:30,230:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:30,231:INFO:Initializing create_model()
2025-11-21 20:25:30,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:30,231:INFO:Checking exceptions
2025-11-21 20:25:30,231:INFO:Importing libraries
2025-11-21 20:25:30,231:INFO:Copying training dataset
2025-11-21 20:25:30,242:INFO:Defining folds
2025-11-21 20:25:30,242:INFO:Declaring metric variables
2025-11-21 20:25:30,251:INFO:Importing untrained model
2025-11-21 20:25:30,254:INFO:Random Forest Classifier Imported successfully
2025-11-21 20:25:30,261:INFO:Starting cross validation
2025-11-21 20:25:30,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:31,225:INFO:Calculating mean and std
2025-11-21 20:25:31,228:INFO:Creating metrics dataframe
2025-11-21 20:25:31,230:INFO:Uploading results into container
2025-11-21 20:25:31,231:INFO:Uploading model into container now
2025-11-21 20:25:31,231:INFO:_master_model_container: 7
2025-11-21 20:25:31,232:INFO:_display_container: 2
2025-11-21 20:25:31,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-11-21 20:25:31,233:INFO:create_model() successfully completed......................................
2025-11-21 20:25:31,358:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:31,358:INFO:Creating metrics dataframe
2025-11-21 20:25:31,373:INFO:Initializing Quadratic Discriminant Analysis
2025-11-21 20:25:31,373:INFO:Total runtime is 0.27543297211329143 minutes
2025-11-21 20:25:31,378:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:31,378:INFO:Initializing create_model()
2025-11-21 20:25:31,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:31,379:INFO:Checking exceptions
2025-11-21 20:25:31,379:INFO:Importing libraries
2025-11-21 20:25:31,379:INFO:Copying training dataset
2025-11-21 20:25:31,394:INFO:Defining folds
2025-11-21 20:25:31,394:INFO:Declaring metric variables
2025-11-21 20:25:31,400:INFO:Importing untrained model
2025-11-21 20:25:31,401:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-21 20:25:31,415:INFO:Starting cross validation
2025-11-21 20:25:31,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:31,508:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,508:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,509:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,509:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,509:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,509:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-21 20:25:31,562:INFO:Calculating mean and std
2025-11-21 20:25:31,562:INFO:Creating metrics dataframe
2025-11-21 20:25:31,562:INFO:Uploading results into container
2025-11-21 20:25:31,562:INFO:Uploading model into container now
2025-11-21 20:25:31,567:INFO:_master_model_container: 8
2025-11-21 20:25:31,567:INFO:_display_container: 2
2025-11-21 20:25:31,567:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-21 20:25:31,567:INFO:create_model() successfully completed......................................
2025-11-21 20:25:31,689:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:31,690:INFO:Creating metrics dataframe
2025-11-21 20:25:31,693:INFO:Initializing Ada Boost Classifier
2025-11-21 20:25:31,693:INFO:Total runtime is 0.2807657281557719 minutes
2025-11-21 20:25:31,699:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:31,699:INFO:Initializing create_model()
2025-11-21 20:25:31,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:31,699:INFO:Checking exceptions
2025-11-21 20:25:31,699:INFO:Importing libraries
2025-11-21 20:25:31,699:INFO:Copying training dataset
2025-11-21 20:25:31,715:INFO:Defining folds
2025-11-21 20:25:31,716:INFO:Declaring metric variables
2025-11-21 20:25:31,720:INFO:Importing untrained model
2025-11-21 20:25:31,727:INFO:Ada Boost Classifier Imported successfully
2025-11-21 20:25:31,733:INFO:Starting cross validation
2025-11-21 20:25:31,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:31,812:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:31,813:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:31,813:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:31,813:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:31,813:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:31,813:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-21 20:25:32,275:INFO:Calculating mean and std
2025-11-21 20:25:32,277:INFO:Creating metrics dataframe
2025-11-21 20:25:32,280:INFO:Uploading results into container
2025-11-21 20:25:32,280:INFO:Uploading model into container now
2025-11-21 20:25:32,281:INFO:_master_model_container: 9
2025-11-21 20:25:32,281:INFO:_display_container: 2
2025-11-21 20:25:32,281:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-11-21 20:25:32,282:INFO:create_model() successfully completed......................................
2025-11-21 20:25:32,394:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:32,394:INFO:Creating metrics dataframe
2025-11-21 20:25:32,401:INFO:Initializing Gradient Boosting Classifier
2025-11-21 20:25:32,401:INFO:Total runtime is 0.29256447950998943 minutes
2025-11-21 20:25:32,411:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:32,412:INFO:Initializing create_model()
2025-11-21 20:25:32,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:32,412:INFO:Checking exceptions
2025-11-21 20:25:32,412:INFO:Importing libraries
2025-11-21 20:25:32,412:INFO:Copying training dataset
2025-11-21 20:25:32,421:INFO:Defining folds
2025-11-21 20:25:32,421:INFO:Declaring metric variables
2025-11-21 20:25:32,429:INFO:Importing untrained model
2025-11-21 20:25:32,434:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 20:25:32,442:INFO:Starting cross validation
2025-11-21 20:25:32,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:33,774:INFO:Calculating mean and std
2025-11-21 20:25:33,776:INFO:Creating metrics dataframe
2025-11-21 20:25:33,778:INFO:Uploading results into container
2025-11-21 20:25:33,780:INFO:Uploading model into container now
2025-11-21 20:25:33,780:INFO:_master_model_container: 10
2025-11-21 20:25:33,780:INFO:_display_container: 2
2025-11-21 20:25:33,781:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:25:33,781:INFO:create_model() successfully completed......................................
2025-11-21 20:25:33,893:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:33,893:INFO:Creating metrics dataframe
2025-11-21 20:25:33,910:INFO:Initializing Linear Discriminant Analysis
2025-11-21 20:25:33,911:INFO:Total runtime is 0.31772056818008426 minutes
2025-11-21 20:25:33,919:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:33,920:INFO:Initializing create_model()
2025-11-21 20:25:33,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:33,921:INFO:Checking exceptions
2025-11-21 20:25:33,921:INFO:Importing libraries
2025-11-21 20:25:33,921:INFO:Copying training dataset
2025-11-21 20:25:33,936:INFO:Defining folds
2025-11-21 20:25:33,937:INFO:Declaring metric variables
2025-11-21 20:25:33,942:INFO:Importing untrained model
2025-11-21 20:25:33,949:INFO:Linear Discriminant Analysis Imported successfully
2025-11-21 20:25:33,957:INFO:Starting cross validation
2025-11-21 20:25:33,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:34,078:INFO:Calculating mean and std
2025-11-21 20:25:34,080:INFO:Creating metrics dataframe
2025-11-21 20:25:34,081:INFO:Uploading results into container
2025-11-21 20:25:34,081:INFO:Uploading model into container now
2025-11-21 20:25:34,081:INFO:_master_model_container: 11
2025-11-21 20:25:34,081:INFO:_display_container: 2
2025-11-21 20:25:34,081:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-21 20:25:34,081:INFO:create_model() successfully completed......................................
2025-11-21 20:25:34,222:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:34,222:INFO:Creating metrics dataframe
2025-11-21 20:25:34,236:INFO:Initializing Extra Trees Classifier
2025-11-21 20:25:34,236:INFO:Total runtime is 0.3231512427330017 minutes
2025-11-21 20:25:34,242:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:34,242:INFO:Initializing create_model()
2025-11-21 20:25:34,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:34,242:INFO:Checking exceptions
2025-11-21 20:25:34,242:INFO:Importing libraries
2025-11-21 20:25:34,242:INFO:Copying training dataset
2025-11-21 20:25:34,265:INFO:Defining folds
2025-11-21 20:25:34,265:INFO:Declaring metric variables
2025-11-21 20:25:34,273:INFO:Importing untrained model
2025-11-21 20:25:34,279:INFO:Extra Trees Classifier Imported successfully
2025-11-21 20:25:34,290:INFO:Starting cross validation
2025-11-21 20:25:34,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:35,254:INFO:Calculating mean and std
2025-11-21 20:25:35,255:INFO:Creating metrics dataframe
2025-11-21 20:25:35,257:INFO:Uploading results into container
2025-11-21 20:25:35,257:INFO:Uploading model into container now
2025-11-21 20:25:35,259:INFO:_master_model_container: 12
2025-11-21 20:25:35,259:INFO:_display_container: 2
2025-11-21 20:25:35,260:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-11-21 20:25:35,260:INFO:create_model() successfully completed......................................
2025-11-21 20:25:35,393:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:35,393:INFO:Creating metrics dataframe
2025-11-21 20:25:35,401:INFO:Initializing Extreme Gradient Boosting
2025-11-21 20:25:35,401:INFO:Total runtime is 0.3425636887550354 minutes
2025-11-21 20:25:35,409:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:35,410:INFO:Initializing create_model()
2025-11-21 20:25:35,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:35,410:INFO:Checking exceptions
2025-11-21 20:25:35,410:INFO:Importing libraries
2025-11-21 20:25:35,410:INFO:Copying training dataset
2025-11-21 20:25:35,421:INFO:Defining folds
2025-11-21 20:25:35,421:INFO:Declaring metric variables
2025-11-21 20:25:35,428:INFO:Importing untrained model
2025-11-21 20:25:35,433:INFO:Extreme Gradient Boosting Imported successfully
2025-11-21 20:25:35,442:INFO:Starting cross validation
2025-11-21 20:25:35,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:36,816:INFO:Calculating mean and std
2025-11-21 20:25:36,817:INFO:Creating metrics dataframe
2025-11-21 20:25:36,817:INFO:Uploading results into container
2025-11-21 20:25:36,817:INFO:Uploading model into container now
2025-11-21 20:25:36,817:INFO:_master_model_container: 13
2025-11-21 20:25:36,817:INFO:_display_container: 2
2025-11-21 20:25:36,817:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-11-21 20:25:36,817:INFO:create_model() successfully completed......................................
2025-11-21 20:25:36,942:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:36,942:INFO:Creating metrics dataframe
2025-11-21 20:25:36,956:INFO:Initializing Light Gradient Boosting Machine
2025-11-21 20:25:36,957:INFO:Total runtime is 0.36849958499272667 minutes
2025-11-21 20:25:36,961:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:36,962:INFO:Initializing create_model()
2025-11-21 20:25:36,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:36,962:INFO:Checking exceptions
2025-11-21 20:25:36,962:INFO:Importing libraries
2025-11-21 20:25:36,962:INFO:Copying training dataset
2025-11-21 20:25:36,977:INFO:Defining folds
2025-11-21 20:25:36,977:INFO:Declaring metric variables
2025-11-21 20:25:36,981:INFO:Importing untrained model
2025-11-21 20:25:36,986:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-21 20:25:36,991:INFO:Starting cross validation
2025-11-21 20:25:36,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:42,431:INFO:Calculating mean and std
2025-11-21 20:25:42,433:INFO:Creating metrics dataframe
2025-11-21 20:25:42,437:INFO:Uploading results into container
2025-11-21 20:25:42,438:INFO:Uploading model into container now
2025-11-21 20:25:42,438:INFO:_master_model_container: 14
2025-11-21 20:25:42,438:INFO:_display_container: 2
2025-11-21 20:25:42,439:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-21 20:25:42,439:INFO:create_model() successfully completed......................................
2025-11-21 20:25:42,589:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:42,590:INFO:Creating metrics dataframe
2025-11-21 20:25:42,602:INFO:Initializing Dummy Classifier
2025-11-21 20:25:42,603:INFO:Total runtime is 0.4626078248023987 minutes
2025-11-21 20:25:42,606:INFO:SubProcess create_model() called ==================================
2025-11-21 20:25:42,607:INFO:Initializing create_model()
2025-11-21 20:25:42,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A048546F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:42,607:INFO:Checking exceptions
2025-11-21 20:25:42,607:INFO:Importing libraries
2025-11-21 20:25:42,608:INFO:Copying training dataset
2025-11-21 20:25:42,624:INFO:Defining folds
2025-11-21 20:25:42,624:INFO:Declaring metric variables
2025-11-21 20:25:42,629:INFO:Importing untrained model
2025-11-21 20:25:42,632:INFO:Dummy Classifier Imported successfully
2025-11-21 20:25:42,644:INFO:Starting cross validation
2025-11-21 20:25:42,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:42,768:INFO:Calculating mean and std
2025-11-21 20:25:42,769:INFO:Creating metrics dataframe
2025-11-21 20:25:42,769:INFO:Uploading results into container
2025-11-21 20:25:42,769:INFO:Uploading model into container now
2025-11-21 20:25:42,769:INFO:_master_model_container: 15
2025-11-21 20:25:42,769:INFO:_display_container: 2
2025-11-21 20:25:42,769:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-11-21 20:25:42,769:INFO:create_model() successfully completed......................................
2025-11-21 20:25:42,895:INFO:SubProcess create_model() end ==================================
2025-11-21 20:25:42,895:INFO:Creating metrics dataframe
2025-11-21 20:25:42,908:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-11-21 20:25:42,924:INFO:Initializing create_model()
2025-11-21 20:25:42,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:42,924:INFO:Checking exceptions
2025-11-21 20:25:42,926:INFO:Importing libraries
2025-11-21 20:25:42,926:INFO:Copying training dataset
2025-11-21 20:25:42,938:INFO:Defining folds
2025-11-21 20:25:42,938:INFO:Declaring metric variables
2025-11-21 20:25:42,938:INFO:Importing untrained model
2025-11-21 20:25:42,938:INFO:Declaring custom model
2025-11-21 20:25:42,938:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 20:25:42,938:INFO:Cross validation set to False
2025-11-21 20:25:42,938:INFO:Fitting Model
2025-11-21 20:25:44,187:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:25:44,187:INFO:create_model() successfully completed......................................
2025-11-21 20:25:44,382:INFO:_master_model_container: 15
2025-11-21 20:25:44,382:INFO:_display_container: 2
2025-11-21 20:25:44,382:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:25:44,382:INFO:compare_models() successfully completed......................................
2025-11-21 20:25:44,403:INFO:Initializing create_model()
2025-11-21 20:25:44,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:25:44,403:INFO:Checking exceptions
2025-11-21 20:25:44,427:INFO:Importing libraries
2025-11-21 20:25:44,428:INFO:Copying training dataset
2025-11-21 20:25:44,445:INFO:Defining folds
2025-11-21 20:25:44,445:INFO:Declaring metric variables
2025-11-21 20:25:44,450:INFO:Importing untrained model
2025-11-21 20:25:44,456:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 20:25:44,466:INFO:Starting cross validation
2025-11-21 20:25:44,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:25:45,898:INFO:Calculating mean and std
2025-11-21 20:25:45,898:INFO:Creating metrics dataframe
2025-11-21 20:25:45,903:INFO:Finalizing model
2025-11-21 20:25:47,145:INFO:Uploading results into container
2025-11-21 20:25:47,145:INFO:Uploading model into container now
2025-11-21 20:25:47,159:INFO:_master_model_container: 16
2025-11-21 20:25:47,159:INFO:_display_container: 3
2025-11-21 20:25:47,159:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:25:47,159:INFO:create_model() successfully completed......................................
2025-11-21 20:25:47,283:INFO:Initializing tune_model()
2025-11-21 20:25:47,284:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'subsample': [0.8, 1.0]}, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-11-21 20:25:47,284:INFO:Checking exceptions
2025-11-21 20:25:47,311:INFO:Copying training dataset
2025-11-21 20:25:47,321:INFO:Checking base model
2025-11-21 20:25:47,321:INFO:Base model : Gradient Boosting Classifier
2025-11-21 20:25:47,325:INFO:Declaring metric variables
2025-11-21 20:25:47,329:INFO:Defining Hyperparameters
2025-11-21 20:25:47,450:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 200, 300], 'actual_estimator__learning_rate': [0.01, 0.1, 0.2], 'actual_estimator__max_depth': [3, 5, 7], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__subsample': [0.8, 1.0]}
2025-11-21 20:25:47,450:INFO:Tuning with n_jobs=-1
2025-11-21 20:25:47,450:INFO:Initializing RandomizedSearchCV
2025-11-21 20:26:11,705:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 10, 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.1}
2025-11-21 20:26:11,708:INFO:Hyperparameter search completed
2025-11-21 20:26:11,708:INFO:SubProcess create_model() called ==================================
2025-11-21 20:26:11,709:INFO:Initializing create_model()
2025-11-21 20:26:11,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A03F7909D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.1})
2025-11-21 20:26:11,709:INFO:Checking exceptions
2025-11-21 20:26:11,709:INFO:Importing libraries
2025-11-21 20:26:11,709:INFO:Copying training dataset
2025-11-21 20:26:11,726:INFO:Defining folds
2025-11-21 20:26:11,727:INFO:Declaring metric variables
2025-11-21 20:26:11,730:INFO:Importing untrained model
2025-11-21 20:26:11,730:INFO:Declaring custom model
2025-11-21 20:26:11,735:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 20:26:11,741:INFO:Starting cross validation
2025-11-21 20:26:11,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:26:12,903:INFO:Calculating mean and std
2025-11-21 20:26:12,905:INFO:Creating metrics dataframe
2025-11-21 20:26:12,906:INFO:Finalizing model
2025-11-21 20:26:13,979:INFO:Uploading results into container
2025-11-21 20:26:13,981:INFO:Uploading model into container now
2025-11-21 20:26:13,983:INFO:_master_model_container: 17
2025-11-21 20:26:13,983:INFO:_display_container: 4
2025-11-21 20:26:13,984:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:26:13,984:INFO:create_model() successfully completed......................................
2025-11-21 20:26:14,157:INFO:SubProcess create_model() end ==================================
2025-11-21 20:26:14,157:INFO:choose_better activated
2025-11-21 20:26:14,159:INFO:SubProcess create_model() called ==================================
2025-11-21 20:26:14,159:INFO:Initializing create_model()
2025-11-21 20:26:14,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-21 20:26:14,159:INFO:Checking exceptions
2025-11-21 20:26:14,159:INFO:Importing libraries
2025-11-21 20:26:14,159:INFO:Copying training dataset
2025-11-21 20:26:14,165:INFO:Defining folds
2025-11-21 20:26:14,165:INFO:Declaring metric variables
2025-11-21 20:26:14,165:INFO:Importing untrained model
2025-11-21 20:26:14,165:INFO:Declaring custom model
2025-11-21 20:26:14,165:INFO:Gradient Boosting Classifier Imported successfully
2025-11-21 20:26:14,165:INFO:Starting cross validation
2025-11-21 20:26:14,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-21 20:26:15,531:INFO:Calculating mean and std
2025-11-21 20:26:15,531:INFO:Creating metrics dataframe
2025-11-21 20:26:15,535:INFO:Finalizing model
2025-11-21 20:26:16,712:INFO:Uploading results into container
2025-11-21 20:26:16,712:INFO:Uploading model into container now
2025-11-21 20:26:16,712:INFO:_master_model_container: 18
2025-11-21 20:26:16,712:INFO:_display_container: 5
2025-11-21 20:26:16,712:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:26:16,712:INFO:create_model() successfully completed......................................
2025-11-21 20:26:16,876:INFO:SubProcess create_model() end ==================================
2025-11-21 20:26:16,878:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.9418
2025-11-21 20:26:16,878:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.942
2025-11-21 20:26:16,878:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-11-21 20:26:16,878:INFO:choose_better completed
2025-11-21 20:26:16,887:INFO:_master_model_container: 18
2025-11-21 20:26:16,887:INFO:_display_container: 4
2025-11-21 20:26:16,887:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-21 20:26:16,887:INFO:tune_model() successfully completed......................................
2025-11-21 20:26:17,081:INFO:Initializing plot_model()
2025-11-21 20:26:17,081:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 20:26:17,081:INFO:Checking exceptions
2025-11-21 20:26:17,102:INFO:Preloading libraries
2025-11-21 20:26:17,116:INFO:Copying training dataset
2025-11-21 20:26:17,117:INFO:Plot type: confusion_matrix
2025-11-21 20:26:17,293:INFO:Fitting Model
2025-11-21 20:26:17,319:WARNING:C:\Users\sivv1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2025-11-21 20:26:17,319:INFO:Scoring test/hold-out set
2025-11-21 20:26:17,492:INFO:Visual Rendered Successfully
2025-11-21 20:26:17,663:INFO:plot_model() successfully completed......................................
2025-11-21 20:26:17,695:INFO:Initializing plot_model()
2025-11-21 20:26:17,695:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A03FA23D50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-11-21 20:26:17,695:INFO:Checking exceptions
2025-11-21 20:26:17,703:INFO:Preloading libraries
2025-11-21 20:26:17,715:INFO:Copying training dataset
2025-11-21 20:26:17,716:INFO:Plot type: feature
2025-11-21 20:26:17,716:WARNING:No coef_ found. Trying feature_importances_
2025-11-21 20:26:17,978:INFO:Visual Rendered Successfully
2025-11-21 20:26:18,114:INFO:plot_model() successfully completed......................................
